[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "eBird Best Practices: Modeling Relative Abundance",
    "section": "",
    "text": "Introduction\nThe contents of this website comprise the notes for a workshop on best practices for using eBird data presented at the Australasian Ornithological Conference 2023 on Monday November 27 in Brisbane, Australia. The workshop is divided into two lessons covering:"
  },
  {
    "objectID": "index.html#sec-intro-setup",
    "href": "index.html#sec-intro-setup",
    "title": "eBird Best Practices: Modeling Relative Abundance",
    "section": "Setup",
    "text": "Setup\nThis workshop is intended to be interactive. All examples are written in the R programming language, and the instructor will work through the examples in real time, while the attendees are encouraged following along by writing the same code. To ensure we can avoid any unnecessary delays, please follow these setup instructions prior to the workshop\n\nDownload and install the latest version of R. You must have R version 4.0.0 or newer to follow along with this workshop\nDownload and install the latest version of RStudio. RStudio is not required for this workshop; however, the instructors will be using it and you may find it easier to following along if you’re working in the same environment.\nCreate an RStudio project for working through the examples in this workshop. In the Data section below, you’ll download the data to the proper path in the project you create.\nThe lessons in this workshop use a variety of R packages. To install all the necessary packages, run the following code\n\n\nif (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  install.packages(\"remotes\")\n}\nremotes::install_github(\"ebird/ebird-best-practices\")\n\n\nEnsure all packages are updated to their most recent versions by clicking on the Update button on the Packages tab in RStudio."
  },
  {
    "objectID": "index.html#sec-intro-setup-data",
    "href": "index.html#sec-intro-setup-data",
    "title": "eBird Best Practices: Modeling Relative Abundance",
    "section": "Data",
    "text": "Data\nSince having a large group of workshop participants attempt to download a large amount of data all at once, on the same WIFI connection, we’ve provided pre-packaged data and a script to load it into the correct directories before the workshop begins.\n\n# download data package to root project directory\noptions(timeout = 10000)\ndownload.file(\"https://cornell.box.com/shared/static/vpk03qqwjtswskam246prd5h9am3lzt5.zip\", \n              destfile = \"data.zip\")\n\n# unzip\nunzip(\"data.zip\")"
  },
  {
    "objectID": "index.html#template-r-scripts",
    "href": "index.html#template-r-scripts",
    "title": "eBird Best Practices: Modeling Relative Abundance",
    "section": "Template R scripts",
    "text": "Template R scripts\nDuring the workshop we’ll work through the lessons on this website, writing code together in real time; however, it will be useful to have script templates to work from. Open RStudio, then:\n\nCreate a script named “ebird-data.R”, visit this link, and copy the contents into the script you just created.\nCreate a script named “ebird-rel-abd.R”, visit this link, and copy the contents into the script you just created."
  },
  {
    "objectID": "index.html#sec-intro-tidyverse",
    "href": "index.html#sec-intro-tidyverse",
    "title": "eBird Best Practices: Modeling Relative Abundance",
    "section": "Tidyverse",
    "text": "Tidyverse\nThroughout this book, we use packages from the Tidyverse, an opinionated collection of R packages designed for data science. Packages such as ggplot2, for data visualization, and dplyr, for data manipulation, are two of the most well known Tidyverse packages; however, there are many more. We’ll try to explain any functions as they come up; however, for a good general resource on working with data in R using the Tidyverse see the free online book R for Data Science by Hadley Wickham.\nThe one piece of the Tidyverse that we will cover up front is the pipe operator %&gt;%. The pipe takes the expression to the left of it and “pipes” it into the first argument of the expression on the right.\n\nlibrary(dplyr)\n\n# without pipe\nmean(1:10)\n#&gt; [1] 5.5\n\n# with pipe\n1:10 %&gt;% mean()\n#&gt; [1] 5.5\n\nThe pipe can code significantly more readable by avoiding nested function calls, reducing the need for intermediate variables, and making sequential operations read left-to-right. For example, to add a new variable to a data frame, then summarize using a grouping variable, the following are equivalent:\n\n# intermediate variables\nmtcars_kg &lt;- mutate(mtcars, wt_kg = 454 * wt)\nmtcars_grouped &lt;- group_by(mtcars_kg, cyl)\nsummarize(mtcars_grouped, wt_kg = mean(wt_kg))\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\n# nested function calls\nsummarize(\n  group_by(\n    mutate(mtcars, wt_kg = 454 * wt),\n    cyl\n  ),\n  wt_kg = mean(wt_kg)\n)\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\n# pipes\nmtcars %&gt;% \n  mutate(wt_kg = 454 * wt) %&gt;% \n  group_by(cyl) %&gt;% \n  summarize(wt_kg = mean(wt_kg))\n#&gt; # A tibble: 3 × 2\n#&gt;     cyl wt_kg\n#&gt;   &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1     4 1038.\n#&gt; 2     6 1415.\n#&gt; 3     8 1816.\n\n\n\n\n\n\n\nExercise\n\n\n\nRewrite the following code using pipes:\n\nset.seed(1)\nround(log(runif(10, min = 0.5)), 1)\n#&gt;  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nset.seed(1)\nrunif(10, min = 0.5) %&gt;% \n  log() %&gt;% \n  round(digits = 1)\n#&gt;  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6"
  },
  {
    "objectID": "ebird.html#sec-ebird-ebd",
    "href": "ebird.html#sec-ebird-ebd",
    "title": "1  eBird Data",
    "section": "1.1 raw eBird Data (EBD)",
    "text": "1.1 raw eBird Data (EBD)\neBird data are released as two tab-separated text files: the eBird Basic Dataset (EBD) containing observation data and the Sampling Event Data (SED) containing checklist data. These files are released monthly and contain all validated bird sightings in the eBird database at the time of release. In the EBD, each row corresponds to the sighting of a single species on a checklist, including the count and any other species-level information (e.g. age, sex, species comments, etc.). In the SED, each row corresponds to a checklist, including the date, time, location, effort (e.g. distance traveled, time spent, etc.), and any additional checklist-level information (e.g. whether this is a complete checklist or not).\n\n1.1.1 Downloading data\nIn this workshop, we’ll use Shining Bronze-Cuckoo observations from Queensland, Australia as an example. We’ll start by downloading the corresponding eBird observation (EBD) and checklist (SED) data by visiting the eBird Basic Dataset download page and filling out the Custom Download form to request Shining Bronze-Cuckoo observations from Queensland. Make sure you check the box “Include sampling event data”, which will include the SED in the data download in addition to the EBD.\n\n\n\n\n\n\n\nTip\n\n\n\nThe eBird database contains a massive amount of data! When requesting eBird data to download it’s important to narrow the request to as small a subset of the data as possible. For example, if we request all Shining Bronze-Cuckoo observations globally, the dataset may be too large to work with in R. Instead, we’ve only requested data for a single state in Australia.\n\n\nOnce the data are ready, you will receive an email with a download link. The downloaded data will be in a compressed .zip format, and should be unarchived. The resulting directory will contain a two text files: one for the EBD (e.g. ebd_BR-RS_fotfly_smp_relJun-2023.txt) containing all the Shining Bronze-Cuckoo observations from Queensland, and one for the SED (e.g. ebd_BR-RS_fotfly_smp_relJun-2023_sampling.txt) containing all checklists from Queensland, The relJune-2023 component of the file name describes which version of the EBD this dataset came from; in this case it’s the June 2023 release.\nIf you would prefer to directly download the exact dataset used in this workshop, download the data package for this workshop.\n\n\n1.1.2 Importing eBird data into R\nThe previous step left us with two tab separated text files, one for the EBD (i.e. observation data) and one for the SED (i.e. checklist data). Start a new RStudio project and put the downloaded text files in the data/ sub-directory of the project directory.\nThe auk R package is specifically designed for working with eBird data. It includes the functions read_ebd() and read_sampling() for importing the EBD and SED, respectively, into R. First let’s import the checklist data (SED).\n\nlibrary(auk)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(lubridate)\nlibrary(sf)\n\nf_sed &lt;- \"data/ebd_AU-QLD_shbcuc1_smp_relSep-2023_sampling.txt\"\nchecklists &lt;- read_sampling(f_sed, unique = FALSE)\nglimpse(checklists)\n#&gt; Rows: 755,445\n#&gt; Columns: 30\n#&gt; $ last_edited_date          &lt;chr&gt; \"2021-04-19 02:40:19.157994\", \"2021-10-22 20…\n#&gt; $ country                   &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\", \"Aust…\n#&gt; $ country_code              &lt;chr&gt; \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"A…\n#&gt; $ state                     &lt;chr&gt; \"Queensland\", \"Queensland\", \"Queensland\", \"Q…\n#&gt; $ state_code                &lt;chr&gt; \"AU-QLD\", \"AU-QLD\", \"AU-QLD\", \"AU-QLD\", \"AU-…\n#&gt; $ county                    &lt;chr&gt; \"Brisbane\", \"Brisbane\", \"Brisbane\", \"Brisban…\n#&gt; $ county_code               &lt;chr&gt; \"AU-QLD-BRI\", \"AU-QLD-BRI\", \"AU-QLD-BRI\", \"A…\n#&gt; $ iba_code                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ bcr_code                  &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ usfws_code                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ atlas_block               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ locality                  &lt;chr&gt; \"Dowse Lagoon (Sandgate)\", \"Dowse Lagoon (Sa…\n#&gt; $ locality_id               &lt;chr&gt; \"L1896576\", \"L1896576\", \"L1896576\", \"L189657…\n#&gt; $ locality_type             &lt;chr&gt; \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\",…\n#&gt; $ latitude                  &lt;dbl&gt; -27.3, -27.3, -27.3, -27.3, -27.3, -27.3, -2…\n#&gt; $ longitude                 &lt;dbl&gt; 153, 153, 153, 153, 153, 153, 153, 153, 153,…\n#&gt; $ observation_date          &lt;date&gt; 2021-04-19, 2021-10-23, 2021-04-25, 2021-11…\n#&gt; $ time_observations_started &lt;chr&gt; \"15:40:00\", \"06:04:00\", \"12:25:00\", \"13:53:0…\n#&gt; $ observer_id               &lt;chr&gt; \"obs427309\", \"obs427309\", \"obs535737\", \"obs9…\n#&gt; $ sampling_event_identifier &lt;chr&gt; \"S85875959\", \"S96568064\", \"S86299492\", \"S978…\n#&gt; $ protocol_type             &lt;chr&gt; \"Traveling\", \"Traveling\", \"Stationary\", \"Tra…\n#&gt; $ protocol_code             &lt;chr&gt; \"P22\", \"P22\", \"P21\", \"P22\", \"P22\", \"P21\", \"P…\n#&gt; $ project_code              &lt;chr&gt; \"EBIRD\", \"EBIRD\", \"EBIRD\", \"EBIRD\", \"EBIRD_A…\n#&gt; $ duration_minutes          &lt;int&gt; 59, 138, 33, 46, 75, 16, 67, 104, 28, 45, NA…\n#&gt; $ effort_distance_km        &lt;dbl&gt; 1.954, 3.437, NA, 1.610, 1.030, NA, 1.310, 2…\n#&gt; $ effort_area_ha            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ number_observers          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ all_species_reported      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n#&gt; $ group_identifier          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ trip_comments             &lt;chr&gt; NA, NA, NA, \"Clear skies light breeze. Targe…\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nTake some time to explore the variables in the checklist dataset. If you’re unsure about any of the variables, consult the metadata document that came with the data download (eBird_Basic_Dataset_Metadata_v1.14.pdf).\n\n\nFor some applications, only the checklist data are required. For example, the checklist data can be used to investigate the spatial and temporal distribution of eBird data within a region. This dataset can also be used to explore how much variation there is in the observation effort variables and identify checklists that have low spatial or temporal precision.\n\n\n\n\n\n\nExercise\n\n\n\nMake a histogram of the distribution of distance traveling for traveling protocol checklists.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nNearly 90% of checklists are less than 10km in length; however, some checklists are as long as 80km in length. Long traveling checklists have lower spatial precision so they should generally be removed prior to analysis.\n\nchecklists_traveling &lt;- filter(checklists, protocol_type == \"Traveling\")\nggplot(checklists_traveling) +\n  aes(x = effort_distance_km) +\n  geom_histogram(binwidth = 5) +\n  scale_y_continuous(limits = c(0, NA), labels = scales::comma) +\n  labs(x = \"Distance traveled [km]\",\n       y = \"# of eBird checklists\",\n       title = \"Distribution of distance traveled on eBird checklists\")\n\n\n\n\n\n\n\n\n\n\n\nNext, let’s load the observation data.\n\nf_ebd &lt;- \"data/ebd_AU-QLD_shbcuc1_smp_relSep-2023.txt\"\nobservations &lt;- read_ebd(f_ebd, unique = FALSE, rollup = FALSE)\nglimpse(observations)\n#&gt; Rows: 23,250\n#&gt; Columns: 49\n#&gt; $ global_unique_identifier   &lt;chr&gt; \"URN:CornellLabOfOrnithology:EBIRD:OBS90068…\n#&gt; $ last_edited_date           &lt;chr&gt; \"2020-04-23 01:19:06\", \"2021-03-24 06:05:52…\n#&gt; $ taxonomic_order            &lt;dbl&gt; 3281, 3281, 3281, 3284, 3281, 3281, 3281, 3…\n#&gt; $ category                   &lt;chr&gt; \"species\", \"species\", \"species\", \"issf\", \"s…\n#&gt; $ taxon_concept_id           &lt;chr&gt; \"avibase-19268395\", \"avibase-19268395\", \"av…\n#&gt; $ common_name                &lt;chr&gt; \"Shining Bronze-Cuckoo\", \"Shining Bronze-Cu…\n#&gt; $ scientific_name            &lt;chr&gt; \"Chrysococcyx lucidus\", \"Chrysococcyx lucid…\n#&gt; $ subspecies_common_name     &lt;chr&gt; NA, NA, NA, \"Shining Bronze-Cuckoo (Shining…\n#&gt; $ subspecies_scientific_name &lt;chr&gt; NA, NA, NA, \"Chrysococcyx lucidus lucidus\",…\n#&gt; $ exotic_code                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ observation_count          &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"3\", \"2\", \"1\", \"1\"…\n#&gt; $ breeding_code              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ breeding_category          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ behavior_code              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ age_sex                    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ country                    &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\", \"Aus…\n#&gt; $ country_code               &lt;chr&gt; \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"…\n#&gt; $ state                      &lt;chr&gt; \"Queensland\", \"Queensland\", \"Queensland\", \"…\n#&gt; $ state_code                 &lt;chr&gt; \"AU-QLD\", \"AU-QLD\", \"AU-QLD\", \"AU-QLD\", \"AU…\n#&gt; $ county                     &lt;chr&gt; \"Mackay\", \"Moreton Bay\", \"Ipswich\", \"Sunshi…\n#&gt; $ county_code                &lt;chr&gt; \"AU-QLD-MAC\", \"AU-QLD-MRB\", \"AU-QLD-IPS\", \"…\n#&gt; $ iba_code                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ bcr_code                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ usfws_code                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ atlas_block                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ locality                   &lt;chr&gt; \"Finch Hatton Gorge\", \"Lake Samsonvale--Gol…\n#&gt; $ locality_id                &lt;chr&gt; \"L921597\", \"L692632\", \"L4784405\", \"L1827741…\n#&gt; $ locality_type              &lt;chr&gt; \"H\", \"H\", \"P\", \"H\", \"H\", \"H\", \"P\", \"H\", \"H\"…\n#&gt; $ latitude                   &lt;dbl&gt; -21.1, -27.3, -27.5, -26.6, -27.7, -27.3, -…\n#&gt; $ longitude                  &lt;dbl&gt; 149, 153, 153, 153, 153, 153, 153, 153, 153…\n#&gt; $ observation_date           &lt;date&gt; 2019-08-30, 2019-10-23, 2019-09-21, 2019-0…\n#&gt; $ time_observations_started  &lt;chr&gt; \"05:51:00\", \"05:09:00\", \"06:30:00\", \"09:41:…\n#&gt; $ observer_id                &lt;chr&gt; \"obsr1490162\", \"obsr277790\", \"obsr186524\", …\n#&gt; $ sampling_event_identifier  &lt;chr&gt; \"S67655665\", \"S61014875\", \"S59994086\", \"S53…\n#&gt; $ protocol_type              &lt;chr&gt; \"Stationary\", \"Traveling\", \"Traveling\", \"Tr…\n#&gt; $ protocol_code              &lt;chr&gt; \"P21\", \"P22\", \"P22\", \"P22\", \"P22\", \"P22\", \"…\n#&gt; $ project_code               &lt;chr&gt; \"EBIRD_AU\", \"EBIRD_AU\", \"EBIRD\", \"EBIRD\", \"…\n#&gt; $ duration_minutes           &lt;int&gt; 540, 361, 95, 61, 240, 115, 70, 85, 60, 141…\n#&gt; $ effort_distance_km         &lt;dbl&gt; NA, 5.240, 0.701, 2.000, 4.500, 1.000, 1.27…\n#&gt; $ effort_area_ha             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ number_observers           &lt;int&gt; 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 3, 1, 1, 4, 1…\n#&gt; $ all_species_reported       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n#&gt; $ group_identifier           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"G43416…\n#&gt; $ has_media                  &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n#&gt; $ approved                   &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n#&gt; $ reviewed                   &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n#&gt; $ reason                     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ trip_comments              &lt;chr&gt; \"Transferred from Daily Checklist.\", NA, NA…\n#&gt; $ species_comments           &lt;chr&gt; \"Heard.\", NA, NA, NA, NA, NA, \"1 immature.\"…\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nTake some time to explore the variables in the observation dataset. Notice that the EBD duplicates many of the checklist-level variables from the SED.\n\n\nWhen we read the data into R, we used unique = FALSE and rollup = FALSE. By default the read functions in auk perform two important pre-processing steps: combining duplicate shared checklists and taxonomic rollup. We intentionally turned off this functionality for the purposes of demonstration.\n\n1.1.2.1 Shared checklists\neBird allows users to share checklists with other eBirders in their group, for example this checklist is shared by 47 observers! These checklists can be identified by looking at the group_identifier variable, which assigns an ID connecting all checklists in the group.\n\nchecklists %&gt;% \n  filter(!is.na(group_identifier)) %&gt;% \n  arrange(group_identifier) %&gt;% \n  select(sampling_event_identifier, group_identifier)\n#&gt; # A tibble: 162,127 × 2\n#&gt;   sampling_event_identifier group_identifier\n#&gt;   &lt;chr&gt;                     &lt;chr&gt;           \n#&gt; 1 S133890080                G10005231       \n#&gt; 2 S133784377                G10005231       \n#&gt; 3 S133893592                G10005466       \n#&gt; 4 S133893590                G10005466       \n#&gt; 5 S133897212                G10005766       \n#&gt; 6 S133883873                G10005766       \n#&gt; # ℹ 162,121 more rows\n\nChecklists with the same group_identifier provide duplicate information on the same birding event in the eBird database. For most analyses, it’s important to collapse these shared checklists down into a single checklist. This can be accomplished with the function auk_unique(), which retains only one independent copy of each checklist.\n\nchecklists_unique &lt;- auk_unique(checklists, checklists_only = TRUE)\nnrow(checklists)\n#&gt; [1] 755445\nnrow(checklists_unique)\n#&gt; [1] 662253\n\nNotice that a new variable, checklist_id, was created that is set to group_identifier for shared checklists and sampling_event_identifier for non-shared checklists.\n\nhead(checklists_unique$checklist_id)\n#&gt; [1] \"S85875959\" \"S96568064\" \"S86299492\" \"S97805740\" \"S94758500\" \"S83599027\"\ntail(checklists_unique$checklist_id)\n#&gt; [1] \"G7637197\" \"G7638838\" \"G7638782\" \"G7638869\" \"G7641275\" \"G7641274\"\n\n\n\n\n\n\n\nTip\n\n\n\nCurious what checklists and observers contributed to a shared checklist after it has been collapsed? The sampling_event_identifier and observer_id contain comma-separated lists of all checklists and observers that went into the shared checklists.\n\nchecklists_unique %&gt;% \n  filter(checklist_id == \"G10638158\") %&gt;%\n  select(checklist_id, group_identifier, sampling_event_identifier, observer_id)\n#&gt; # A tibble: 1 × 4\n#&gt;   checklist_id group_identifier sampling_event_identifier            observer_id\n#&gt;   &lt;chr&gt;        &lt;chr&gt;            &lt;chr&gt;                                &lt;chr&gt;      \n#&gt; 1 G10638158    G10638158        S145972310,S145972882,S145973235,S1… obs1013108…\n\n\n\n\n\n1.1.2.2 Taxonomic rollup\neBird observations can be made at levels below species (e.g. subspecies) or above species (e.g. a bird that was identified as a duck, but the species could not be determined); however, for most uses we’ll want observations at the species level. This is especially true if we want to produce detection/non-detection data from complete checklists because “complete” only applies at the species level.\n\n\n\n\n\n\nTip\n\n\n\nIn the example dataset used for this workshop, these taxonomic issues don’t apply. We have requested Shining Bronze-Cuckoo observations, so we haven’t received any observations for taxa above species. However, there are records of Shining Bronze-Cuckoo (Shining) and Shining Bronze-Cuckoo (Golden) in Queensland during this time period (e.g., this checklist with photos. Accordingly, to use all records, we need to rollup these two subspecies into one set of species-level information. This can happen in many situations. For example, this checklist has 10 Yellow-rumped Warblers, 5 each of two Yellow-rumped Warbler subspecies, and one hybrid between the two subspecies. auk_rollup() will combine all four of these observations into a single Yellow-rumped Warbler observation.\n\n\nThe function auk_rollup() drops all observations not identifiable to a species and rolls up all observations reported below species to the species level.\n\nobservations_rollup &lt;- auk_rollup(observations)\n\n# only checklist example with both subspecies and one species-level entry\nobservations %&gt;% \n  filter(sampling_event_identifier == \"S102653162\") %&gt;%\n  select(sampling_event_identifier, common_name, subspecies_common_name, \n         observation_count)\n#&gt; # A tibble: 3 × 4\n#&gt;   sampling_event_identifier common_name subspecies_common_name observation_count\n#&gt;   &lt;chr&gt;                     &lt;chr&gt;       &lt;chr&gt;                  &lt;chr&gt;            \n#&gt; 1 S102653162                Shining Br… Shining Bronze-Cuckoo… 1                \n#&gt; 2 S102653162                Shining Br… &lt;NA&gt;                   2                \n#&gt; 3 S102653162                Shining Br… Shining Bronze-Cuckoo… 1\nobservations_rollup %&gt;% \n  filter(sampling_event_identifier == \"S102653162\") %&gt;%\n  select(sampling_event_identifier, common_name,\n         observation_count)\n#&gt; # A tibble: 1 × 3\n#&gt;   sampling_event_identifier common_name           observation_count\n#&gt;   &lt;chr&gt;                     &lt;chr&gt;                 &lt;chr&gt;            \n#&gt; 1 S102653162                Shining Bronze-Cuckoo 4\n\n\n\n\n\n\n\nTip\n\n\n\nIf multiple taxa on a single checklist roll up to the same species, auk_rollup() attempts to combine them intelligently. If each observation has a count, those counts are added together, but if any of the observations is missing a count (i.e. the count is “X”) the combined observation is also assigned an “X”. In the example checklist from the previous tip, with four taxa all rolling up to Yellow-rumped Warbler, auk_rollup() will add the four counts together to get 21 Yellow-rumped Warblers (10 + 5 + 5 + 1).\n\n\n\n\n\n1.1.3 Generating detection/non-detection data\nComplete eBird checklists are extremely valuable because, for all species that weren’t reported, we can infer counts of 0. This allows us to convert eBird from presence only data to detection/non-detection data, which allows for much more robust analyses. Note that we don’t use the term presence/absence data here because a non-detection doesn’t necessarily imply the species was absent, only that the observer didn’t detect and identify it.\nWe refer to the process of producing detection/non-detection data as “zero-filling” the eBird data because we’re filling in the missing zeros. We’ll read the eBird data into R again, filter to only complete checklists, then use the function auk_zerofill() to generate detection/non-detection data. Note that shared checklists are combined and taxonomic rollup is performed by default when using the read_*() functions from auk.\n\n# import checklist data\nchecklists &lt;- read_sampling(f_sed) %&gt;% \n  # subset to complete checklists\n  filter(all_species_reported)\n# import observation data\nobservations &lt;- read_ebd(f_ebd) %&gt;% \n  # subset to complete checklists\n  filter(all_species_reported)\n# zero-fill to produce detection/non-detection data\nzf &lt;- auk_zerofill(observations, checklists, collapse = TRUE)\nglimpse(zf)\n#&gt; Rows: 509,294\n#&gt; Columns: 38\n#&gt; $ checklist_id              &lt;chr&gt; \"S85875959\", \"S96568064\", \"S86299492\", \"S978…\n#&gt; $ last_edited_date          &lt;chr&gt; \"2021-04-19 02:40:19.157994\", \"2021-10-22 20…\n#&gt; $ country                   &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\", \"Aust…\n#&gt; $ country_code              &lt;chr&gt; \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"A…\n#&gt; $ state                     &lt;chr&gt; \"Queensland\", \"Queensland\", \"Queensland\", \"Q…\n#&gt; $ state_code                &lt;chr&gt; \"AU-QLD\", \"AU-QLD\", \"AU-QLD\", \"AU-QLD\", \"AU-…\n#&gt; $ county                    &lt;chr&gt; \"Brisbane\", \"Brisbane\", \"Brisbane\", \"Brisban…\n#&gt; $ county_code               &lt;chr&gt; \"AU-QLD-BRI\", \"AU-QLD-BRI\", \"AU-QLD-BRI\", \"A…\n#&gt; $ iba_code                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ bcr_code                  &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ usfws_code                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ atlas_block               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ locality                  &lt;chr&gt; \"Dowse Lagoon (Sandgate)\", \"Dowse Lagoon (Sa…\n#&gt; $ locality_id               &lt;chr&gt; \"L1896576\", \"L1896576\", \"L1896576\", \"L189657…\n#&gt; $ locality_type             &lt;chr&gt; \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\", \"H\",…\n#&gt; $ latitude                  &lt;dbl&gt; -27.3, -27.3, -27.3, -27.3, -27.3, -27.3, -2…\n#&gt; $ longitude                 &lt;dbl&gt; 153, 153, 153, 153, 153, 153, 153, 153, 153,…\n#&gt; $ observation_date          &lt;date&gt; 2021-04-19, 2021-10-23, 2021-04-25, 2021-11…\n#&gt; $ time_observations_started &lt;chr&gt; \"15:40:00\", \"06:04:00\", \"12:25:00\", \"13:53:0…\n#&gt; $ observer_id               &lt;chr&gt; \"obs427309\", \"obs427309\", \"obs535737\", \"obs9…\n#&gt; $ sampling_event_identifier &lt;chr&gt; \"S85875959\", \"S96568064\", \"S86299492\", \"S978…\n#&gt; $ protocol_type             &lt;chr&gt; \"Traveling\", \"Traveling\", \"Stationary\", \"Tra…\n#&gt; $ protocol_code             &lt;chr&gt; \"P22\", \"P22\", \"P21\", \"P22\", \"P22\", \"P21\", \"P…\n#&gt; $ project_code              &lt;chr&gt; \"EBIRD\", \"EBIRD\", \"EBIRD\", \"EBIRD\", \"EBIRD_A…\n#&gt; $ duration_minutes          &lt;int&gt; 59, 138, 33, 46, 75, 16, 67, 104, 28, 45, 80…\n#&gt; $ effort_distance_km        &lt;dbl&gt; 1.954, 3.437, NA, 1.610, 1.030, NA, 1.310, 2…\n#&gt; $ effort_area_ha            &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ number_observers          &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ all_species_reported      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n#&gt; $ group_identifier          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ trip_comments             &lt;chr&gt; NA, NA, NA, \"Clear skies light breeze. Targe…\n#&gt; $ scientific_name           &lt;chr&gt; \"Chrysococcyx lucidus\", \"Chrysococcyx lucidu…\n#&gt; $ breeding_code             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ breeding_category         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ behavior_code             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ age_sex                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ observation_count         &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\",…\n#&gt; $ species_observed          &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n\nThe observation_count variable has true counts as well as “X”s, which indicate that the species was detected but the number of individuals was not counted. auk_zerofill() adds a new binary column, species_observed, indicating whether or not the species was detected.\n\nselect(zf, observation_count, species_observed) %&gt;% \n  head(10)\n#&gt; # A tibble: 10 × 2\n#&gt;   observation_count species_observed\n#&gt;   &lt;chr&gt;             &lt;lgl&gt;           \n#&gt; 1 0                 FALSE           \n#&gt; 2 0                 FALSE           \n#&gt; 3 0                 FALSE           \n#&gt; 4 0                 FALSE           \n#&gt; 5 0                 FALSE           \n#&gt; 6 0                 FALSE           \n#&gt; # ℹ 4 more rows\n\nLet’s convert the “X”s to NAs and transform observation_count to an integer variable.\n\nzf$observation_count &lt;- if_else(zf$observation_count == \"X\", \n                                NA_character_, zf$observation_count) %&gt;% \n  as.integer()\nselect(zf, observation_count, species_observed) %&gt;% \n  head(10)\n#&gt; # A tibble: 10 × 2\n#&gt;   observation_count species_observed\n#&gt;               &lt;int&gt; &lt;lgl&gt;           \n#&gt; 1                 0 FALSE           \n#&gt; 2                 0 FALSE           \n#&gt; 3                 0 FALSE           \n#&gt; 4                 0 FALSE           \n#&gt; 5                 0 FALSE           \n#&gt; 6                 0 FALSE           \n#&gt; # ℹ 4 more rows\n\n\n\n1.1.4 Filtering data\nNow that you have a detection/non-detection dataset, it’s likely that you want to do something with it. For example, you may want to make a map, identify priority areas for a species, or train a species distribution model. Regardless of the specific application, it’s likely that some amount of filtering of the data is required first. Some of the ways you may want to filter eBird data include:\n\nTemporal filtering: filter the data to a specific range of years or to a specific time of year.\nSpatial filtering: filter the data to focus on a specific region, e.g. a protected area.\nIncreasing precision: some eBird checklists are quite long in distance or duration leading to spatial or temporal imprecision. By removing longer checklists we can increase the spatial precision of the dataset.\nReducing variation in effort: unlike structured scientific surveys, data can be submitted to eBird using a variety of protocols and there is significant variation in effort between checklists in the eBird dataset. Variation in protocol and effort leads to variation in detectability (more effort generally leads to higher detectability). We can choose to impose more structure on the eBird dataset by filtering to reduce variation in protocol and effort.\n\nThe specific filtering you apply will depend on how you intend to use the eBird data. However, for the sake of this example, let’s filter the eBird data to only traveling and stationary checklists from 2013-2022 that are less than 6 hours in duration and 10 km in length.\n\nzf_filtered &lt;- zf %&gt;% \n  filter(year(observation_date) &gt;= 2013, year(observation_date) &lt;= 2022,\n         protocol_type %in% c(\"Traveling\", \"Stationary\"),\n         duration_minutes &lt; 6 * 60,\n         effort_distance_km &lt; 10 | protocol_type == \"Stationary\")\nnrow(zf)\n#&gt; [1] 509294\nnrow(zf_filtered)\n#&gt; [1] 342881\n\nWe reduced the number of checklists by 166,413, but the checklists remaining are of higher quality.\n\n\n1.1.5 Environmental Covariate Assignment\nAt this point, if you were planning to run a species distribution model with this data, you’d want some environmental variables as predictors. However, adding environmental variables can be onerous, computationally expensive, and varies based on use case. We provide guidance in our “Best Practices for Using eBird Data” document on extracting environmental variables to use with eBird data. For continuing this work on your own, please use that reference. For the remainder of this workshop, we’re going to skip this process and use the eBird Reference Dataset (ERD) that already contains the environmental variables used in for eBird Status and Trends modeling."
  },
  {
    "objectID": "ebird.html#sec-ebird-erd",
    "href": "ebird.html#sec-ebird-erd",
    "title": "1  eBird Data",
    "section": "1.2 eBird Reference Dataset (ERD)",
    "text": "1.2 eBird Reference Dataset (ERD)\nThe eBird Reference Dataset (ERD) is a subset of the full eBird database created annually for eBird Status and Trends modeling. Only semi-structured (complete checklists with effort information) traveling and stationary counts from the last 15 years are included in the ERD and we assign a set of environmental variables assigned to checklist. In the following sections we’ll provide an introduction to the ERD, describe the associated prediction grid used to make predictions across space, and highlight some of the challenges associated with using eBird data for analysis.\nThe ERD is distributed in two parts: observation data and checklist data. In the observation dataset, each row corresponds to the sighting of a single species on a checklist, including the count and any other species-level information. In the checklist dataset, each row corresponds to a checklist, including the date, time, location, effort (e.g. distance traveled, time spent, etc.), and any additional checklist-level information.\nFor this workshop, and extract of the ERD is provided in the workshop data package. The observations and checklsits datasets are provided in parquet format, an open source standard for efficient storage and retrieval of tabular data. If you haven’t already done so, following the instructions in the Introduction to create an RStudio project and download the workshop data package. The parquet files should be located at:\ndata/ebird_observations_AU-QLD.parquet\ndata/ebird_checklists_AU-QLD.parquet\nLet’s start by reading these two datasets into R using the arrow package and exploring them. We’ll start with the checklist dataset.\n\nlibrary(arrow)\nlibrary(auk)\nlibrary(dplyr)\nlibrary(ebirdst)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(terra)\n\nchecklists &lt;- read_parquet(\"data/ebird_checklists_AU-QLD_2022.parquet\")\nglimpse(checklists)\n#&gt; Rows: 357,213\n#&gt; Columns: 151\n#&gt; $ checklist_id                       &lt;int&gt; 10864617, 11307779, 6971840, 102635…\n#&gt; $ observer_id                        &lt;int&gt; 267451, 113983, 162908, 113983, 166…\n#&gt; $ loc_id                             &lt;chr&gt; \"L1560273\", \"L1650808\", \"H2561832\",…\n#&gt; $ longitude                          &lt;dbl&gt; 153, 150, 139, 153, 145, 145, 152, …\n#&gt; $ latitude                           &lt;dbl&gt; -26.7, -28.5, -19.0, -27.2, -16.7, …\n#&gt; $ year                               &lt;dbl&gt; 2012, 2012, 2008, 2012, 2011, 2011,…\n#&gt; $ day_of_year                        &lt;dbl&gt; 128, 212, 180, 85, 284, 283, 34, 31…\n#&gt; $ hours_of_day                       &lt;dbl&gt; 11.65, 10.00, 6.75, 11.42, 15.42, 1…\n#&gt; $ solar_noon_diff                    &lt;dbl&gt; -0.0376, -2.0229, -2.0756, -0.3446,…\n#&gt; $ is_stationary                      &lt;lgl&gt; TRUE, FALSE, FALSE, TRUE, FALSE, FA…\n#&gt; $ effort_hrs                         &lt;dbl&gt; 0.167, 0.167, 8.000, 0.333, 0.583, …\n#&gt; $ effort_distance_km                 &lt;dbl&gt; 0.000, 2.000, 5.000, 0.000, 1.500, …\n#&gt; $ effort_speed_kmph                  &lt;dbl&gt; 0.000, 11.976, 0.625, 0.000, 2.573,…\n#&gt; $ num_observers                      &lt;int&gt; 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1,…\n#&gt; $ moon_fraction                      &lt;dbl&gt; 0.9874, 0.8842, 0.3158, 0.0594, 0.9…\n#&gt; $ moon_altitude                      &lt;dbl&gt; -0.7028, -0.6658, 0.6386, 0.6711, -…\n#&gt; $ cds_u10                            &lt;dbl&gt; -0.1342, 1.9947, -5.1339, -3.9891, …\n#&gt; $ cds_v10                            &lt;dbl&gt; -0.7690, 2.7611, 0.5347, 2.1257, -0…\n#&gt; $ cds_d2m                            &lt;dbl&gt; 8.580, 4.629, 8.287, 15.854, 11.582…\n#&gt; $ cds_t2m                            &lt;dbl&gt; 23.02, 8.29, 24.84, 23.38, 34.93, 3…\n#&gt; $ cds_hcc                            &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, …\n#&gt; $ cds_i10fg                          &lt;dbl&gt; 4.03, 8.04, 9.83, 10.01, 9.44, 8.83…\n#&gt; $ cds_mcc                            &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.695…\n#&gt; $ cds_lcc                            &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.7405, 0.0…\n#&gt; $ cds_sf                             &lt;dbl&gt; 8.67e-19, 0.00e+00, 0.00e+00, 0.00e…\n#&gt; $ cds_rf                             &lt;dbl&gt; 6.07e-18, 0.00e+00, 0.00e+00, 2.95e…\n#&gt; $ cds_slc                            &lt;dbl&gt; -133.21, -11.49, -12.35, -25.82, -1…\n#&gt; $ cds_msl                            &lt;dbl&gt; 101650, 102426, 101786, 101845, 100…\n#&gt; $ eastness_1km_median                &lt;dbl&gt; 3.61e-02, 8.04e-08, 4.35e-02, 1.12e…\n#&gt; $ eastness_1km_sd                    &lt;dbl&gt; 0.23578, 0.03816, 0.20141, 0.25066,…\n#&gt; $ eastness_90m_median                &lt;dbl&gt; 7.59e-02, -2.76e-04, 1.51e-03, 2.74…\n#&gt; $ eastness_90m_sd                    &lt;dbl&gt; 0.16464, 0.00216, 0.02724, 0.06283,…\n#&gt; $ northness_1km_median               &lt;dbl&gt; -7.84e-03, 7.70e-02, -6.40e-02, 5.0…\n#&gt; $ northness_1km_sd                   &lt;dbl&gt; 0.0950, 0.0705, 0.2609, 0.1821, 0.3…\n#&gt; $ northness_90m_median               &lt;dbl&gt; -0.007993, 0.000385, -0.001088, -0.…\n#&gt; $ northness_90m_sd                   &lt;dbl&gt; 0.13644, 0.00182, 0.01958, 0.05712,…\n#&gt; $ elevation_250m_median              &lt;dbl&gt; 317.450, 218.982, 143.838, 64.140, …\n#&gt; $ elevation_250m_sd                  &lt;dbl&gt; 47.518, 0.878, 6.444, 18.788, 10.73…\n#&gt; $ elevation_30m_median               &lt;dbl&gt; 314.7, 217.5, 140.8, 54.8, 394.3, 3…\n#&gt; $ elevation_30m_sd                   &lt;dbl&gt; 55.56, 5.03, 9.73, 24.47, 13.24, 13…\n#&gt; $ island                             &lt;dbl&gt; 30005, 30005, 30005, 30005, 30005, …\n#&gt; $ astwbd_c1_ed                       &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ astwbd_c1_pland                    &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …\n#&gt; $ astwbd_c2_ed                       &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, …\n#&gt; $ astwbd_c2_pland                    &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, …\n#&gt; $ astwbd_c3_ed                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ astwbd_c3_pland                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ gsw_c2_pland                       &lt;dbl&gt; 0.00000, 0.95312, 0.31391, 0.02483,…\n#&gt; $ gsw_c2_ed                          &lt;dbl&gt; 0.000, 10.504, 3.197, 0.550, 0.184,…\n#&gt; $ gsw_c3_pland                       &lt;dbl&gt; 0.00000, 0.19215, 0.12675, 0.00993,…\n#&gt; $ gsw_c3_ed                          &lt;dbl&gt; 0.00, 3.01, 1.58, 0.22, 0.00, 0.00,…\n#&gt; $ intertidal_c1_ed                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ intertidal_c1_pland                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ ntl_mean                           &lt;dbl&gt; 0.0000, 7.1068, 0.0000, 0.2118, 0.2…\n#&gt; $ ntl_sd                             &lt;dbl&gt; 0.0000, 5.4641, 0.0000, 0.3992, 0.4…\n#&gt; $ road_density_c1                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ road_density_c2                    &lt;dbl&gt; 0, 681, 0, 545, 422, 422, 0, 0, 0, …\n#&gt; $ road_density_c3                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ road_density_c4                    &lt;dbl&gt; 410, 321, 631, 0, 80, 80, 287, 287,…\n#&gt; $ road_density_c5                    &lt;dbl&gt; 0, 0, 0, 766, 0, 0, 0, 0, 0, 0, 0, …\n#&gt; $ mcd12q1_lccs1_c1_ed                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c1_pland             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c2_ed                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c2_pland             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c11_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c11_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c12_ed               &lt;dbl&gt; 9.50, 0.00, 0.00, 1.69, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs1_c12_pland            &lt;dbl&gt; 53.60, 0.00, 0.00, 1.00, 0.00, 0.00…\n#&gt; $ mcd12q1_lccs1_c13_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c13_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c14_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c14_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c15_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c15_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c16_ed               &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 1.76, 1.76,…\n#&gt; $ mcd12q1_lccs1_c16_pland            &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 3.001, …\n#&gt; $ mcd12q1_lccs1_c21_ed               &lt;dbl&gt; 11.66, 0.00, 0.00, 5.08, 0.00, 0.00…\n#&gt; $ mcd12q1_lccs1_c21_pland            &lt;dbl&gt; 43.72, 0.00, 0.00, 9.40, 0.00, 0.00…\n#&gt; $ mcd12q1_lccs1_c22_ed               &lt;dbl&gt; 2.158, 6.516, 0.899, 9.734, 4.405, …\n#&gt; $ mcd12q1_lccs1_c22_pland            &lt;dbl&gt; 2.678, 41.444, 0.776, 76.168, 90.99…\n#&gt; $ mcd12q1_lccs1_c31_ed               &lt;dbl&gt; 0.00, 6.52, 7.64, 4.66, 2.64, 2.64,…\n#&gt; $ mcd12q1_lccs1_c31_pland            &lt;dbl&gt; 0.00, 58.56, 32.62, 13.43, 6.00, 6.…\n#&gt; $ mcd12q1_lccs1_c32_ed               &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs1_c32_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c41_ed               &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs1_c41_pland            &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 24.9,…\n#&gt; $ mcd12q1_lccs1_c42_ed               &lt;dbl&gt; 0.0, 0.0, 4.5, 0.0, 0.0, 0.0, 14.7,…\n#&gt; $ mcd12q1_lccs1_c42_pland            &lt;dbl&gt; 0.00, 0.00, 9.01, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs1_c43_ed               &lt;dbl&gt; 0.0, 0.0, 10.3, 0.0, 0.0, 0.0, 0.0,…\n#&gt; $ mcd12q1_lccs1_c43_pland            &lt;dbl&gt; 0.0, 0.0, 57.6, 0.0, 0.0, 0.0, 0.0,…\n#&gt; $ mcd12q1_lccs1_c255_ed              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c255_pland           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c25_ed               &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …\n#&gt; $ mcd12q1_lccs2_c25_pland            &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …\n#&gt; $ mcd12q1_lccs2_c35_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c35_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c36_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c36_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs3_c27_ed               &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs3_c27_pland            &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs3_c50_ed               &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs3_c50_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs3_c51_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs3_c51_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ has_shoreline                      &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, …\n#&gt; $ shoreline_waveheight_mean          &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, …\n#&gt; $ shoreline_waveheight_sd            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_tidal_range_mean         &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ shoreline_tidal_range_sd           &lt;dbl&gt; 0.00000, 0.00000, 0.00000, 0.00000,…\n#&gt; $ shoreline_chlorophyll_mean         &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ shoreline_chlorophyll_sd           &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0…\n#&gt; $ shoreline_turbidity_mean           &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.000, …\n#&gt; $ shoreline_turbidity_sd             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_sinuosity_mean           &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ shoreline_sinuosity_sd             &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ shoreline_slope_mean               &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ shoreline_slope_sd                 &lt;dbl&gt; 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,…\n#&gt; $ shoreline_outflow_density_mean     &lt;dbl&gt; 0.00e+00, 0.00e+00, 0.00e+00, 0.00e…\n#&gt; $ shoreline_outflow_density_sd       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_n            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c1_density   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c2_density   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c3_density   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c4_density   &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …\n#&gt; $ shoreline_emu_physical_n           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c1_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c2_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c3_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c4_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c5_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c6_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c7_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c8_density  &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, …\n#&gt; $ shoreline_emu_physical_c9_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c10_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c11_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c12_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c13_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c14_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c15_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c16_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c17_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c18_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c19_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c20_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c21_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c22_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c23_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ has_evi                            &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,…\n#&gt; $ evi_median                         &lt;dbl&gt; 56375768, 26577095, 16683584, 49761…\n#&gt; $ evi_sd                             &lt;dbl&gt; 4978114, 6436081, 5444980, 6107690,…\n\nThere are a huge number of columns in this data frame. The first set of variables provide standard information about the checklist: where and when did the observation occur, what type of search was conducted, and how much search effort was expended. Two important differences exist between these variables and what you will see if you look at the raw eBird dataset: when a GPS track is available we replace the checklist or hotspot location (latitude/longitude) with the centroid of the track and the time of the checklist is expressed as the difference between the checklist midpoint and solar noon, a more ecologically meaningful quantity.\nAll the remaining variables are not collected in eBird, they’re calculated and added by the Status and Trends team based on external data sets. First, those variables beginning with cds_, provides information about the weather at the time of the observation, which can impact detectibility. This is followed by a large suite of environmental variables summarized over a 3km diameter circular neighborhood around the checklist location, including variables describing: elevation and topography, land and water cover, roads, and night time lights (a proxy for urban development). Most variables are summarized as two quantities expressing composition (what habitat is available) and configuration (how that habitat is arranged spatially). For continuous variables, such as elevation, we use the median and standard deviation. For categorical variables, such as land cover class, we use percent landcover (pland) and edge density (ed).\n\n\n\nExample of calculating percent land cover and edge density for a 3km diamter circular neighborhood centered on a checklist location. pland for each class is the percent of the circle covered by that class. To calculate ed for each class, we add up the perimeter lengths of all patches of that class, then divide by the area of the circle.\n\n\nThe land and water cover variables can be challenging to interpret based on their names alone (e.g. mcd12q1_lccs1_c12_pland); however, these names can be looked up in the ebirdst_predictors data frame from the ebirdst package. For example, let’s look up what mcd12q1_lccs1_c12_pland corresponds to.\n\nfilter(ebirdst_predictors, predictor == \"mcd12q1_lccs1_c12_pland\") %&gt;% \n  select(predictor, label)\n#&gt; # A tibble: 1 × 2\n#&gt;   predictor               label                                \n#&gt;   &lt;chr&gt;                   &lt;chr&gt;                                \n#&gt; 1 mcd12q1_lccs1_c12_pland Evergreen Broadleaf Forests (% cover)\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nTake some time to explore the variables in the checklist dataset. Try looking up a variable in ebirdst_predictors. Ask for help if you need clarification on the meaning of any of the variables.\n\n\nNow let’s look at the observation dataset.\n\nobservations &lt;- read_parquet(\"data/ebird_observations_AU-QLD_2022.parquet\")\nglimpse(observations)\n#&gt; Rows: 7,292,576\n#&gt; Columns: 5\n#&gt; $ checklist_id &lt;dbl&gt; 10928575, 10928575, 10928575, 10928575, 10928575, 1092857…\n#&gt; $ species_code &lt;chr&gt; \"rensti\", \"faecur\", \"grsplo\", \"strher\", \"cursan\", \"batgod…\n#&gt; $ valid        &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n#&gt; $ obs_detected &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n#&gt; $ obs_count    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\nThis is a much simpler dataset with only five columns:\n\nchecklist_id: unique identifier for the checklist that this observation belongs to. Allows joining the observation data to the checklist data.\nspecies_code: unique identifier for the species that this observation was made for.\nvalid: a binary variable indicating is the observation was determined to be valid (TRUE) or invalid (FALSE) by the eBird reviewers.\nobs_detected: a binary variable indicating if the species was detected (1) or not detected (0). Since this is a dataset of observations only, obs_detected is always 1; however, having this variable will become useful when we join to the checklist dataset in the next section.\nobs_count: count of the number of individuals or an NA if no count was provided (if an “X” was entered for count on the eBird checklist).\n\n\n\n\n\n\n\nTip\n\n\n\nTo look up the common name or scientific name of a species try appending the species code to the URL https://ebird.org/species/. For example, visit https://ebird.org/species/maslap1 to look up the species code maslap1. This information is also available in the ebird_taxonomy data frame in the auk package.\n\nfilter(ebird_taxonomy, species_code == \"maslap1\") %&gt;% \n  select(species_code, common_name, scientific_name, family)\n#&gt;   species_code    common_name scientific_name       family\n#&gt; 1      maslap1 Masked Lapwing  Vanellus miles Charadriidae\n\n\n\n\n1.2.1 Zero-filling eBird data\nComplete eBird checklists are extremely valuable because, for all species that weren’t reported, we can infer counts of 0. This allows us to convert eBird from presence only data to detection/non-detection data, which allows for much more robust analyses. Note that we don’t use the term presence/absence data here because a non-detection doesn’t necessarily imply the species was absent, only that observer wasn’t able to detect and identify it.\nWe refer to the process of producing detection/non-detection data as “zero-filling” the eBird data because we’re filling in the missing zeros. Let’s consider observations of Shining Bronze-Cuckoo (species code shbcuc1).\n\nbird_detections &lt;- observations %&gt;% \n  filter(species_code == \"shbcuc1\") %&gt;% \n  select(checklist_id, valid, obs_detected, obs_count)\n\nNext join this set of detections to the complete set of checklists, including detections and non-detections.\n\nbird_all &lt;- left_join(checklists, bird_detections, by = \"checklist_id\") %&gt;%\n  select(checklist_id, latitude, longitude, year, day_of_year,\n         valid, obs_detected, obs_count)\nhead(bird_all)\n#&gt; # A tibble: 6 × 8\n#&gt;   checklist_id latitude longitude  year day_of_year valid obs_detected obs_count\n#&gt;          &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;lgl&gt;        &lt;int&gt;     &lt;int&gt;\n#&gt; 1     10864617    -26.7      153.  2012         128 NA              NA        NA\n#&gt; 2     11307779    -28.5      150.  2012         212 NA              NA        NA\n#&gt; 3      6971840    -19.0      139.  2008         180 NA              NA        NA\n#&gt; 4     10263519    -27.2      153.  2012          85 TRUE             1         1\n#&gt; 5      9020044    -16.7      145.  2011         284 NA              NA        NA\n#&gt; 6      9009843    -16.7      145.  2011         283 NA              NA        NA\n\nFinally, for rows where the bird was not detected we can replace the missing counts with 0. At this time, we recommend removing any checklists with valid == 0 because there is uncertainty about whether or not the species was detected. Let’s also filter to a subset of months, to keep the data smaller and relevant to a particular season.\n\nbird_zf &lt;- bird_all %&gt;% \n  filter(is.na(valid) | valid == 1) %&gt;% \n  mutate(\n    # checklist not in the observations dataset are non-detections\n    obs_detected = coalesce(obs_detected, 0L),\n    # non-detections correspond to a count of 0\n    obs_count = if_else(obs_detected == 1, obs_count, 0)\n  ) %&gt;%\n  # approximately november through january\n  filter(day_of_year &gt;= 305 | day_of_year &lt; 32)\n\nWe can now, for example, make a map of observations. We’ll use spatial data that was prepared in advance and provided in the data package.\n\n# load and project gis data\nmap_proj &lt;- \"+proj=laea +lon_0=146.95 +lat_0=-19.15 +datum=WGS84 +units=m +no_defs\"\nne_land &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_land\") %&gt;% \n  st_transform(crs = map_proj) %&gt;% \n  st_geometry()\nne_country_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_country_lines\") %&gt;% \n  st_transform(crs = map_proj) %&gt;% \n  st_geometry()\nne_state_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_state_lines\") %&gt;% \n  st_transform(crs = map_proj) %&gt;% \n  st_geometry()\ntarget_state &lt;- read_sf(\"data/gis-data.gpkg\", \"regions\") %&gt;% \n  filter(state_code == \"AU-QLD\") %&gt;% \n  st_transform(crs = map_proj) %&gt;% \n  st_geometry()\n\n# prepare ebird data for mapping\nbird_sf &lt;- bird_zf %&gt;% \n  # convert to spatial points\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  st_transform(crs = map_proj)\n\n# map\npar(mar = c(0.25, 0.25, 0.25, 0.25))\n# set up plot area\nplot(st_geometry(target_state), col = NA, border = NA)\n# contextual gis data\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\nplot(target_state, col = \"#e6e6e6\", border = NA, add = TRUE)\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\n# ebird observations\n# all\nplot(bird_sf,\n     pch = 19, cex = 0.1, col = scales::alpha(\"#555555\", 4),\n     add = TRUE)\n# detection\nplot(filter(bird_sf, obs_detected == 1),\n     pch = 19, cex = 0.3, col = scales::alpha(\"#4daf4a\", 1),\n     add = TRUE)\n# legend\nlegend(\"bottomright\", bty = \"n\",\n       col = c(\"#555555\", \"#4daf4a\"),\n       legend = c(\"eBird checklists\", \"Bird sightings\"),\n       pch = 19)\nbox()\npar(new = TRUE, mar = c(0, 0, 3, 0))\ntitle(\"Shining Bronze-Cuckoo eBird Observations\\nNovember-January 2007-2022\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry producing zero-filled, detection/non-detection data for another species.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFor example, to produce detection/non-detection data for Masked Lapwing use:\n\nsp_zf &lt;- observations %&gt;% \n  filter(species_code == \"maslap1\") %&gt;% \n  left_join(checklists, ., by = \"checklist_id\") %&gt;% \n  filter(is.na(valid) | valid == 1) %&gt;% \n  mutate(obs_detected = coalesce(obs_detected, 0),\n         obs_count = if_else(obs_detected == 1, obs_count, 0)) %&gt;% \n  select(checklist_id, obs_detected, obs_count)\nhead(sp_zf)\n#&gt; # A tibble: 6 × 3\n#&gt;   checklist_id obs_detected obs_count\n#&gt;          &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n#&gt; 1     10864617            0         0\n#&gt; 2     11307779            1         2\n#&gt; 3      6971840            0         0\n#&gt; 4     10263519            0         0\n#&gt; 5      9020044            0         0\n#&gt; 6      9009843            0         0\n\n\n\n\n\n\n1.2.2 Prediction grid\nThe ultimate goal of modeling the occurrence or abundance of a species is frequently to produce a map showing the distribution of that species in space. To do so, we need to know the values of our predictor variables over the region that we intend to make predictions. To make this possible, the ERD is distributed with a prediction grid: a regular grid of points covering the entire globe spaced 3km apart for which all the environmental variables have been calculated for the year 2022.\nThe data package for this course contains an example subset of the prediction grid. The file data/prediction-grid_year_AU-QLD.parquet contains the environmental variables for each point on the grid and the file data/prediction-grid_template.tif is a 3km by 3km raster template where each each cell center is a point on the prediction grid. Let’s start by examining the environmental variables.\n\nprediction_grid &lt;- read_parquet(\"data/prediction-grid_year_AU-QLD_2022.parquet\")\nglimpse(prediction_grid)\n#&gt; Rows: 230,422\n#&gt; Columns: 123\n#&gt; $ srd_id                             &lt;int&gt; 50299954, 50299955, 50299956, 50299…\n#&gt; $ longitude                          &lt;dbl&gt; 142, 142, 142, 142, 142, 142, 142, …\n#&gt; $ latitude                           &lt;dbl&gt; -9.19, -9.19, -9.19, -9.19, -9.19, …\n#&gt; $ eastness_1km_median                &lt;dbl&gt; -8.11e-03, -9.89e-03, 4.66e-02, 3.1…\n#&gt; $ eastness_1km_sd                    &lt;dbl&gt; 0.0875, 0.1937, 0.1585, 0.1373, 0.1…\n#&gt; $ eastness_90m_median                &lt;dbl&gt; 6.06e-04, 5.23e-05, 1.53e-04, -2.61…\n#&gt; $ eastness_90m_sd                    &lt;dbl&gt; 0.00474, 0.00407, 0.00657, 0.01536,…\n#&gt; $ northness_1km_median               &lt;dbl&gt; -6.06e-02, 1.53e-01, 7.75e-02, -5.6…\n#&gt; $ northness_1km_sd                   &lt;dbl&gt; 0.3412, 0.1793, 0.2380, 0.1677, 0.3…\n#&gt; $ northness_90m_median               &lt;dbl&gt; -0.001320, -0.000886, 0.000655, 0.0…\n#&gt; $ northness_90m_sd                   &lt;dbl&gt; 0.01242, 0.01134, 0.01204, 0.01721,…\n#&gt; $ elevation_250m_median              &lt;dbl&gt; 14.513, 13.969, 14.086, 0.174, 13.9…\n#&gt; $ elevation_250m_sd                  &lt;dbl&gt; 2.67, 3.22, 3.96, 7.31, 5.04, 5.78,…\n#&gt; $ elevation_30m_median               &lt;dbl&gt; 14.1, 13.3, 12.2, 13.1, 14.4, 17.5,…\n#&gt; $ elevation_30m_sd                   &lt;dbl&gt; 5.06, 5.09, 4.50, 4.40, 5.30, 5.22,…\n#&gt; $ island                             &lt;dbl&gt; 392, 392, 392, 392, 1067, 1067, 106…\n#&gt; $ astwbd_c1_ed                       &lt;dbl&gt; 2.26, 2.26, 5.95, 5.95, 9.26, 14.02…\n#&gt; $ astwbd_c1_pland                    &lt;dbl&gt; 2.20, 1.21, 11.17, 81.91, 42.20, 37…\n#&gt; $ astwbd_c2_ed                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ astwbd_c2_pland                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ astwbd_c3_ed                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ astwbd_c3_pland                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ gsw_c2_pland                       &lt;dbl&gt; 0.823, 6.787, 8.823, 7.259, 1.704, …\n#&gt; $ gsw_c2_ed                          &lt;dbl&gt; 5.27, 18.01, 16.18, 11.68, 14.06, 2…\n#&gt; $ gsw_c3_pland                       &lt;dbl&gt; 1.8037, 0.5269, 11.5355, 81.5255, 3…\n#&gt; $ gsw_c3_ed                          &lt;dbl&gt; 2.228, 1.398, 5.633, 5.833, 9.295, …\n#&gt; $ intertidal_c1_ed                   &lt;dbl&gt; 2.24, 2.16, 6.65, 16.81, 13.13, 7.9…\n#&gt; $ intertidal_c1_pland                &lt;dbl&gt; 2.37, 1.06, 12.20, 19.01, 10.81, 18…\n#&gt; $ ntl_mean                           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ ntl_sd                             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ road_density_c1                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ road_density_c2                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ road_density_c3                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ road_density_c4                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ road_density_c5                    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c1_ed                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c1_pland             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c2_ed                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c2_pland             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c11_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c11_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c12_ed               &lt;dbl&gt; 7.338, 10.131, 8.094, 3.083, 8.544,…\n#&gt; $ mcd12q1_lccs1_c12_pland            &lt;dbl&gt; 17.695, 36.156, 44.618, 4.919, 26.6…\n#&gt; $ mcd12q1_lccs1_c13_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c13_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c14_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c14_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c15_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c15_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c16_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c16_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c21_ed               &lt;dbl&gt; 12.52, 13.21, 16.19, 7.49, 13.94, 1…\n#&gt; $ mcd12q1_lccs1_c21_pland            &lt;dbl&gt; 68.50, 28.15, 40.24, 19.06, 33.23, …\n#&gt; $ mcd12q1_lccs1_c22_ed               &lt;dbl&gt; 2.16, 7.05, 3.15, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs1_c22_pland            &lt;dbl&gt; 3.10, 18.50, 6.22, 0.00, 0.00, 0.00…\n#&gt; $ mcd12q1_lccs1_c31_ed               &lt;dbl&gt; 4.75, 6.61, 2.70, 0.00, 0.00, 0.00,…\n#&gt; $ mcd12q1_lccs1_c31_pland            &lt;dbl&gt; 10.64, 17.13, 1.36, 0.00, 0.00, 0.0…\n#&gt; $ mcd12q1_lccs1_c32_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c32_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c41_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c41_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c42_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c42_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c43_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c43_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c255_ed              &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs1_c255_pland           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c25_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c25_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c35_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c35_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c36_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs2_c36_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs3_c27_ed               &lt;dbl&gt; 3.89, 4.85, 7.19, 4.40, 7.19, 8.37,…\n#&gt; $ mcd12q1_lccs3_c27_pland            &lt;dbl&gt; 45.60, 52.36, 90.17, 23.97, 59.84, …\n#&gt; $ mcd12q1_lccs3_c50_ed               &lt;dbl&gt; 1.295, 6.607, 0.899, 0.000, 0.000, …\n#&gt; $ mcd12q1_lccs3_c50_pland            &lt;dbl&gt; 2.573, 13.835, 0.626, 0.000, 0.000,…\n#&gt; $ mcd12q1_lccs3_c51_ed               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ mcd12q1_lccs3_c51_pland            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ has_shoreline                      &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE,…\n#&gt; $ shoreline_waveheight_mean          &lt;dbl&gt; 0.380, 0.380, 0.380, 0.380, 0.380, …\n#&gt; $ shoreline_waveheight_sd            &lt;dbl&gt; 0.00000, 0.00000, 0.00000, 0.00000,…\n#&gt; $ shoreline_tidal_range_mean         &lt;dbl&gt; 4.24, 4.13, 4.09, 4.06, 4.02, 3.93,…\n#&gt; $ shoreline_tidal_range_sd           &lt;dbl&gt; 0.0000, 0.0462, 0.0191, 0.0000, 0.0…\n#&gt; $ shoreline_chlorophyll_mean         &lt;dbl&gt; 3.70, 3.76, 3.76, 3.84, 3.83, 3.79,…\n#&gt; $ shoreline_chlorophyll_sd           &lt;dbl&gt; 0.037448, 0.000638, 0.045479, 0.044…\n#&gt; $ shoreline_turbidity_mean           &lt;dbl&gt; 0.1450, 0.1450, 0.1884, 0.2029, 0.0…\n#&gt; $ shoreline_turbidity_sd             &lt;dbl&gt; 0.000000, 0.000000, 0.028934, 0.000…\n#&gt; $ shoreline_sinuosity_mean           &lt;dbl&gt; 1.04, 1.04, 1.10, 1.10, 1.32, 1.34,…\n#&gt; $ shoreline_sinuosity_sd             &lt;dbl&gt; 0.000, 0.000, 0.000, 0.000, 0.405, …\n#&gt; $ shoreline_slope_mean               &lt;dbl&gt; 120.0, 13.3, 85.0, 56.0, 89.3, 74.3…\n#&gt; $ shoreline_slope_sd                 &lt;dbl&gt; 50.22, 5.74, 48.43, 10.09, 61.16, 4…\n#&gt; $ shoreline_outflow_density_mean     &lt;dbl&gt; 1.06e-04, 4.18e-05, 4.18e-05, 4.18e…\n#&gt; $ shoreline_outflow_density_sd       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_n            &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c1_density   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c2_density   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c3_density   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_erodibility_c4_density   &lt;dbl&gt; 181, 149, 367, 366, 677, 1088, 1240…\n#&gt; $ shoreline_emu_physical_n           &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c1_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c2_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c3_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c4_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c5_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c6_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c7_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c8_density  &lt;dbl&gt; 181, 149, 367, 366, 677, 1088, 1240…\n#&gt; $ shoreline_emu_physical_c9_density  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c10_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c11_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c12_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c13_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c14_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c15_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c16_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c17_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c18_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c19_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c20_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c21_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c22_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ shoreline_emu_physical_c23_density &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\nThese variables should be mostly familiar from the ERD, except for srd_id which is a unique identifier for each point on the grid. Next let’s load the raster template using the terra package.\n\nraster_template &lt;- rast(\"data/prediction-grid_template.tif\")\nraster_template\n#&gt; class       : SpatRaster \n#&gt; dimensions  : 5630, 13511, 1  (nrow, ncol, nlyr)\n#&gt; resolution  : 2963, 2963  (x, y)\n#&gt; extent      : -2e+07, 2e+07, -6673060, 1e+07  (xmin, xmax, ymin, ymax)\n#&gt; coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#&gt; source      : prediction-grid_template.tif \n#&gt; name        : mask \n#&gt; min value   :    1 \n#&gt; max value   :    1\n\nThis is a global 2.96km by 2.96km square grid in an equal area projection. We can use the terra function rasterize to insert values from the prediction grid into the template for mapping. For example, let’s make a raster dataset of percent cover of evergreen broadleaf forest (mcd12q1_lccs1_c12_pland).\n\nforest_cover &lt;- prediction_grid %&gt;% \n  # convert to spatial object using sf\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  # transform to the coordinate reference system of the raster\n  st_transform(crs = crs(raster_template)) %&gt;% \n  # rasterize the points using the raster template\n  rasterize(raster_template, field = \"mcd12q1_lccs1_c12_pland\")\n\nNow we can make a simple map of evergreen broadleaf forest. Note that the raster template is global, but we can use trim() to remove all areas that have missing values.\n\nplot(trim(forest_cover), axes = FALSE)\n\n\n\n\n\n\n\n\nThe map looks distorted because the prediction grid uses a sinusoidal projection, which works well for analysis but not for mapping. In the next lesson, we’ll demonstrate how to project data into a coordinate reference system more suitable for mapping.\n\n\n1.2.3 Spatial and temporal bias\nDespite the strengths of eBird data, species observations collected through citizen science projects exhibit both spatial and temporal bias requiring special care when using them for rigorous analyses. Spatial bias occurs because eBird participants are more likely to be collect data near their homes, in easily accessible areas such as roadsides, or in areas known to be good for birding. Looking at the above map of bird observations it’s clear that the eBird checklists are clustered around cities and roads. Temporal bias occurs because participants preferentially collect data when they are available, such as weekends, and at times of year when they expect to observe more birds, notably during the breeding season. We can plot the distribution of checklists over the days of the year to see this bias:\n\nchecklist_per_day &lt;- checklists %&gt;% \n  filter(day_of_year &lt; 366) %&gt;% \n  count(day_of_year)\nggplot(checklist_per_day) +\n  aes(x = day_of_year, y = n) +\n  geom_line() +\n  scale_y_continuous(labels = scales::comma) +\n  labs(x = \"Day of Year\", y = \"# checklists\",\n       title = \"Daily eBird checklists submission\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nThree is a clear seasonal pattern to the number of eBird checklists submitted (fewer checklists in March) as well as daily and weekly variation within seasons. In addition, there are spikes in checklists submissions. What do you think could be causing these sudden increases?\nFinally, for most species, there is strong class imbalance in the data, meaning there are usually many more non-detections than detections. As a results, a distribution model predicting that the species is absent everywhere will have high accuracy, but no ecological value. For example, the prevalence rate of this species is only 3%.\n\nmean(bird_zf$obs_detected)\n#&gt; [1] 0.0275\n\nTo address these three issues (spatial bias, temporal bias, and class imbalance) we recommend subsampling the data using a technique called case controlled grid sampling. We overlay an equal area 3km by 3km grid over the checklists, then sample one detection and one non-detection from each grid cell for each week of each year. Let’s look at a simple example of how spatial grid sampling works.”\n\n\n\n1. Take one week of eBird observations. Detections are show in green and non-detections are shown in gray.\n\n\n\n\n\n2. Separate the detections and non-detections. In this example, there is a higher density of observations in the lower right corner of the region and the prevalence of detections is 2%.\n\n\n\n\n\n3. Overlay an equal area grid on top of the points, For Status and Trends we use a 3km by 3km grid.\n\n\n\n\n\n4. Sample one checklist from each grid cell.\n\n\n\n\n\n5. Recombine the detections and non-detections. The observations are much more evenly distributed in space and the prevalence of detections has increased from 2% to 20%.\n\n\nThe function grid_sample_stratified() from the ebirdst package is specifically designed to perform case controlled grid sampling on eBird data. For example, let’s apply this technique to the bird observations.\n\n# perform case controlled grid sampling\nbird_sampled &lt;- grid_sample_stratified(bird_zf, obs_column = \"obs_detected\")\n\n# how many checklists were removed?\nnrow(bird_zf)\n#&gt; [1] 90620\nnrow(bird_sampled)\n#&gt; [1] 33256\n\n# how has prevalence changed\nmean(bird_zf$obs_detected)\n#&gt; [1] 0.0275\nmean(bird_sampled$obs_detected)\n#&gt; [1] 0.0432\n\nSo, after sampling, we’re left with 37% of the observations we started with, but the spatial and temporal bias has been significantly reduced.\nWe now have the data and tools necessary to model relative abundance using eBird data, which will be the focus of Lesson 2."
  },
  {
    "objectID": "abundance.html#sec-abundance-data",
    "href": "abundance.html#sec-abundance-data",
    "title": "2  Modeling Relative Abundance",
    "section": "2.1 Data preparation",
    "text": "2.1 Data preparation\nLet’s start by reading the eBird data into R and zero-filling it to produce detection/non-detection data for the species.\n\nlibrary(arrow)\nlibrary(auk)\nlibrary(dplyr)\nlibrary(ebirdst)\nlibrary(fields)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(mccf1)\nlibrary(ranger)\nlibrary(scam)\nlibrary(sf)\nlibrary(terra)\n\n# set seed for reproducibility\nset.seed(1)\n\n# detections\nobservations &lt;- read_parquet(\"data/ebird_observations_AU-QLD_2022.parquet\") %&gt;% \n  filter(species_code == \"shbcuc1\") %&gt;% \n  select(checklist_id, valid, obs_detected, obs_count)\n\n# zero filled checklists\nchecklists &lt;- read_parquet(\"data/ebird_checklists_AU-QLD_2022.parquet\") %&gt;%\n  left_join(observations, by = \"checklist_id\") %&gt;% \n  filter(is.na(valid) | valid) %&gt;% \n  mutate(\n    # checklist not in the observations dataset are non-detections\n    obs_detected = coalesce(obs_detected, 0L),\n    # non-detections correspond to a count of 0\n    obs_count = ifelse(obs_detected == 1L, obs_count, 0)\n  )\n\nNext let’s subset the data to only observations from November through January, summer months during which we expect detectability and habitat associations to be stationary. To reduce variation in detectability, we’ll also subset the data to only those checklists less than 6 hours in duration and 10km in length, at speeds below 100km/h, and with 10 or fewer observers. Furthermore, we’ll only consider data from the past 15 years (2008-2022).\n\nchecklists &lt;- checklists %&gt;% \n  filter(\n    # last 15 years of data\n    year &gt;= 2008,\n    # jan-feb\n    (day_of_year &gt;= 305 | day_of_year &lt;= 31),\n    # effort filters\n    effort_hrs &lt;= 6,\n    effort_distance_km &lt;= 10,\n    effort_speed_kmph &lt;= 100,\n    num_observers &lt;= 10)\n\nFor the final filtering step, we’ll use spatial boundaries from Australia’s bioregions to subset the data to the region around Brisbane and the one to the west.\n\nstudy_region &lt;- read_sf(\"data/ibra61_reg.gpkg\") %&gt;%\n  filter((REG_CODE %in% c(\"SEQ\", \"BBS\")) & STATE == \"QLD\") %&gt;%\n  st_union() %&gt;%\n  st_as_sf() %&gt;%\n  st_transform(crs = 4326)\n\n# subset to regions of interest\nin_region &lt;- checklists %&gt;%\n  select(checklist_id, latitude, longitude) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_join(study_region, left = FALSE) %&gt;%\n  st_drop_geometry()\nchecklists &lt;- semi_join(checklists, in_region, by = \"checklist_id\")\n\n\n2.1.1 Test-train split\nWe’ll hold aside a portion of the observations from training to be used as an independent test set to assess the predictive performance of the model. Specifically, we’ll randomly split the data into 80% of observations for training and 20% for testing. To help with this, we create a new variable type that will indicate whether the observation falls in the test set or training set.\n\nchecklists$type &lt;- ifelse(runif(nrow(checklists)) &lt;= 0.8, \"train\", \"test\")\n# confirm the proportion in each set is correct\ntable(checklists$type) / nrow(checklists)\n#&gt; \n#&gt;  test train \n#&gt; 0.199 0.801\n\n\n\n2.1.2 Case controlled grid sampling\nFollowing the method outlined in Section 1.2.3, we perform a round of case controlled grid sampling on the data to reduce spatial and temporal bias as well as class imbalance. We can use the sample_by argument to grid_sample_stratified() to independently sample from the train and test sets to remove bias from both.\n\nchecklists_sampled &lt;- grid_sample_stratified(checklists,\n                                             obs_column = \"obs_detected\",\n                                             sample_by = \"type\")\n\nHow did this impact the prevalence of detections compared to non-detections?\n\n# original data\nnrow(checklists)\n#&gt; [1] 54340\ncount(checklists, obs_detected) %&gt;% \n  mutate(percent = n / sum(n))\n#&gt; # A tibble: 2 × 3\n#&gt;   obs_detected     n percent\n#&gt;          &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1            0 52388  0.964 \n#&gt; 2            1  1952  0.0359\n\n# after sampling\nnrow(checklists_sampled)\n#&gt; [1] 23645\ncount(checklists_sampled, obs_detected) %&gt;% \n  mutate(percent = n / sum(n))\n#&gt; # A tibble: 2 × 3\n#&gt;   obs_detected     n percent\n#&gt;          &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;\n#&gt; 1            0 22418  0.948 \n#&gt; 2            1  1227  0.0519\n\nSo, the case controlled sampling decreased the overall number of checklists by a factor of 2.3, but increased the prevalence of detections. This increase in detections will help the random forests model distinguish where birds are being observed; however, this does affect the prevalence rate of the detections in the data. As a result, the estimated encounter rate based on these subsampled data will be larger than the true encounter rate. When examining the outputs from the models it will be important to recall that we altered the prevalence rate at this stage."
  },
  {
    "objectID": "abundance.html#sec-abundance-hurdle",
    "href": "abundance.html#sec-abundance-hurdle",
    "title": "2  Modeling Relative Abundance",
    "section": "2.2 Hurdle model",
    "text": "2.2 Hurdle model\nFor this two-step hurdle model, we’ll start by training an random forests model for encounter rate. Then we’ll subset the eBird checklist to only those where the species was detected or predicted to occur by the encounter rate model. We’ll use this subset of the data to train a second random forests model for expected count. Finally we’ll combine the results of the two steps together to produce estimates of relative abundance.\nLet’s start by select by removing the 20% of checklists held aside for testing and selecting only those columns we’ll use as response or predictor variables in the models.\n\nchecklists_train &lt;- checklists_sampled %&gt;%\n  filter(type == \"train\") %&gt;% \n  select(checklist_id,\n         obs_detected, obs_count,\n         is_stationary,\n         year, day_of_year, solar_noon_diff,\n         effort_hrs, effort_distance_km, effort_speed_kmph,\n         num_observers,\n         eastness_1km_median, eastness_1km_sd,\n         eastness_90m_median, eastness_90m_sd,\n         northness_1km_median, northness_1km_sd,\n         northness_90m_median, northness_90m_sd,\n         elevation_250m_median, elevation_250m_sd,\n         elevation_30m_median, elevation_30m_sd,\n         intertidal_c1_ed, intertidal_c1_pland,\n         ntl_mean, ntl_sd,\n         evi_median, evi_sd,\n         starts_with(\"astwbd\"),\n         starts_with(\"road_density\"),\n         starts_with(\"mcd12q1\"),\n         starts_with(\"gsw\"))\n\n\n2.2.1 Step 1: Encounter rate\nFor the first step of the hurdle model we’ll train a random forests model to estimate the probability of detection/non-detection of the species, a binary classification problem. Random forests are an excellent, general purpose machine learning method suitable for modeling encounter rate in a wide variety of scenarios.\nMost classification algorithms aim to minimize the overall error rate, which results in poor predictive performance for rare classes. To address this issue, we’ll use a balanced random forests approach, a modification of the traditional random forest algorithm designed to handle imbalanced data. In this approach, each of the trees that makes up the random forest is generated using a random sample of the data chosen such that there are an equal number of detections (the rare class) and non-detections (the common class). To use this approach, we’ll need to calculate the proportion of detections in the dataset.\n\ndetection_freq &lt;- mean(checklists_train$obs_detected)\n\nWe’re now ready to train the encounter rate random forests model using the ranger package. Rather than writing out a complete model formula, we’ll use the ~ . notation to instruct the ranger() to use all variables as predictors. We just need to be cautious to remove both checklist_id and obs_count from the data frame. Since this is a classification problem, we also need to convert the response variable (obs_detected) to a factor variable.\n\ntrain_er &lt;- select(checklists_train, -checklist_id, -obs_count)\ner_model &lt;- ranger(formula =  as.factor(obs_detected) ~ ., \n                   data = train_er,\n                   importance = \"impurity\",\n                   # this ensures ranger predicts class probabilities\n                   # not just the most likely class\n                   probability = TRUE,\n                   # implement a balanced random forests\n                   replace = TRUE, \n                   sample.fraction = c(detection_freq, detection_freq))\n\nPredicted probabilities from a random forests model do not always line up with the observed frequency of detection. We’ll address this mismatch using model calibration, which aligns the estimated probabilities to the observed frequencies. In particular, to calibrate our model results, we predict encounter rate for each checklist in the training set, then fit a binomial Generalized Additive Model (GAM) with the real observations as the response and the predicted encounter rate as the predictor variable.\n\n# predicted encounter rate and observed detection\nobs_pred &lt;- tibble(obs = train_er$obs_detected, \n                   pred = er_model$predictions[, 2])\n\n# fit calibration model\ncalibration_model &lt;- scam(obs ~ s(pred, k = 6, bs = \"mpi\"), \n                          gamma = 2,\n                          data = obs_pred)\n\nThe random forest model produces continuous estimates of encounter rate from 0-1. However, for many applications, including selecting which observations are included in the next stage of the hurdle, we’ll need to reclassify this continuous probability to a binary presence/absence estimate. This reclassification is done by setting a threshold above which the species is predicted to be absent. We recommend selecting a threshold using the MCC-F1 curve, which performs well for class imbalanced data. The R package mccf1 implements this method.\n\n# mcc and fscore calculation for various thresholds\nmcc_f1 &lt;- mccf1(response = obs_pred$obs, predictor = obs_pred$pred)\n\n# identify best threshold\nmcc_f1_summary &lt;- summary(mcc_f1)\n#&gt;  mccf1_metric best_threshold\n#&gt;         0.336          0.611\nthreshold &lt;- mcc_f1_summary$best_threshold[1]\n\n\n\n2.2.2 Step 2: Count\nFor the second step of the hurdle model, we train a random forests model to estimate the expected count of individuals on eBird checklists where the species was detected or predicted to be detected by the encounter rate model. So, we’ll start by subsetting the data to just these checklists. In addition, we’ll remove any observations for which the observer reported that species was present, but didn’t report a count of the number of individuals (coded as a count of “X” in the eBird database, but converted to NA in our dataset).\n\n# attach the predicted encounter rate\ntrain_count &lt;- checklists_train\ntrain_count$pred_er &lt;- er_model$predictions[, 2]\n# subset to only observed or predicted detections\ntrain_count &lt;- train_count %&gt;% \n  filter(!is.na(obs_count), \n         obs_count &gt; 0 | pred_er &gt; threshold) %&gt;% \n  select(-checklist_id, -obs_detected, -pred_er)\n\nWe’ve found that including estimated encounter rate as a predictor in the count model improves predictive performance. So, with this in mind, we predict encounter rate for the training dataset and add it as an additional column.\n\npredicted_er &lt;- predict(er_model, data = train_count, type = \"response\")\npredicted_er &lt;- predicted_er$predictions[, 2]\ntrain_count$predicted_er &lt;- predicted_er\n\nFinally, we train a random forests model to estimate count. This is superficially very similar to the random forests model for encounter rate; however, for count we’re using a regression random forest while for encounter rate we used a balanced classification random forest.\n\ncount_model &lt;- ranger(formula = obs_count ~ .,\n                      data = train_count,\n                      importance = \"impurity\",\n                      replace = TRUE)\n\n\n\n2.2.3 Assessment\nTo assess the quality of the encounter rate, count, and relative abundance models, we’ll validate the their ability to predict the observed patterns of detection and counts using independent validation data (i.e. the 20% test data set). There are a range of predictive performance metrics (PPMs) that can be used to compare the predictions to the actual observations. We’ll start by estimating encounter rate, count, and relative abundance for the spatiotemporally grid sampled test dataset.\n\n# get the test set held out from training\nchecklists_test &lt;- filter(checklists_sampled, type == \"test\")\n\n# estimate encounter rate for test data\npred_er &lt;- predict(er_model, data = checklists_test, type = \"response\")\n# extract probability of detection\npred_er &lt;- pred_er$predictions[, 2]\n# convert to binary using the threshold\npred_binary &lt;- as.integer(pred_er &gt; threshold)\n# calibrate\npred_calibrated &lt;- predict(calibration_model, \n                           newdata = data.frame(pred = pred_er), \n                           type = \"response\") %&gt;% \n  as.numeric()\n# constrain probabilities to 0-1\npred_calibrated &lt;- pmin(pmax(pred_calibrated, 0), 1)\n\n# add predicted encounter rate required for count estimates\nchecklists_test$predicted_er &lt;- pred_er\n# estimate count\npred_count &lt;- predict(count_model, data = checklists_test, type = \"response\")\npred_count &lt;- pred_count$predictions\n\n# relative abundance is the product of encounter rate and count\npred_abundance &lt;- pred_calibrated * pred_count\n\n# combine all estimates together\nobs_pred_test &lt;- data.frame(\n  id = seq_along(pred_abundance),\n  # actual detection/non-detection\n  obs_detected = checklists_test$obs_detected,\n  obs_count = checklists_test$obs_count,\n  # model estimates\n  pred_binary = pred_binary,\n  pred_er = pred_calibrated,\n  pred_count = pred_count,\n  pred_abundance = pred_abundance\n)\n\nFirst we’ll calculate a suite of PPMs for the encounter rate model.\n\n# mean squared error (mse)\nmse &lt;- mean((obs_pred_test$obs_detected - obs_pred_test$pred_er)^2, \n            na.rm = TRUE)\n\n# spearman correlation, based on in range observations only\nspearman &lt;- cor(obs_pred_test$pred_er[obs_pred_test$pred_binary &gt; 0], \n                obs_pred_test$obs_detected[obs_pred_test$pred_binary &gt; 0], \n                method = \"spearman\")\n\n# precision-recall auc\nem &lt;- precrec::evalmod(scores = obs_pred_test$pred_binary, \n                       labels = obs_pred_test$obs_detected)\npr_auc &lt;- precrec::auc(em) %&gt;% \n  filter(curvetypes == \"PRC\") %&gt;% \n  pull(aucs)\n\n# calculate metrics for binary prediction: kappa, sensitivity, specificity\npa_metrics &lt;- obs_pred_test %&gt;% \n  select(id, obs_detected, pred_binary) %&gt;% \n  PresenceAbsence::presence.absence.accuracy(na.rm = TRUE, st.dev = FALSE)\n\n# mcc and f1\nmcc_f1 &lt;- calculate_mcc_f1(obs_pred_test$obs_detected, \n                           obs_pred_test$pred_binary)\n\n# combine metrics together\nppms &lt;- tibble(\n  mse = mse,\n  spearman = spearman,\n  sensitivity = pa_metrics$sensitivity,\n  specificity = pa_metrics$specificity,\n  kappa = pa_metrics$Kappa,\n  pr_auc = pr_auc,\n  mcc = mcc_f1$mcc,\n  f1 = mcc_f1$f1\n)\nknitr::kable(ppms, digits = 3)\n\n\n\n\nmse\nspearman\nsensitivity\nspecificity\nkappa\npr_auc\nmcc\nf1\n\n\n\n\n0.035\n0.208\n0.595\n0.893\n0.243\n0.142\n0.29\n0.289\n\n\n\n\n\nThe count and abundance predictive performance metrics are measures of within range performance, meaning we compare observed count vs. estimated count and abundance only for those checklists where the model predicts the species to occur.\n\n# subset to only those checklists where detection is predicted\ndetections_test &lt;- filter(obs_pred_test, \n                          pred_binary &gt; 0,\n                          !is.na(obs_count))\n\n# count metrics\ncount_spearman &lt;- cor(detections_test$pred_count, \n                      detections_test$obs_count,\n                      method = \"spearman\")\nlog_count_pearson &lt;- cor(log(detections_test$pred_count + 1),\n                         log(detections_test$obs_count + 1),\n                         method = \"pearson\")\n\n# abundance metrics\nabundance_spearman &lt;- cor(detections_test$pred_abundance, \n                          detections_test$obs_count,\n                          method = \"spearman\")\nlog_abundance_pearson &lt;- cor(log(detections_test$pred_abundance + 1),\n                             log(detections_test$obs_count + 1),\n                             method = \"pearson\")\n\n# combine metrics together\nppms &lt;- tibble(\n  count_spearman = count_spearman,\n  log_count_pearson = log_count_pearson,\n  abundance_spearman = abundance_spearman,\n  log_abundance_pearson = log_abundance_pearson\n)\nknitr::kable(ppms, digits = 3)\n\n\n\n\n\n\n\n\n\n\ncount_spearman\nlog_count_pearson\nabundance_spearman\nlog_abundance_pearson\n\n\n\n\n0.199\n0.211\n0.22\n0.199\n\n\n\n\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nLet’s take a moment to consider these predictive performance metrics. How would the importance of different metrics change based on your intended application?"
  },
  {
    "objectID": "abundance.html#sec-abundance-habitat",
    "href": "abundance.html#sec-abundance-habitat",
    "title": "2  Modeling Relative Abundance",
    "section": "2.3 Habitat associations",
    "text": "2.3 Habitat associations\nFrom the random forest model, we can glean two important sources of information about the association between species detection and features of their local environment. First, predictor importance is a measure of the predictive power of each variable used as a predictor in the model, and is calculated as a byproduct of fitting a random forests model. Second, partial dependence estimates the marginal effect of one predictor holding all other predictors constant.\n\n2.3.1 Predictor importance\nDuring the process of training a random forests model, some variables are removed at each node of the trees that make up the random forests. Predictor importance is based on the mean decrease in accuracy of the model when a given predictor is not used. It’s technically an average Gini index, but essentially larger values indicate that a predictor is more important to the model.\n\npi &lt;- er_model$variable.importance\npi &lt;- data.frame(predictor = names(pi), importance = unname(pi)) %&gt;% \n  arrange(desc(importance))\n# plot top 10 predictors\nggplot(head(pi, 10)) + \n  aes(x = fct_reorder(predictor, importance), y = importance) +\n  geom_col() +\n  geom_hline(yintercept = 0, linewidth = 2, colour = \"#555555\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  coord_flip() +\n  labs(x = NULL, \n       y = \"Predictor Importance (Gini Index)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        panel.grid.major.x = element_line(colour = \"#cccccc\", linewidth = 0.5))\n\n\n\n\n\n\n\n\nThe most important predictors of detection/non-detection are often effort variables. Indeed, that’s the case here: checklist duration, distance traveled, and time of day (solar_noon_diff) all appear in the top 5 predictors. This is not surprising: going out at the right time of day and expending more effort searching will lead to a higher probability of detecting Wood Thrush. Focusing on the habitat variables, both elevation and slope variables have high importance, and the top habitat variables are from evergreen broadleaf forest and open forest. Note however, that high importance doesn’t tell us the direction of the relationship with detection, for that we’ll have to look at partial dependence plots.\n\n\n\n\n\n\nExercise\n\n\n\nLook up the predictor names in ebirdst_predictors to see what habitat types these variables correspond to. Based on your knowledge of the species, does it make sense that these habitat types are important? Go further and look up the descriptions in ebirdst_predictor_descriptions to learn more about the predictor and see if there’s a reference.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfilter(ebirdst_predictors, \n       predictor %in% c(\"mcd12q1_lccs1_c12_pland\",\n                        \"ntl_mean\",\n                        \"mcd12q1_lccs1_c31_pland\")) %&gt;% \n  select(predictor, label)\n#&gt; # A tibble: 3 × 2\n#&gt;   predictor               label                                \n#&gt;   &lt;chr&gt;                   &lt;chr&gt;                                \n#&gt; 1 ntl_mean                Nighttime Lights (Mean)              \n#&gt; 2 mcd12q1_lccs1_c12_pland Evergreen Broadleaf Forests (% cover)\n#&gt; 3 mcd12q1_lccs1_c31_pland Unclassified (% cover)\n\nglimpse(ebirdst_predictor_descriptions)\n#&gt; Rows: 37\n#&gt; Columns: 4\n#&gt; $ dataset     &lt;chr&gt; \"ebird\", \"ebird\", \"ebird\", \"ebird\", \"ebird\", \"ebird\", \"ebi…\n#&gt; $ predictor   &lt;chr&gt; \"longitude\", \"latitude\", \"year\", \"day_of_year\", \"solar_noo…\n#&gt; $ description &lt;chr&gt; \"Longitude assigned to checklist. Locations are assigned u…\n#&gt; $ reference   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"https://doi.org/1…\n\n\n\n\n\n\n2.3.2 Partial dependence\nPartial dependence plots show the marginal effect of a given predictor on encounter rate averaged across the other predictors. These plots are generated by predicting encounter rate at a regular sequence of points across the full range of values of a given predictor. At each predictor value, predictions of encounter rate are made for a random subsample of the training dataset with the focal predictor fixed, but all other predictors left as is. The encounter rate predictions are then averaged across all the checklists in the training dataset giving an estimate of the average encounter rate at a specific value of the focal predictor. This is a cumbersome process, but we provide a function below that does all the hard work for you! This function takes the following arguments:\n\npredictor: the name of the predictor to calculate partial dependence for\nmodel: the encounter rate model object\ndata: the original data used to train the model\nx_res: the resolution of the grid over which to calculate the partial dependence, i.e. the number of points between the minimum and maximum values of the predictor to evaluate partial dependence at\nn: number of points to subsample from the training data\n\n\n# function to calculate partial dependence for a single predictor\ncalculate_pd &lt;- function(predictor, model, data, \n                         x_res = 25, n = 1000) {\n  # create prediction grid using quantiles\n  x_grid &lt;- quantile(data[[predictor]],\n                     probs = seq(from = 0, to = 1, length = x_res),\n                     na.rm = TRUE)\n  # remove duplicates\n  x_grid &lt;- x_grid[!duplicated(signif(x_grid, 8))]\n  x_grid &lt;- unname(unique(x_grid))\n  grid &lt;- data.frame(predictor = predictor, x = x_grid)\n  names(grid) &lt;- c(\"predictor\", predictor)\n  \n  # subsample training data\n  n &lt;- min(n, nrow(data))\n  data &lt;- data[sample(seq.int(nrow(data)), size = n, replace = FALSE), ]\n  \n  # drop focal predictor from data\n  data &lt;- data[names(data) != predictor]\n  grid &lt;- merge(grid, data, all = TRUE)\n  \n  # predict\n  p &lt;- predict(model, data = grid)\n  \n  # summarize\n  pd &lt;- grid[, c(\"predictor\", predictor)]\n  names(pd) &lt;- c(\"predictor\", \"x\")\n  pd$encounter_rate &lt;- p$predictions[, 2]\n  pd &lt;- dplyr::group_by(pd, predictor, x) %&gt;% \n    dplyr::summarise(encounter_rate = mean(encounter_rate, na.rm = TRUE),\n                     .groups = \"drop\")\n  \n  return(pd)\n}\n\nNow we’ll use this function to calculate partial dependence for the top 9 predictor variables.\n\n# calculate partial dependence for each predictor\n# map is used to iteratively apply calculate_pd to each predictor\npd &lt;- NULL\nfor (predictor in head(pi$predictor)) {\n  pd &lt;- calculate_pd(predictor, model = er_model, data = checklists_train) %&gt;% \n    bind_rows(pd, .)\n}\n\n# calibrate predictions\npd$encounter_rate &lt;- predict(calibration_model, \n                             newdata = tibble(pred = pd$encounter_rate), \n                             type = \"response\") %&gt;% \n  as.numeric()\n\n# plot\nggplot(pd) +\n  aes(x = x, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ as_factor(predictor), ncol = 2, scales = \"free\") +\n  labs(x = NULL, y = \"Encounter Rate\") +\n  theme_minimal() +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        axis.line = element_line(color = \"grey60\"),\n        axis.ticks  = element_line(color = \"grey60\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nConsider the relationships shown in the partial dependence plots in light of your knowledge of the species. Do these relationships make sense."
  },
  {
    "objectID": "abundance.html#sec-abundance-predict",
    "href": "abundance.html#sec-abundance-predict",
    "title": "2  Modeling Relative Abundance",
    "section": "2.4 Prediction",
    "text": "2.4 Prediction\nUsing the prediction grid described in Section 1.2.2, we can estimate relative abundance over our entire study area. First we estimate encounter rate and count, then we multiply these together to get an estimate of relative abundance. Let’s read in the prediction grid and subset to just the region we’re focusing on.\n\npred_grid_year &lt;- read_parquet(\"data/prediction-grid_year_AU-QLD_2022.parquet\")\n\npred_grid_evi &lt;- read_parquet(\"data/prediction-grid_week_AU-QLD_2022.parquet\") %&gt;%\n  filter(day_of_year == 347) %&gt;%\n  select(srd_id, evi_median, evi_sd)\n\npred_grid_all &lt;- pred_grid_year %&gt;%\n  left_join(pred_grid_evi, by = \"srd_id\")\n\nraster_template &lt;- rast(\"data/prediction-grid_template.tif\") %&gt;% \n  # crop raster to study region\n  crop(st_transform(study_region, crs = crs(.)))\n\n# subset to the three regions we're focusing on\nin_region &lt;- pred_grid_all %&gt;%\n  select(srd_id, latitude, longitude) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;%\n  st_join(study_region, left = FALSE) %&gt;%\n  st_drop_geometry()\npred_grid &lt;- semi_join(pred_grid_all, in_region, by = \"srd_id\")\n\nThe prediction grid only includes values for the environmental variables, so to make predictions we’ll need to add effort variables to this prediction grid. We’ll make predictions for a standard eBird checklist: a 2 km, 1 hour traveling count at the peak time of day for detecting this species. Finally, we’ll make these predictions for December 15, 2022, the middle of our November-January focal window for the latest year for which we have eBird data.\nTo find the time of day with the highest detection probability, we can look for the peak of the partial dependence plot.\n\n# estimate a partial dependence plot for solar noon diff\npd_time &lt;- calculate_pd(\"solar_noon_diff\",\n                        model = er_model, \n                        data = checklists_train) %&gt;% \n  select(solar_noon_diff = x, encounter_rate)\n\n# partial dependence plot\nggplot(pd_time) +\n  aes(x = solar_noon_diff, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = seq(-12, 13, by = 3)) +\n  labs(x = \"Difference from solar noon\",\n       y = \"Encounter\",\n       title = \"Partial dependence\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nBased on the above plot, it appears that about 5 hours before solar noon is the optimal time for observing the species. We could stop here and set our prediction values to fixed units, but there is significant value in defining these prediction units differently for our estimates of range boundary. Think of this as two different searches. First, a search goes out for as long (time and distance) as it takes to detect the species in all places (maximized detection). Then a separate search goes out for a standardized amount of duration and distance. In this way, we get the best range boundary possible combined with standardized estimates of encounter rate, count, and relative abundance within that range boundary. To maximize the effort units for predicting the range boundary, we’ll need to look at the peaks of the partials for these predictors as well.\n\n# estimate a partial dependence plot for effort_hrs\npd_hrs &lt;- calculate_pd(\"effort_hrs\",\n                        model = er_model, \n                        data = checklists_train) %&gt;% \n  select(effort_hrs = x, encounter_rate)\n\n# partial dependence plot\nggplot(pd_hrs) +\n  aes(x = effort_hrs, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = seq(0, 6, by = 1)) +\n  labs(x = \"Effort Hours\",\n       y = \"Encounter\",\n       title = \"Partial dependence\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nHere we see a slope that doesn’t stop asymptoting until we get to 6 hours. However, that value of six hours is the last quantile and represents potential extrapolation territory, so we’ll chose the second to last quantile (which isn’t that different) at 3.5 hours.\n\n# estimate a partial dependence plot for effort_distance_km\npd_km &lt;- calculate_pd(\"effort_distance_km\",\n                        model = er_model, \n                        data = checklists_train) %&gt;% \n  select(effort_distance_km = x, encounter_rate)\n\n# partial dependence plot\nggplot(pd_km) +\n  aes(x = effort_distance_km, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks = seq(0, 10, by = 1)) +\n  labs(x = \"Effort Distance (km)\",\n       y = \"Encounter\",\n       title = \"Partial dependence\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nAgain, here the last quantile value is way out at 10 and could generate extrapolation, so we’ll choose 5.5 km, the next quantile value. We also need to remember that we have effort_speed_kmph as a predictor in the model. Let’s generate a partial for this, to see if 5.5 km / 3.5 hours produces a reasonable value.\n\n# estimate a partial dependence plot for rate\npd_km &lt;- calculate_pd(\"effort_speed_kmph\",\n                        model = er_model, \n                        data = checklists_train) %&gt;% \n  select(effort_speed_kmph = x, encounter_rate)\n\n# partial dependence plot\nggplot(pd_km) +\n  aes(x = effort_speed_kmph, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  geom_vline(xintercept = 5.5 / 3.5, col = \"red\") +\n  #scale_x_continuous(breaks = seq(0, 6, by = 1)) +\n  xlim(c(0, 5)) +\n  labs(x = \"Effort Speed (km/h))\",\n       y = \"Encounter\",\n       title = \"Partial dependence\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nThis looks good. It’s not the absolute peak of the rate partial, but it’s pretty close, especially given the magnitude range of the encounter rate for this partial. Let’s add all the effort variables to the prediction grid.\n\npred_grid_eff &lt;- pred_grid %&gt;% \n  mutate(year = 2022,\n         day_of_year = 349,\n         solar_noon_diff = -5,\n         is_stationary = 0,\n         effort_hrs = 3,\n         effort_distance_km = 5,\n         effort_speed_kmph = 5/3,\n         num_observers = 1)\n\nFirst, we’ll estimate binary presence/absence of the range boundary with an encounter rate prediction using these maximized effort values. Then we’ll reset the effort values the more standardized values of 1 hour, 2 km, and 2 kmph. These values are close to the means and medians of the data distribution. After we’ve reset these effort values, we’ll estimate calibrated encounter rate, count, and abundance for each point on the prediction grid.\n\n# binary presence/absence\npred_binary_er &lt;- predict(er_model, data = pred_grid_eff, type = \"response\")\npred_binary_er &lt;- pred_binary_er$predictions[, 2]\npred_binary &lt;- as.integer(pred_binary_er &gt; threshold)\n\n# set prediction values for effort back to standardized values\npred_grid_eff$effort_hrs &lt;- 1\npred_grid_eff$effort_distance_km &lt;- 2\npred_grid_eff$effort_speed_kmph &lt;- 2\n\n# encounter rate estimate\npred_er &lt;- predict(er_model, data = pred_grid_eff, type = \"response\")\npred_er &lt;- pred_er$predictions[, 2]\n\n# apply calibration\npred_er_cal &lt;- predict(calibration_model, \n                       data.frame(pred = pred_er), \n                       type = \"response\") %&gt;% \n  as.numeric()\n\n# add predicted encounter rate required for count estimates\npred_grid_eff$predicted_er &lt;- pred_er\n# count estimate\npred_count &lt;- predict(count_model, data = pred_grid_eff, type = \"response\")\npred_count &lt;- pred_count$predictions\n\n# add estimates to prediction grid\npredictions &lt;- pred_grid_eff %&gt;% \n  select(srd_id, latitude, longitude) %&gt;% \n  bind_cols(in_range = pred_binary,\n            encounter_rate = pred_er_cal,\n            count = pred_count) %&gt;% \n  mutate(encounter_rate = pmin(pmax(encounter_rate, 0), 1),\n         abundance = pred_er_cal * pred_count)\n\nNext, we convert these estimates to raster format using the raster template.\n\nr_pred &lt;- predictions %&gt;% \n  # convert to spatial features\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  st_transform(crs = crs(raster_template)) %&gt;% \n  # rasterize\n  rasterize(raster_template, \n            field = c(\"in_range\", \"encounter_rate\", \"count\", \"abundance\"), \n            fun = mean) %&gt;% # throws an error without\n  setNames(c(\"in_range\", \"encounter_rate\", \"count\", \"abundance\"))\n# trim global raster to study region\nr_pred &lt;- trim(r_pred)\n\nPrior to mapping these predictions, let’s load some contextual GIS data and project everything to a more suitable coordinate reference system.\n\n# load and project gis data\nmap_proj &lt;- \"+proj=laea +lon_0=146.95 +lat_0=-19.15 +datum=WGS84 +units=m +no_defs\"\nne_land &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_land\") %&gt;% \n  st_transform(crs = map_proj) %&gt;% \n  st_geometry()\nne_country_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_country_lines\") %&gt;% \n  st_transform(crs = map_proj) %&gt;% \n  st_geometry()\nne_state_lines &lt;- read_sf(\"data/gis-data.gpkg\", \"ne_state_lines\") %&gt;% \n  st_transform(crs = map_proj) %&gt;% \n  st_geometry()\nstudy_region_proj &lt;- st_transform(study_region, crs = map_proj) %&gt;% \n  st_geometry()\n\n# project the raster data\nr_pred_proj &lt;- crop(r_pred, st_transform(study_region, crs(r_pred))) %&gt;% \n  project(map_proj, method = \"near\")\n\nFinally we’ll produce a map of relative abundance. The values shown on this map are the expected number of birds seen by an average eBirder conducting a 2 hour, 1 km checklist on December 15, 2022 at the optimal time of day for detecting the species. Prior to mapping the relative abundance, we’ll multiple by the in_range layer, which will produce a map showing zero relative abundance where the model predicts that the species does not occur.\n\n# in range abundance\nr_plot &lt;- r_pred_proj[[\"abundance\"]] * r_pred_proj[[\"in_range\"]]\n\npar(mar = c(0.25, 0.25, 0.25, 0.25))\n# set up plot area\nplot(study_region_proj, col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# define quantile breaks, excluding zeros\nbrks &lt;- ifel(r_plot &gt; 0, r_plot, NA) %&gt;% \n  global(fun = quantile, \n         probs = seq(0, 1, 0.1), na.rm = TRUE) %&gt;% \n  as.numeric() %&gt;% \n  unique()\n# label the bottom, middle, and top value\nlbls &lt;- round(c(min(brks), median(brks), max(brks)), 2)\n# ebird status and trends color palette\npal &lt;- ebirdst_palettes(n = length(brks) - 1, type = \"weekly\")\nplot(r_plot, \n     col = c(\"#e6e6e6\", pal), breaks = c(0, brks), \n     maxpixels = ncell(r_plot),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# borders\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region_proj, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n# legend\nimage.plot(zlim = c(0, 1), legend.only = TRUE,\n           col = pal, breaks = seq(0, 1, length.out = length(brks)),\n           smallplot = c(0.89, 0.91, 0.2, 0.8),\n           horizontal = FALSE,\n           axis.args = list(at = c(0, 0.5, 1), labels = lbls,\n                            fg = \"black\", col.axis = \"black\",\n                            cex.axis = 0.75, lwd.ticks = 0.5),\n           legend.args = list(text = \"Relative Abundance\",\n                              side = 2, col = \"black\",\n                              cex = 1, line = 0))"
  }
]