[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "eBird Best Practices Workshop (ROC)",
    "section": "",
    "text": "Introduction\nThe contents of this website comprise the notes for a workshop on best practices for using eBird data and eBird Status data products presented to Red de Observadores de Aves y Vida Silvestre de Chile (ROC). The workshop is divided into three lessons covering:"
  },
  {
    "objectID": "index.html#sec-intro-setup",
    "href": "index.html#sec-intro-setup",
    "title": "eBird Best Practices Workshop (ROC)",
    "section": "Setup",
    "text": "Setup\nThis workshop is intended to be interactive. All examples are written in the R programming language, and the instructor will work through the examples in real time, while the attendees are encouraged following along by writing the same code. To ensure we can avoid any unnecessary delays, please follow these setup instructions prior to the workshop\n\nRequest access to raw eBird data.\nRequest access to the eBird Status data products.\nDownload and install the latest version of R. You must have R version 4.0.0 or newer to follow along with this workshop\nDownload and install the latest version of RStudio. RStudio is not required for this workshop; however, the instructors will be using it and you may find it easier to following along if you’re working in the same environment.\nThe lessons in this workshop use a variety of R packages. To install all the necessary packages, run the following code\n\n\nif (!requireNamespace(\"remotes\", quietly = TRUE)) {\n  install.packages(\"remotes\")\n}\nremotes::install_github(\"ebird/ebird-best-practices\")\n\n\nEnsure all packages are updated to their most recent versions by clicking on the Update button on the Packages tab in RStudio."
  },
  {
    "objectID": "index.html#sec-intro-data",
    "href": "index.html#sec-intro-data",
    "title": "eBird Best Practices Workshop (ROC)",
    "section": "Data",
    "text": "Data\nTo follow along with the lessons in the workshop you’ll need to download the workshop data package. This data package contains a variety of datasets used throughout the three lessons. You should have received an email with a link to download a zip file from Google Drive. Download all files in the folder, create a new RStudio project, unzip the data package, and place all the files in the data/ subdirectory of the project."
  },
  {
    "objectID": "index.html#sec-intro-tidyverse",
    "href": "index.html#sec-intro-tidyverse",
    "title": "eBird Best Practices Workshop (ROC)",
    "section": "Tidyverse",
    "text": "Tidyverse\nThroughout this book, we use packages from the Tidyverse, an opinionated collection of R packages designed for data science. Packages such as ggplot2, for data visualization, and dplyr, for data manipulation, are two of the most well known Tidyverse packages; however, there are many more. We’ll try to explain any functions as they come up; however, for a good general resource on working with data in R using the Tidyverse see the free online book R for Data Science by Hadley Wickham.\nThe one piece of the Tidyverse that we will cover up front is the pipe operator %>%. The pipe takes the expression to the left of it and “pipes” it into the first argument of the expression on the right.\n\nlibrary(dplyr)\n\n# without pipe\nmean(1:10)\n#> [1] 5.5\n\n# with pipe\n1:10 %>% mean()\n#> [1] 5.5\n\nThe pipe can code significantly more readable by avoiding nested function calls, reducing the need for intermediate variables, and making sequential operations read left-to-right. For example, to add a new variable to a data frame, then summarize using a grouping variable, the following are equivalent:\n\n# intermediate variables\nmtcars_kg <- mutate(mtcars, wt_kg = 454 * wt)\nmtcars_grouped <- group_by(mtcars_kg, cyl)\nsummarize(mtcars_grouped, wt_kg = mean(wt_kg))\n#> # A tibble: 3 × 2\n#>     cyl wt_kg\n#>   <dbl> <dbl>\n#> 1     4 1038.\n#> 2     6 1415.\n#> 3     8 1816.\n\n# nested function calls\nsummarize(\n  group_by(\n    mutate(mtcars, wt_kg = 454 * wt),\n    cyl\n  ),\n  wt_kg = mean(wt_kg)\n)\n#> # A tibble: 3 × 2\n#>     cyl wt_kg\n#>   <dbl> <dbl>\n#> 1     4 1038.\n#> 2     6 1415.\n#> 3     8 1816.\n\n# pipes\nmtcars %>% \n  mutate(wt_kg = 454 * wt) %>% \n  group_by(cyl) %>% \n  summarize(wt_kg = mean(wt_kg))\n#> # A tibble: 3 × 2\n#>     cyl wt_kg\n#>   <dbl> <dbl>\n#> 1     4 1038.\n#> 2     6 1415.\n#> 3     8 1816.\n\n\n\n\n\n\n\nExercise\n\n\n\nRewrite the following code using pipes:\n\nset.seed(1)\nround(log(runif(10, min = 0.5)), 1)\n#>  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nset.seed(1)\nrunif(10, min = 0.5) %>% \n  log() %>% \n  round(digits = 1)\n#>  [1] -0.5 -0.4 -0.2  0.0 -0.5 -0.1  0.0 -0.2 -0.2 -0.6"
  },
  {
    "objectID": "ebird.html#sec-ebird-erd",
    "href": "ebird.html#sec-ebird-erd",
    "title": "1  eBird Data",
    "section": "1.1 eBird Reference Dataset (ERD)",
    "text": "1.1 eBird Reference Dataset (ERD)\nThe eBird Reference Dataset (ERD) is a subset of the full eBird database released annually, containing only semi-structured (complete checklists with effort information) traveling and stationary counts from the last 15 years. The ERD is distributed in two parts: observation data and checklist data. In the observation dataset, each row corresponds to the sighting of a single species on a checklist, including the count and any other species-level information (e.g. age, sex, species comments, etc.). In the checklist dataset, each row corresponds to a checklist, including the date, time, location, effort (e.g. distance traveled, time spent, etc.), and any additional checklist-level information (e.g. whether this is a complete checklist or not). These two datasets are provided in parquet format, an open source standard for efficient storage and retrieval of tabular data, in the following files:\ndata/ebird_observations_chile_2021.parquet\ndata/ebird_checklists_chile_2021.parquet\nLet’s start by reading these two datasets into R using the arrow package and exploring them. We’ll start with the checklist dataset.\n\nlibrary(arrow)\nlibrary(auk)\nlibrary(dplyr)\nlibrary(ebirdst)\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(terra)\n\nchecklists <- read_parquet(\"data/ebird_checklists_chile_2021.parquet\")\nglimpse(checklists)\n#> Rows: 186,908\n#> Columns: 98\n#> $ checklist_id                     <int> 100062145, 100164965, 100241802, 1003…\n#> $ observer_id                      <int> 796344, 2898939, 1676221, 185941, 534…\n#> $ loc_id                           <chr> \"Trax_S100062145\", \"L6626679\", \"Trax_…\n#> $ longitude                        <dbl> -71.5, -71.0, -73.1, -70.2, -71.4, -7…\n#> $ latitude                         <dbl> -32.9, -35.6, -40.6, -33.4, -32.7, -3…\n#> $ is_stationary                    <dbl> 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1…\n#> $ year                             <int> 2021, 2021, 2021, 2012, 2021, 2021, 2…\n#> $ day_of_year                      <dbl> 363, 365, 361, 52, 355, 360, 52, 55, …\n#> $ hours_of_day                     <dbl> 10.95, 12.58, 16.05, 10.50, 9.70, 8.3…\n#> $ solar_noon_diff_mid              <dbl> -2.805, 1.778, 2.178, -2.936, -3.771,…\n#> $ effort_hours                     <dbl> 0.134, 6.000, 0.084, 1.000, 0.567, 1.…\n#> $ effort_distance_km               <dbl> 0.340, 10.000, 0.000, 1.000, 0.000, 0…\n#> $ effort_speed_kmph                <dbl> 2.5373, 1.6667, 0.0000, 1.0000, 0.000…\n#> $ number_observers                 <int> 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1…\n#> $ cds_u10                          <dbl> 1.697, 3.316, 0.665, 1.505, 1.937, 0.…\n#> $ cds_v10                          <dbl> -3.1903, -1.0040, 3.4476, 0.5027, -1.…\n#> $ cds_d2m                          <dbl> 12.541, 5.630, 13.361, -0.621, 12.222…\n#> $ cds_t2m                          <dbl> 14.78, 19.96, 25.15, 12.15, 14.30, 11…\n#> $ cds_hcc                          <dbl> 0.00000, 0.00000, 0.00000, 0.00000, 0…\n#> $ cds_i10fg                        <dbl> 7.26, 12.81, 8.13, 8.37, 5.12, 4.71, …\n#> $ cds_mcc                          <dbl> 0.0000, 0.0000, 0.6003, 0.0000, 0.000…\n#> $ cds_lcc                          <dbl> 0.95340, 0.00000, 0.61487, 0.00000, 0…\n#> $ cds_sf                           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ cds_rf                           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ cds_slc                          <dbl> 65.10, -30.67, -67.19, -41.09, 33.80,…\n#> $ cds_msl                          <dbl> 101779, 101232, 101667, 101732, 10144…\n#> $ eastness_1km_median              <dbl> -0.00411, 0.00732, 0.01700, 0.04960, …\n#> $ eastness_1km_sd                  <dbl> 0.2935, 0.2253, 0.1927, 0.1467, 0.244…\n#> $ eastness_90m_median              <dbl> -3.69e-02, 4.44e-02, -1.63e-03, 3.76e…\n#> $ eastness_90m_sd                  <dbl> 0.04190, 0.25816, 0.02712, 0.28047, 0…\n#> $ northness_1km_median             <dbl> -0.169959, 0.052624, 0.505542, 0.0875…\n#> $ northness_1km_sd                 <dbl> 0.1812, 0.2881, 0.2597, 0.2418, 0.225…\n#> $ northness_90m_median             <dbl> 5.68e-03, -5.46e-02, 9.70e-03, -2.38e…\n#> $ northness_90m_sd                 <dbl> 0.03915, 0.24051, 0.04255, 0.12762, 0…\n#> $ elev_30m_median                  <dbl> 34, 2130, 38, 2833, 76, 2904, 3146, 1…\n#> $ elev_30m_sd                      <dbl> 33.82, 117.60, 16.55, 187.94, 25.46, …\n#> $ elev_250m_median                 <dbl> 43.00, 2137.00, 45.00, 2843.00, 50.50…\n#> $ elev_250m_sd                     <dbl> 38.21, 101.61, 14.22, 181.66, 58.86, …\n#> $ island                           <dbl> 30002, 30002, 30002, 30002, 30002, 30…\n#> $ astwbd_fs_c1_1500_ed             <dbl> 3.38, 0.00, 0.00, 0.00, 5.55, 0.00, 0…\n#> $ astwbd_fs_c1_1500_pland          <dbl> 9.07, 0.00, 0.00, 0.00, 44.78, 0.00, …\n#> $ astwbd_fs_c2_1500_ed             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ astwbd_fs_c2_1500_pland          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ astwbd_fs_c3_1500_ed             <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ astwbd_fs_c3_1500_pland          <dbl> 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.…\n#> $ gp_rtp_1                         <dbl> 0, 0, 537, 0, 0, 0, 0, 0, 718, 0, 0, …\n#> $ gp_rtp_2                         <dbl> 391.3, 0.0, 40.7, 949.0, 328.6, 0.0, …\n#> $ gp_rtp_3                         <dbl> 0.0, 0.0, 24.3, 112.8, 0.0, 41.4, 0.0…\n#> $ gp_rtp_4                         <dbl> 0, 0, 0, 0, 0, 181, 0, 0, 0, 0, 0, 0,…\n#> $ gp_rtp_5                         <dbl> 0, 0, 0, 0, 0, 244, 0, 0, 0, 0, 0, 0,…\n#> $ intertidal_fs_c1_1500_ed         <dbl> 10.045, 0.000, 0.000, 0.000, 7.137, 0…\n#> $ intertidal_fs_c1_1500_pland      <dbl> 1.65, 0.00, 0.00, 0.00, 1.24, 0.00, 0…\n#> $ ntl_mean                         <dbl> 1.75005, 0.00000, 28.90472, 1.67595, …\n#> $ ntl_sd                           <dbl> 1.5571, 0.0000, 14.7225, 2.4289, 1.54…\n#> $ mcd12q1_lccs1_fs_c1_1500_ed      <dbl> 4.20, 14.10, 0.00, 7.19, 0.00, 5.40, …\n#> $ mcd12q1_lccs1_fs_c1_1500_pland   <dbl> 8.33, 36.73, 0.00, 63.89, 0.00, 47.22…\n#> $ mcd12q1_lccs1_fs_c2_1500_ed      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c2_1500_pland   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c11_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c11_1500_pland  <dbl> 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.…\n#> $ mcd12q1_lccs1_fs_c12_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c12_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c13_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c13_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c14_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c14_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c15_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c15_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c16_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c16_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c21_1500_ed     <dbl> 3.60, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c21_1500_pland  <dbl> 5.56, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c22_1500_ed     <dbl> 13.19, 2.64, 3.08, 0.00, 6.68, 0.00, …\n#> $ mcd12q1_lccs1_fs_c22_1500_pland  <dbl> 61.11, 6.12, 89.80, 0.00, 61.90, 0.00…\n#> $ mcd12q1_lccs1_fs_c31_1500_ed     <dbl> 7.79, 2.20, 3.08, 0.00, 3.08, 3.00, 0…\n#> $ mcd12q1_lccs1_fs_c31_1500_pland  <dbl> 22.22, 10.20, 10.20, 0.00, 4.76, 5.56…\n#> $ mcd12q1_lccs1_fs_c32_1500_ed     <dbl> 0.00, 18.06, 0.00, 7.19, 0.00, 8.39, …\n#> $ mcd12q1_lccs1_fs_c32_1500_pland  <dbl> 0.00, 46.94, 0.00, 36.11, 0.00, 47.22…\n#> $ mcd12q1_lccs1_fs_c41_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c41_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c42_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c42_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c43_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c43_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs1_fs_c255_1500_ed    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c255_1500_pland <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c25_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c25_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c35_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c35_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c36_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs2_fs_c36_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs3_fs_c27_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 2.06, 0.00, 0…\n#> $ mcd12q1_lccs3_fs_c27_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 2.38, 0.00, 0…\n#> $ mcd12q1_lccs3_fs_c50_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs3_fs_c50_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0…\n#> $ mcd12q1_lccs3_fs_c51_1500_ed     <dbl> 0.0, 0.0, 0.0, 0.0, 0.0, 2.4, 0.0, 0.…\n#> $ mcd12q1_lccs3_fs_c51_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 2.78, 0…\n\nThere are a huge number of columns in this data frame. The first set of variables provide standard information about the checklist: where and when did the observation occur, what type of search was conducted, and how much search effort was expended. Two important differences exist between these variables and what you will see if you look at the raw eBird dataset: when a GPS track is available we replace the checklist or hotspot location (latitude/longitude) with the centroid of the track and the time of the checklist is expressed as the difference between the checklist midpoint and solar noon, a more ecologically meaningful quantity.\nAll the remaining variables are not collected in eBird, they’re calculated and added by the Status and Trends team based on external data sets. First, those variables beginning with cds_, provides information about the weather at the time of the observation, which can impact detectibility. This is followed by a large suite of environmental variables summarized over a 3km diameter circular neighborhood around the checklist location, including variables describing: elevation and topography, land and water cover, roads, and night time lights (a proxy for urban development). Most variables are summarized as two quantities expressing composition (what habitat is available) and configuration (how that habitat is arranged spatially). For continuous variables, such as elevation, we use the median and standard deviation. For categorical variables, such as land cover class, we use percent landcover (pland) and edge density (ed).\n\n\n\nExample of calculating percent land cover and edge density for a 3km diamter circular neighborhood centered on a checklist location. pland for each class is the percent of the circle covered by that class. To calculate ed for each class, we add up the perimeter lengths of all patches of that class, then divide by the area of the circle.\n\n\nThe land and water cover variables can be challenging to interpret based on their names alone (e.g. mcd12q1_lccs1_fs_c12_1500_pland); however, these names can be looked up in the ebirdst_predictors data frame from the ebirdst package. For example, let’s look up what mcd12q1_lccs1_fs_c12_1500_pland corresponds to.\n\nfilter(ebirdst_predictors, predictor == \"mcd12q1_lccs1_fs_c12_1500_pland\") %>% \n  select(predictor, predictor_label)\n#> # A tibble: 1 × 2\n#>   predictor                       predictor_label                  \n#>   <chr>                           <chr>                            \n#> 1 mcd12q1_lccs1_fs_c12_1500_pland Evergreen Broadleaf Forests PLAND\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nTake some time to explore the variables in the checklist dataset. Try looking up a variable in ebirst_predictors. Ask for help if you need clarification on the meaning of any of the variables.\n\n\nNow let’s look at the observation dataset.\n\nobservations <- read_parquet(\"data/ebird_observations_chile_2021.parquet\")\nglimpse(observations)\n#> Rows: 2,167,999\n#> Columns: 5\n#> $ checklist_id           <dbl> 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08, 1e+08…\n#> $ species_code           <chr> \"eardov1\", \"blcsis2\", \"gyhsif1\", \"houwre\", \"reb…\n#> $ only_presence_reported <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,…\n#> $ valid                  <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#> $ obs_count              <int> 2, 4, 2, 1, 1, 3, 1, 4, 1, NA, 1, NA, NA, NA, N…\n\nThis is a much simpler dataset with only five columns:\n\nchecklist_id: unique identifier for the checklist that this observation belongs to. Allows joining the observation data to the checklist data.\nspecies_code: unique identifier for the species that this observation was made for.\nonly_presence_reported: a binary variable indicating if a count of the number of individuals seen was provided for the species (0) or if an “X” was used to indicate the species was detected but not counted (1).\nvalid: a binary variable indicating is the observation was determined to be valid (1) or invalid (0) by the eBird reviewers.\nobs_count: count of the number of individuals or an NA if no count was provided.\n\n\n\n\n\n\n\nTip\n\n\n\nTo look up the common name or scientific name of a species try appending the species code to the URL https://ebird.org/species/. For example, visit https://ebird.org/species/eardov1 to look up the species code eardov1. This information is also available in the ebird_taxonomy data frame in the auk package.\n\nfilter(ebird_taxonomy, species_code == \"eardov1\") %>% \n  select(species_code, common_name, scientific_name, family)\n#>   species_code common_name    scientific_name     family\n#> 1      eardov1  Eared Dove Zenaida auriculata Columbidae"
  },
  {
    "objectID": "ebird.html#sec-ebird-zf",
    "href": "ebird.html#sec-ebird-zf",
    "title": "1  eBird Data",
    "section": "1.2 Zero-filling eBird data",
    "text": "1.2 Zero-filling eBird data\nComplete eBird checklists are extremely valuable because, for all species that weren’t reported, we can infer counts of 0. This allows us to convert eBird from presence only data to detection/non-detection data, which allows for much more robust analyses. Note that we don’t use the term presence/absence data here because a non-detection doesn’t necessarily imply the species was absent, only that observer wasn’t able to detect and identify it.\nWe refer to the process of producing detection/non-detection data as “zero-filling” the eBird data because we’re filling in the missing zeros. Let’s consider observations of Chucao Tapaculo (species code chutap1).\n\nchutap1_detections <- observations %>% \n  filter(species_code == \"chutap1\") %>% \n  select(checklist_id, valid, obs_count) %>% \n  mutate(obs_detected = 1L)\n\nNext join this set of detections to the complete set of checklists, including detections and non-detections.\n\nchutap1_all <- left_join(checklists, chutap1_detections, by = \"checklist_id\") %>%\n  select(checklist_id, latitude, longitude, year, day_of_year,\n         valid, obs_count, obs_detected)\nhead(chutap1_all)\n#> # A tibble: 6 × 8\n#>   checklist_id latitude longitude  year day_of_year valid obs_count obs_detected\n#>          <dbl>    <dbl>     <dbl> <int>       <dbl> <int>     <int>        <int>\n#> 1    100062145    -32.9     -71.5  2021         363    NA        NA           NA\n#> 2    100164965    -35.6     -71.0  2021         365     1        NA            1\n#> 3    100241802    -40.6     -73.1  2021         361    NA        NA           NA\n#> 4     10034436    -33.4     -70.2  2012          52    NA        NA           NA\n#> 5    100385722    -32.7     -71.4  2021         355    NA        NA           NA\n#> 6    100390786    -33.3     -70.3  2021         360    NA        NA           NA\n\nFinally, for rows where Chucao Tapaculo was not detected we can replace the missing counts with 0. At this time, we recommend removing any checklists with valid == 0 because there is uncertainty about whether or not the species was detected.\n\nchutap1_zf <- chutap1_all %>% \n  filter(is.na(valid) | valid == 1) %>% \n  mutate(\n    # checklist not in the observations dataset are non-detections\n    obs_detected = coalesce(obs_detected, 0L),\n    # non-detections correspond to a count of 0\n    obs_count = if_else(obs_detected == 1, obs_count, 0)\n  )\n\nWe can now, for example, make a map of Chucao Tapaculo observations in the Chilean region of Los Lagos We’ll use spatial data that was prepared in advance and provided in the data package.\n\n# load and project gis data\nmap_proj <- \"+proj=laea +lat_0=-40 +lon_0=-72\"\nne_land <- read_sf(\"data/gis-data.gpkg\", \"ne_land\") %>% \n  st_transform(crs = map_proj) %>% \n  st_geometry()\nne_country_lines <- read_sf(\"data/gis-data.gpkg\", \"ne_country_lines\") %>% \n  st_transform(crs = map_proj) %>% \n  st_geometry()\nne_state_lines <- read_sf(\"data/gis-data.gpkg\", \"ne_state_lines\") %>% \n  st_transform(crs = map_proj) %>% \n  st_geometry()\nlos_lagos <- read_sf(\"data/gis-data.gpkg\", \"ne_states\") %>% \n  filter(state_code == \"CL-LL\") %>% \n  st_transform(crs = map_proj) %>% \n  st_geometry()\n\n# prepare ebird data for mapping\nchutap1_sf <- chutap1_zf %>% \n  # convert to spatial points\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>% \n  st_transform(crs = map_proj)\n\n# map\npar(mar = c(0.25, 0.25, 0.25, 0.25))\n# set up plot area\nplot(st_geometry(los_lagos), col = NA, border = NA)\n# contextual gis data\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\nplot(los_lagos, col = \"#e6e6e6\", border = NA, add = TRUE)\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\n# ebird observations\n# all\nplot(chutap1_sf,\n     pch = 19, cex = 0.1, col = scales::alpha(\"#555555\", 0.25),\n     add = TRUE)\n#> Warning in plot.sf(chutap1_sf, pch = 19, cex = 0.1, col =\n#> scales::alpha(\"#555555\", : ignoring all but the first attribute\n# detection\nplot(filter(chutap1_sf, obs_detected == 1),\n     pch = 19, cex = 0.3, col = scales::alpha(\"#4daf4a\", 1),\n     add = TRUE)\n#> Warning in plot.sf(filter(chutap1_sf, obs_detected == 1), pch = 19, cex = 0.3,\n#> : ignoring all but the first attribute\n# legend\nlegend(\"bottomright\", bty = \"n\",\n       col = c(\"#555555\", \"#4daf4a\"),\n       legend = c(\"eBird checklists\", \"Chucao Tapaculo sightings\"),\n       pch = 19)\nbox()\npar(new = TRUE, mar = c(0, 0, 3, 0))\ntitle(\"Chucao Tapaculo eBird Observations\\nJune 2007-2021\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry producing zero-filled, detection/non-detection data for another species.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFor example, to produce detection/non-detection data for Thorn-tailed Rayadito use:\n\nthtray1_zf <- observations %>% \n  filter(species_code == \"thtray1\") %>% \n  mutate(obs_detected = 1) %>% \n  left_join(checklists, ., by = \"checklist_id\") %>% \n  filter(is.na(valid) | valid == 1) %>% \n  mutate(obs_detected = coalesce(obs_detected, 0),\n         obs_count = if_else(obs_detected == 1, obs_count, 0)) %>% \n  select(checklist_id, obs_detected, obs_count)\nhead(thtray1_zf)\n#> # A tibble: 6 × 3\n#>   checklist_id obs_detected obs_count\n#>          <dbl>        <dbl>     <dbl>\n#> 1    100062145            0         0\n#> 2    100164965            1        NA\n#> 3    100241802            0         0\n#> 4     10034436            0         0\n#> 5    100385722            0         0\n#> 6    100390786            0         0"
  },
  {
    "objectID": "ebird.html#sec-ebird-pred",
    "href": "ebird.html#sec-ebird-pred",
    "title": "1  eBird Data",
    "section": "1.3 Prediction grid",
    "text": "1.3 Prediction grid\nThe ultimate goal of modeling the occurrence or abundance of a species is frequently to produce a map showing the distribution of that species in space. To do so, we need to know the values of our predictor variables over the region that we intend to make predictions. To make this possible, the ERD is distributed with a prediction grid: a regular grid of points covering the entire globe spaced 3km apart for which all the environmental variables have been calculated for the year 2021. Internally, we often refer to this prediction grid as the Spatial Reference Dataset (SRD).\nThe data package for this course contains a subset of the prediction grid for Chile. The file data/ebird_prediction-grid_chile_2021.parquet contains the environmental variables for each point on the grid and the file data/prediction-grid_template.tif is a 3km by 3km raster template where each each cell center is a point on the prediction grid. Let’s start by examining the environmental variables.\n\nprediction_grid <- read_parquet(\"data/ebird_prediction-grid_chile_2021.parquet\")\nglimpse(prediction_grid)\n#> Rows: 151,313\n#> Columns: 83\n#> $ srd_id                           <int> 54237418, 54237419, 54237420, 5423742…\n#> $ longitude                        <dbl> -69.4, -69.4, -69.4, -69.3, -69.3, -6…\n#> $ latitude                         <dbl> -17, -17, -17, -17, -17, -17, -17, -1…\n#> $ eastness_1km_median              <dbl> -0.058229, -0.044364, -0.047317, -0.0…\n#> $ eastness_1km_sd                  <dbl> 0.2181, 0.1155, 0.2455, 0.1704, 0.266…\n#> $ eastness_90m_median              <dbl> 0.06977, 0.03524, 0.00753, -0.02868, …\n#> $ eastness_90m_sd                  <dbl> 0.1154, 0.1539, 0.1562, 0.0899, 0.112…\n#> $ northness_1km_median             <dbl> 0.01759, -0.00286, 0.02578, 0.08451, …\n#> $ northness_1km_sd                 <dbl> 0.236, 0.251, 0.125, 0.278, 0.253, 0.…\n#> $ northness_90m_median             <dbl> -0.00962, -0.01659, 0.00475, -0.01966…\n#> $ northness_90m_sd                 <dbl> 0.1396, 0.1397, 0.0844, 0.1282, 0.136…\n#> $ elev_30m_median                  <dbl> 4271, 4073, 4051, 4008, 4167, 4116, 4…\n#> $ elev_30m_sd                      <dbl> 76.5, 65.6, 104.6, 73.8, 82.4, 34.0, …\n#> $ elev_250m_median                 <dbl> 4269, 4083, 4063, 4018, 4181, 4131, 4…\n#> $ elev_250m_sd                     <dbl> 72.6, 58.7, 98.3, 73.8, 71.4, 30.8, 3…\n#> $ island                           <dbl> 30002, 30002, 30002, 30002, 30002, 30…\n#> $ astwbd_fs_c1_1500_ed             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ astwbd_fs_c1_1500_pland          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ astwbd_fs_c2_1500_ed             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ astwbd_fs_c2_1500_pland          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ astwbd_fs_c3_1500_ed             <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ astwbd_fs_c3_1500_pland          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ gp_rtp_1                         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ gp_rtp_2                         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ gp_rtp_3                         <dbl> 0.0, 505.6, 189.7, 132.4, 0.0, 219.8,…\n#> $ gp_rtp_4                         <dbl> 0.0, 0.0, 586.0, 321.2, 0.0, 678.3, 7…\n#> $ gp_rtp_5                         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ intertidal_fs_c1_1500_ed         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ intertidal_fs_c1_1500_pland      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ ntl_mean                         <dbl> 0.000, 0.000, 0.000, 0.000, 0.000, 0.…\n#> $ ntl_sd                           <dbl> 0.000, 0.000, 0.000, 0.000, 0.000, 0.…\n#> $ mcd12q1_lccs1_fs_c1_1500_ed      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c1_1500_pland   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c2_1500_ed      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c2_1500_pland   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c11_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c11_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c12_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c12_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c13_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c13_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c14_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c14_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c15_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c15_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c16_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c16_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c21_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c21_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c22_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c22_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c31_1500_ed     <dbl> 7.71, 11.99, 8.39, 13.88, 5.40, 7.19,…\n#> $ mcd12q1_lccs1_fs_c31_1500_pland  <dbl> 42.86, 66.67, 80.56, 38.10, 16.67, 78…\n#> $ mcd12q1_lccs1_fs_c32_1500_ed     <dbl> 9.76, 9.59, 6.00, 7.19, 11.39, 0.00, …\n#> $ mcd12q1_lccs1_fs_c32_1500_pland  <dbl> 26.19, 16.67, 13.89, 14.29, 33.33, 0.…\n#> $ mcd12q1_lccs1_fs_c41_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c41_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c42_1500_ed     <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 2.57, 4…\n#> $ mcd12q1_lccs1_fs_c42_1500_pland  <dbl> 0.00, 0.00, 0.00, 0.00, 0.00, 7.14, 2…\n#> $ mcd12q1_lccs1_fs_c43_1500_ed     <dbl> 7.19, 4.80, 3.60, 16.96, 14.39, 4.63,…\n#> $ mcd12q1_lccs1_fs_c43_1500_pland  <dbl> 30.95, 16.67, 5.56, 47.62, 50.00, 14.…\n#> $ mcd12q1_lccs1_fs_c255_1500_ed    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs1_fs_c255_1500_pland <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c25_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c25_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c35_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c35_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c36_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c36_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs3_fs_c27_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs3_fs_c27_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs3_fs_c50_1500_ed     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs3_fs_c50_1500_pland  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs3_fs_c51_1500_ed     <dbl> 1.54, 0.00, 0.00, 0.00, 1.80, 1.54, 1…\n#> $ mcd12q1_lccs3_fs_c51_1500_pland  <dbl> 2.38, 0.00, 0.00, 0.00, 2.78, 2.38, 2…\n#> $ mod44w_oic_fs_c1_1500_ed         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mod44w_oic_fs_c1_1500_pland      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mod44w_oic_fs_c2_1500_ed         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mod44w_oic_fs_c2_1500_pland      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mod44w_oic_fs_c3_1500_ed         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mod44w_oic_fs_c3_1500_pland      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c9_1500_ed      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#> $ mcd12q1_lccs2_fs_c9_1500_pland   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\nThese variables should be mostly familiar from the ERD, except for srd_id which is a unique identifier for each point on the grid. Next let’s load the raster template using the terra package.\n\nraster_template <- rast(\"data/prediction-grid_template.tif\")\nraster_template\n#> class       : SpatRaster \n#> dimensions  : 5630, 13511, 1  (nrow, ncol, nlyr)\n#> resolution  : 2963, 2963  (x, y)\n#> extent      : -2e+07, 2e+07, -6673060, 1e+07  (xmin, xmax, ymin, ymax)\n#> coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#> source      : prediction-grid_template.tif \n#> name        : mask \n#> min value   :    1 \n#> max value   :    1\n\nThis is a global 2.96km by 2.96km square grid in a equal area projection. We can use the terra function rasterize to insert values from the prediction grid into the template for mapping. For example, let’s make a raster dataset of percent cover of evergreen broadleaf forest (mcd12q1_lccs1_fs_c12_1500_pland).\n\nforest_cover <- prediction_grid %>% \n  # convert to spatial object using sf\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>% \n  # transform to the coordinate reference system of the raster\n  st_transform(crs = crs(raster_template)) %>% \n  # rasterize the points using the raster template\n  rasterize(raster_template, field = \"mcd12q1_lccs1_fs_c12_1500_pland\")\n\nNow we can make a simple map of evergreen broadleaf forest for Chile. Not that the raster template is global, but we can use trim() to remove all areas that have missing values for a map of Chile only.\n\nplot(trim(forest_cover), axes = FALSE)\n\n\n\n\n\n\n\n\nThe map looks distorted because the prediction grid uses a sinusoidal projection, which works well for analysis but not for mapping. In the next lesson, we’ll demonstrate how to project data into a coordinate reference system more suitable for mapping."
  },
  {
    "objectID": "ebird.html#sec-ebird-bias",
    "href": "ebird.html#sec-ebird-bias",
    "title": "1  eBird Data",
    "section": "1.4 Spatial and temporal bias",
    "text": "1.4 Spatial and temporal bias\nDespite the strengths of eBird data, species observations collected through citizen science projects exhibit both spatial and temporal bias requiring special care when using them for rigorous analyses. Spatial bias occurs because eBird participants are more likely to be collect data near their homes, in easily accessible areas such as roadsides, or in areas known to be good for birding. Looking at the above map of Chucao Tapaculo observations it’s clear that the eBird checklists are clustered around cities and roads. Temporal bias occurs because participants preferentially collect data when they are available, such as weekends, and at times of year when they expect to observe more birds, notably during the breeding season. We can plot the distribution of checklists over the days of the year to see this bias:\n\nchecklist_per_day <- checklists %>% \n  filter(day_of_year < 366) %>% \n  count(day_of_year)\nggplot(checklist_per_day) +\n  aes(x = day_of_year, y = n) +\n  geom_line() +\n  scale_y_continuous(labels = scales::comma) +\n  labs(x = \"Day of Year\", y = \"# checklists\",\n       title = \"Daily eBird checklists submission\") +\n  theme_gray()\n\n\n\n\n\n\n\n\nThree is a clear seasonal pattern to the number of eBird checklists submitted (fewer checklists in the winter) as well as daily and weekly variation within seasons. In addition, there are two huge spikes in checklists submissions, one in May and the other in October, what do you think could be causing these sudden increases?\nFinally, for most species, there is strong class imbalance in the data, meaning there are usually many more non-detections than detections. As a results, a distribution model predicting that the species is absent everywhere will have high accuracy, but no ecological value. For example, the prevalence rate of Chucao Tapaculo in Chile is only 5%.\n\nmean(chutap1_zf$obs_detected)\n#> [1] 0.0518\n\nTo address these three issues (spatial bias, temporal bias, and class imbalance) we recommend subsampling the data using a technique called case controlled grid sampling. We overlay an equal area 3km by 3km grid over the checklists, then sample one detection and one non-detection from each grid cell for each week of each year. Let’s look at a simple example of how spatial grid sampling works.”\n\n\n\n1. Take one week of eBird observations. Detections are show in green and non-detections are shown in gray.\n\n\n\n\n\n2. Separate the detections and non-detections. In this example, there is a higher density of observations in the lower right corner of the region and the prevalence of detections is 2%.\n\n\n\n\n\n3. Overlay an equal area grid on top of the points, For Status and Trends we use a 3km by 3km grid.\n\n\n\n\n\n4. Sample one checklist from each grid cell.\n\n\n\n\n\n5. Recombine the detections and non-detections. The observations are much more evenly distributed in space and the prevalence of detections has increased from 2% to 20%.\n\n\nThe function grid_sample_stratified() from the ebirdst package is specifically designed to perform case controlled grid sampling on eBird data. For example, let’s apply this technique to the Chucao Tapaculo observations.\n\n# perform case controlled grid sampling\nchutap1_sampled <- grid_sample_stratified(chutap1_zf, \n                                          obs_column = \"obs_detected\")\n\n# how many checklists were removed?\nnrow(chutap1_zf)\n#> [1] 186906\nnrow(chutap1_sampled)\n#> [1] 77265\n\n# how has prevalence changed\nmean(chutap1_zf$obs_detected)\n#> [1] 0.0518\nmean(chutap1_sampled$obs_detected)\n#> [1] 0.0728\n\nSo, after sampling, we’re left with 41% of the observations we started with, but the spatial and temporal bias has been significantly reduced.\nWe now have the data and tools necessary to model relative abundance using eBird data, which will be the focus of Lesson 2."
  },
  {
    "objectID": "abundance.html#sec-abundance-data",
    "href": "abundance.html#sec-abundance-data",
    "title": "2  Modeling Relative Abundance",
    "section": "2.1 Data preparation",
    "text": "2.1 Data preparation\nLet’s start by reading the eBird data into R and zero-filling it to produce detection/non-detection data for Chucao Tapaculo.\n\nlibrary(arrow)\nlibrary(auk)\nlibrary(dplyr)\nlibrary(ebirdst)\nlibrary(fields)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(mccf1)\nlibrary(ranger)\nlibrary(scam)\nlibrary(sf)\nlibrary(terra)\n\n# set seed for reproducibility\nset.seed(1)\n\n# detections\nobservations <- read_parquet(\"data/ebird_observations_chile_2021.parquet\") %>% \n  filter(species_code == \"chutap1\") %>% \n  select(checklist_id, valid, obs_count) %>% \n  mutate(obs_detected = 1L)\n\n# zero filled checklists\nchecklists <- read_parquet(\"data/ebird_checklists_chile_2021.parquet\") %>%\n  left_join(observations, by = \"checklist_id\") %>% \n  filter(is.na(valid) | valid == 1) %>% \n  mutate(\n    # checklist not in the observations dataset are non-detections\n    obs_detected = coalesce(obs_detected == 1, 0L),\n    # non-detections correspond to a count of 0\n    obs_count = ifelse(obs_detected == 1, obs_count, 0)\n  )\n\nNext let’s subset the data to only observations from January and February, summer months during which we expect detectability and habitat associations to be stationary. To reduce variation in detecatability, we’ll also subset the data to only those checklists less than 24 hours in duration and 10km in length, at speeds below 100km/h, and with 10 or fewer observers. Furthermore, we’ll only consider data from the past 15 years (2007-2021).\n\nchecklists <- checklists %>% \n  filter(\n    # last 10 years of data\n    year >= 2013,\n    # jan-feb\n    day_of_year >= 1, day_of_year <= 59,\n    # effort filters\n    effort_hours <= 24,\n    effort_distance_km <= 10,\n    effort_speed_kmph <= 100,\n    number_observers <= 10)\n\nFor the final filtering step, we’ll use spatial boundaries included in the data package to subset observations to only those from Araucanía, Los Ríos, and Los Lagos.\n\nstudy_region <- read_sf(\"data/gis-data.gpkg\", layer = \"ne_states\") %>%\n  filter(state_code %in% c(\"CL-AR\", \"CL-LR\", \"CL-LL\"))\n\n# subset to regions of interest\nin_region <- checklists %>%\n  select(checklist_id, latitude, longitude) %>%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>%\n  st_join(study_region, left = FALSE) %>%\n  st_drop_geometry()\nchecklists <- semi_join(checklists, in_region, by = \"checklist_id\")\n\n\n2.1.1 Test-train split\nWe’ll hold aside a portion of the observations from training to be used as an independent test set to assess the predictive performance of the model. Specifically, we’ll randomly split the data into 80% of observations for training and 20% for testing. To help with this, we create a new variable type that will indicate whether the observation falls in the test set or training set.\n\nchecklists$type <- ifelse(runif(nrow(checklists)) <= 0.8, \"train\", \"test\")\n# confirm the proportion in each set is correct\ntable(checklists$type) / nrow(checklists)\n#> \n#>  test train \n#> 0.208 0.792\n\n\n\n2.1.2 Case controlled grid sampling\nFollowing the method outlined in Section 1.4, we perform a round of case controlled grid sampling on the data to reduce spatial and temporal bias as well as class imbalance. We can use the sample_by argument to grid_sample_stratified() to independently sample from the train and test sets to remove bias from both.\n\nchecklists_sampled <- grid_sample_stratified(checklists,\n                                             obs_column = \"obs_detected\",\n                                             sample_by = \"type\")\n\nHow did this impact the prevalence of detections compared to non-detections?\n\n# original data\nnrow(checklists)\n#> [1] 6171\ncount(checklists, obs_detected) %>% \n  mutate(percent = n / sum(n))\n#> # A tibble: 2 × 3\n#>   obs_detected     n percent\n#>          <int> <int>   <dbl>\n#> 1            0  4460   0.723\n#> 2            1  1711   0.277\n\n# after sampling\nnrow(checklists_sampled)\n#> [1] 3187\ncount(checklists_sampled, obs_detected) %>% \n  mutate(percent = n / sum(n))\n#> # A tibble: 2 × 3\n#>   obs_detected     n percent\n#>          <int> <int>   <dbl>\n#> 1            0  2139   0.671\n#> 2            1  1048   0.329\n\nSo, the case controlled sampling decreased the overall number of checklists by a factor of 1.9, but increased the prevalence of detections. This increase in detections will help the random forests model distinguish where birds are being observed; however, this does affect the prevalence rate of the detections in the data. As a result, the estimated encounter rate based on these subsampled data will be larger than the true encounter rate. When examining the outputs from the models it will be important to recall that we altered the prevalence rate at this stage."
  },
  {
    "objectID": "abundance.html#sec-abundance-hurdle",
    "href": "abundance.html#sec-abundance-hurdle",
    "title": "2  Modeling Relative Abundance",
    "section": "2.2 Hurdle model",
    "text": "2.2 Hurdle model\nFor this two-step hurdle model, we’ll start by training an random forests model for encounter rate. Then we’ll subset the eBird checklist to only those where the species was detected or predicted to occur by the encounter rate model. We’ll use this subset of the data to train a second random forests model for expected count. Finally we’ll combine the results of the two steps together to produce estimates of relative abundance.\nLet’s start by select by removing the 20% of checklists held aside for testing and selecting only those columns we’ll use as response or predictor variables in the models.\n\nchecklists_train <- checklists_sampled %>%\n  filter(type == \"train\") %>% \n  select(checklist_id,\n         obs_detected, obs_count,\n         is_stationary,\n         year, day_of_year, solar_noon_diff_mid,\n         effort_hours, effort_distance_km, effort_speed_kmph,\n         number_observers,\n         eastness_1km_median, eastness_1km_sd,\n         eastness_90m_median, eastness_90m_sd,\n         northness_1km_median, northness_1km_sd,\n         northness_90m_median, northness_90m_sd,\n         elev_250m_median, elev_250m_sd,\n         intertidal_fs_c1_1500_ed, intertidal_fs_c1_1500_pland,\n         ntl_mean, ntl_sd,\n         starts_with(\"astwbd\"),\n         starts_with(\"gp_rtp\"),\n         starts_with(\"mcd12q1\"))\n\n\n2.2.1 Step 1: Encounter rate\nFor the first step of the hurdle model we’ll train a random forests model to estimate the probability of detection/non-detection of Chucao Tapaculo, a binary classification problem. Random forests are an excellent, general purpose machine learning method suitable for modeling encounter rate in a wide variety of scenarios.\nMost classification algorithms aim to minimize the overall error rate, which results in poor predictive performance for rare classes. To address this issue, we’ll use a balanced random forests approach, a modification of the traditional random forest algorithm designed to handle imbalanced data. In this approach, each of the trees that makes up the random forest is generated using a random sample of the data chosen such that there are an equal number of detections (the rare class) and non-detections (the common class). To use this approach, we’ll need to calculate the proportion of detections in the dataset.\n\ndetection_freq <- mean(checklists_train$obs_detected)\n\nWe’re now ready to train the encounter rate random forests model using the ranger package. Rather than writing out a complete model formula, we’ll use the ~ . notation to instruct the ranger() to use all variables as predictors. We just need to be cautious to remove both checklist_id and obs_count from the data frame. Since this is a classification problem, we also need to convert the response variable (obs_detected) to a factor variable.\n\ntrain_er <- select(checklists_train, -checklist_id, -obs_count)\ner_model <- ranger(formula =  as.factor(obs_detected) ~ ., \n                   data = train_er,\n                   importance = \"impurity\",\n                   # this ensures ranger predicts class probabilities\n                   # not just the most likely class\n                   probability = TRUE,\n                   # implement a balanced random forests\n                   replace = TRUE, \n                   sample.fraction = c(detection_freq, detection_freq))\n\nPredicted probabilities from a random forests model do not always line up with the observed frequency of detection. We’ll address this mismatch using model calibration, which aligns the estimated probabilities to the observed frequencies. In particular, to calibrate our model results, we predict encounter rate for each checklist in the training set, then fit a binomial Generalized Additive Model (GAM) with the real observations as the response and the predicted encounter rate as the predictor variable.\n\n# predicted encounter rate and observed detection\nobs_pred <- tibble(obs = train_er$obs_detected, \n                   pred = er_model$predictions[, 2])\n\n# fit calibration model\ncalibration_model <- scam(obs ~ s(pred, k = 6, bs = \"mpi\"), \n                          gamma = 2,\n                          data = obs_pred)\n\nThe random forest model produces continuous estimates of encounter rate from 0-1. However, for many applications, including selecting which observations are included in the next stage of the hurdle, we’ll need to reclassify this continuous probability to a binary presence/absence estimate. This reclassification is done by setting a threshold above which the species is predicted to be absent. We recommend selecting a threshold using the MCC-F1 curve, which performs well for class imbalanced data. The R package mccf1 implements this method.\n\n# mcc and fscore calculation for various thresholds\nmcc_f1 <- mccf1(response = obs_pred$obs, predictor = obs_pred$pred)\n\n# identify best threshold\nmcc_f1_summary <- summary(mcc_f1)\n#>  mccf1_metric best_threshold\n#>         0.518          0.473\nthreshold <- mcc_f1_summary$best_threshold[1]\n\n\n\n2.2.2 Step 2: Count\nFor the second step of the hurdle model, we train a random forests model to estimate the expected count of individuals on eBird checklists where the species was detected or predicted to be detected by the encounter rate model. So, we’ll start by subsetting the data to just these checklists. In addition, we’ll remove any observations for which the observer reported that Chucao Tapaculo was present, but didn’t report a count of the number of individuals (coded as a count of “X” in the eBird database, but converted to NA in our dataset).\n\n# attach the predicted encounter rate\ntrain_count <- checklists_train\ntrain_count$pred_er <- er_model$predictions[, 2]\n# subset to only observed or predicted detections\ntrain_count <- train_count %>% \n  filter(!is.na(obs_count), \n         obs_count > 0 | pred_er > threshold) %>% \n  select(-checklist_id, -obs_detected, -pred_er)\n\nWe’ve found that including estimated encounter rate as a predictor in the count model improves predictive performance. So, with this in mind, we predict encounter rate for the training dataset and add it as an additional column.\n\npredicted_er <- predict(er_model, data = train_count, type = \"response\")\npredicted_er <- predicted_er$predictions[, 2]\ntrain_count$predicted_er <- predicted_er\n\nFinally, we train a random forests model to estimate count. This is superficially very similar to the random forests model for encounter rate; however, for count we’re using a regression random forest while for encounter rate we used a balanced classification random forest.\n\ncount_model <- ranger(formula = obs_count ~ .,\n                      data = train_count,\n                      importance = \"impurity\",\n                      replace = TRUE)\n\n\n\n2.2.3 Assessment\nTo assess the quality of the encounter rate, count, and relative abundance models, we’ll validate the their ability to predict the observed patterns of detection and counts using independent validation data (i.e. the 20% test data set). There are a range of predictive performance metrics (PPMs) that can be used to compare the predictions to the actual observations. We’ll start by estimating encounter rate, count, and relative abundance for the spatiotemporally grid sampled test dataset.\n\n# get the test set held out from training\nchecklists_test <- filter(checklists_sampled, type == \"test\")\n\n# estimate encounter rate for test data\npred_er <- predict(er_model, data = checklists_test, type = \"response\")\n# extract probability of detection\npred_er <- pred_er$predictions[, 2]\n# convert to binary using the threshold\npred_binary <- as.integer(pred_er > threshold)\n# calibrate\npred_calibrated <- predict(calibration_model, \n                           newdata = data.frame(pred = pred_er), \n                           type = \"response\") %>% \n  as.numeric()\n# constrain probabilities to 0-1\npred_calibrated <- pmin(pmax(pred_calibrated, 0), 1)\n\n# add predicted encounter rate required for count estimates\nchecklists_test$predicted_er <- pred_er\n# estimate count\npred_count <- predict(count_model, data = checklists_test, type = \"response\")\npred_count <- pred_count$predictions\n\n# relative abundance is the product of encounter rate and count\npred_abundance <- pred_calibrated * pred_count\n\n# combine all estimates together\nobs_pred_test <- data.frame(\n  id = seq_along(pred_abundance),\n  # actual detection/non-detection\n  obs_detected = checklists_test$obs_detected,\n  obs_count = checklists_test$obs_count,\n  # model estimates\n  pred_binary = pred_binary,\n  pred_er = pred_calibrated,\n  pred_count = pred_count,\n  pred_abundance = pred_abundance\n)\n\nFirst we’ll calculate a suite of PPMs for the encounter rate model.\n\n# mean squared error (mse)\nmse <- mean((obs_pred_test$obs_detected - obs_pred_test$pred_er)^2, \n            na.rm = TRUE)\n\n# spearman correlation, based on in range observations only\nspearman <- cor(obs_pred_test$pred_er[obs_pred_test$pred_binary > 0], \n                obs_pred_test$obs_detected[obs_pred_test$pred_binary > 0], \n                method = \"spearman\")\n\n# precision-recall auc\nem <- precrec::evalmod(scores = obs_pred_test$pred_binary, \n                       labels = obs_pred_test$obs_detected)\npr_auc <- precrec::auc(em) %>% \n  filter(curvetypes == \"PRC\") %>% \n  pull(aucs)\n\n# calculate metrics for binary prediction: kappa, sensitivity, specificity\npa_metrics <- obs_pred_test %>% \n  select(id, obs_detected, pred_binary) %>% \n  PresenceAbsence::presence.absence.accuracy(na.rm = TRUE, st.dev = FALSE)\n\n# mcc and f1\nmcc_f1 <- calculate_mcc_f1(obs_pred_test$obs_detected, \n                           obs_pred_test$pred_binary)\n\n# combine metrics together\nppms <- tibble(\n  mse = mse,\n  spearman = spearman,\n  sensitivity = pa_metrics$sensitivity,\n  specificity = pa_metrics$specificity,\n  kappa = pa_metrics$Kappa,\n  pr_auc = pr_auc,\n  mcc = mcc_f1$mcc,\n  f1 = mcc_f1$f1\n)\nknitr::kable(ppms, digits = 3)\n\n\n\n\nmse\nspearman\nsensitivity\nspecificity\nkappa\npr_auc\nmcc\nf1\n\n\n\n\n0.133\n0.291\n0.816\n0.795\n0.571\n0.605\n0.58\n0.721\n\n\n\n\n\nThe count and abundance predictive performance metrics are measures of within range performance, meaning we compare observed count vs. estimated count and abundance only for those checklists where the model predicts the species to occur.\n\n# subset to only those checklists where detection is predicted\ndetections_test <- filter(obs_pred_test, \n                          pred_binary > 0,\n                          !is.na(obs_count))\n\n# count metrics\ncount_spearman <- cor(detections_test$pred_count, \n                      detections_test$obs_count,\n                      method = \"spearman\")\nlog_count_pearson <- cor(log(detections_test$pred_count + 1),\n                         log(detections_test$obs_count + 1),\n                         method = \"pearson\")\n\n# abundance metrics\nabundance_spearman <- cor(detections_test$pred_abundance, \n                          detections_test$obs_count,\n                          method = \"spearman\")\nlog_abundance_pearson <- cor(log(detections_test$pred_abundance + 1),\n                             log(detections_test$obs_count + 1),\n                             method = \"pearson\")\n\n# combine metrics together\nppms <- tibble(\n  count_spearman = count_spearman,\n  log_count_pearson = log_count_pearson,\n  abundance_spearman = abundance_spearman,\n  log_abundance_pearson = log_abundance_pearson\n)\nknitr::kable(ppms, digits = 3)\n\n\n\n\n\n\n\n\n\n\ncount_spearman\nlog_count_pearson\nabundance_spearman\nlog_abundance_pearson\n\n\n\n\n0.436\n0.493\n0.455\n0.515\n\n\n\n\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nLet’s take a moment to consider these predictive performance metrics. How would the importance of different metrics change based on your intended application?"
  },
  {
    "objectID": "abundance.html#sec-abundance-habitat",
    "href": "abundance.html#sec-abundance-habitat",
    "title": "2  Modeling Relative Abundance",
    "section": "2.3 Habitat associations",
    "text": "2.3 Habitat associations\nFrom the random forest model, we can glean two important sources of information about the association between Chucao Tapaculo detection and features of their local environment. First, predictor importance is a measure of the predictive power of each variable used as a predictor in the model, and is calculated as a byproduct of fitting a random forests model. Second, partial dependence estimates the marginal effect of one predictor holding all other predictors constant.\n\n2.3.1 Predictor importance\nDuring the process of training a random forests model, some variables are removed at each node of the trees that make up the random forests. Predictor importance is based on the mean decrease in accuracy of the model when a given predictor is not used. It’s technically an average Gini index, but essentially larger values indicate that a predictor is more important to the model.\n\npi <- er_model$variable.importance\npi <- data.frame(predictor = names(pi), importance = unname(pi)) %>% \n  arrange(desc(importance))\n# plot top 10 predictors\nggplot(head(pi, 10)) + \n  aes(x = fct_reorder(predictor, importance), y = importance) +\n  geom_col() +\n  geom_hline(yintercept = 0, linewidth = 2, colour = \"#555555\") +\n  scale_y_continuous(expand = c(0, 0)) +\n  coord_flip() +\n  labs(x = NULL, \n       y = \"Predictor Importance (Gini Index)\") +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        panel.grid.major.x = element_line(colour = \"#cccccc\", linewidth = 0.5))\n\n\n\n\n\n\n\n\nThe most important predictors of detection/non-detection are often effort variables. Indeed, that’s the case here: checklist duration, distance traveled, and time of day (solar_noon_diff) all appear in the top 5 predictors. This is not surprising: going out at the right time of day and expending more effort searching will lead to a higher probability of detecting Wood Thrush. Focusing on the habitat variables, both elevation variables have high importance, and the top habitat variables are from evergreen broadleaf forest and sparse forests. Note however, that high importance doesn’t tell us the direction of the relationship with detection, for that we’ll have to look at partial dependence plots.\n\n\n\n\n\n\nExercise\n\n\n\nLook up the predictor names in ebirdst_predictors to see what habitat types these variables correspond to. Based on your knowledge of the species, does it make sense that these habitat types are important?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nfilter(ebirdst_predictors, \n       predictor %in% c(\"mcd12q1_lccs1_fs_c12_1500_pland\",\n                        \"ntl_mean\",\n                        \"mcd12q1_lccs1_fs_c22_1500_pland\")) %>% \n  select(predictor, predictor_label)\n#> # A tibble: 3 × 2\n#>   predictor                       predictor_label                  \n#>   <chr>                           <chr>                            \n#> 1 ntl_mean                        Nighttime Lights                 \n#> 2 mcd12q1_lccs1_fs_c12_1500_pland Evergreen Broadleaf Forests PLAND\n#> 3 mcd12q1_lccs1_fs_c22_1500_pland Sparse Forests PLAND\n\n\n\n\n\n\n2.3.2 Partial dependence\nPartial dependence plots show the marginal effect of a given predictor on encounter rate averaged across the other predictors. These plots are generated by predicting encounter rate at a regular sequence of points across the full range of values of a given predictor. At each predictor value, predictions of encounter rate are made for a random subsample of the training dataset with the focal predictor fixed, but all other predictors left as is. The encounter rate predictions are then averaged across all the checklists in the training dataset giving an estimate of the average encounter rate at a specific value of the focal predictor. This is a cumbersome process, but we provide a function below that does all the hard work for you! This function takes the following arguments:\n\npredictor: the name of the predictor to calculate partial dependence for\nmodel: the encounter rate model object\ndata: the original data used to train the model\nx_res: the resolution of the grid over which to calculate the partial dependence, i.e. the number of points between the minimum and maximum values of the predictor to evaluate partial dependence at\nn: number of points to subsample from the training data\n\n\n# function to calculate partial dependence for a single predictor\ncalculate_pd <- function(predictor, model, data, \n                         x_res = 25, n = 1000) {\n  # create prediction grid using quantiles\n  x_grid <- quantile(data[[predictor]],\n                     probs = seq(from = 0, to = 1, length = x_res),\n                     na.rm = TRUE)\n  # remove duplicates\n  x_grid <- x_grid[!duplicated(signif(x_grid, 8))]\n  x_grid <- unname(unique(x_grid))\n  grid <- data.frame(predictor = predictor, x = x_grid)\n  names(grid) <- c(\"predictor\", predictor)\n  \n  # subsample training data\n  n <- min(n, nrow(data))\n  data <- data[sample(seq.int(nrow(data)), size = n, replace = FALSE), ]\n  \n  # drop focal predictor from data\n  data <- data[names(data) != predictor]\n  grid <- merge(grid, data, all = TRUE)\n  \n  # predict\n  p <- predict(model, data = grid)\n  \n  # summarize\n  pd <- grid[, c(\"predictor\", predictor)]\n  names(pd) <- c(\"predictor\", \"x\")\n  pd$encounter_rate <- p$predictions[, 2]\n  pd <- dplyr::group_by(pd, predictor, x) %>% \n    dplyr::summarise(encounter_rate = mean(encounter_rate, na.rm = TRUE),\n                     .groups = \"drop\")\n  \n  return(pd)\n}\n\nNow we’ll use this function to calculate partial dependence for the top 9 predictor variables.\n\n# calculate partial dependence for each predictor\n# map is used to iteratively apply calculate_pd to each predictor\npd <- NULL\nfor (predictor in head(pi$predictor)) {\n  pd <- calculate_pd(predictor, model = er_model, data = checklists_train) %>% \n    bind_rows(pd, .)\n}\n\n# calibrate predictions\npd$encounter_rate <- predict(calibration_model, \n                             newdata = tibble(pred = pd$encounter_rate), \n                             type = \"response\") %>% \n  as.numeric()\n\n# plot\nggplot(pd) +\n  aes(x = x, y = encounter_rate) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(~ as_factor(predictor), ncol = 2, scales = \"free\") +\n  labs(x = NULL, y = \"Encounter Rate\") +\n  theme_minimal() +\n  theme_minimal() +\n  theme(panel.grid = element_blank(),\n        axis.line = element_line(color = \"grey60\"),\n        axis.ticks  = element_line(color = \"grey60\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nConsider the relationships shown in the partial dependence plots in light of your knowledge of the species. Do these relationships make sense."
  },
  {
    "objectID": "abundance.html#sec-abundance-predict",
    "href": "abundance.html#sec-abundance-predict",
    "title": "2  Modeling Relative Abundance",
    "section": "2.4 Prediction",
    "text": "2.4 Prediction\nUsing the prediction grid described in Section 1.3, we can estimate relative abundance over our entire study area. First we estimate encounter rate and count, then we multiply these together to get an estimate of relative abundance. Let’s read in the prediction grid and subset to just the region we’re focusing on.\n\npred_grid_all <- read_parquet(\"data/ebird_prediction-grid_chile_2021.parquet\")\nraster_template <- rast(\"data/prediction-grid_template.tif\")\n\n# subset to the three regions we're focusing on\nin_region <- pred_grid_all %>%\n  select(srd_id, latitude, longitude) %>%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>%\n  st_join(study_region, left = FALSE) %>%\n  st_drop_geometry()\npred_grid <- semi_join(pred_grid_all, in_region, by = \"srd_id\")\n\nThe prediction grid only includes values for the environmental variables, so to make predictions we’ll need to add effort variables to this prediction grid. We’ll make predictions for a standard eBird checklist: a 1 km, 2 hour traveling count at the peak time of day for detecting this species. Finally, we’ll make these predictions for Janurary 31, 2021, the middle of our January-February focal window for the latest year for which we have eBird data.\nTo find the time of day with the highest detection probability, we can look for the peak of the partial dependence plot.\n\n# estimate a partial dependence plot for solar noon diff\npd_time <- calculate_pd(\"solar_noon_diff_mid\",\n                        model = er_model, \n                        data = checklists_train) %>% \n  select(solar_noon_diff_mid = x, encounter_rate)\n\n# partial dependence plot\nggplot(pd_time) +\n  aes(x = solar_noon_diff_mid, y = encounter_rate) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(-12, 13, by = 3)) +\n  labs(x = \"Difference from solar noon\",\n       y = \"Encounter\",\n       title = \"Partial dependence\")\n\n\n\n\n\n\n\n\nBased on the above plot, it appears that 6 hours before solar noon is the optimal time for observing Chucao Tapaculo. Let’s add all the effort variables to the prediction grid.\n\npred_grid_eff <- pred_grid %>% \n  mutate(year = 2021,\n         day_of_year = 31,\n         solar_noon_diff_mid = -6,\n         is_stationary = 0,\n         effort_hours = 2,\n         effort_distance_km = 1,\n         effort_speed_kmph = 0.5,\n         number_observers = 1)\n\nNow we can estimate calibrated encounter rate, count, and abundance for each point on the prediction grid. We also include a binary estimate of the range boundary.\n\n# encounter rate estimate\npred_er <- predict(er_model, data = pred_grid_eff, type = \"response\")\npred_er <- pred_er$predictions[, 2]\n# binary prediction\npred_binary <- as.integer(pred_er > threshold)\n# apply calibration\npred_er_cal <- predict(calibration_model, \n                       data.frame(pred = pred_er), \n                       type = \"response\") %>% \n  as.numeric()\n\n# add predicted encounter rate required for count estimates\npred_grid_eff$predicted_er <- pred_er\n# count estimate\npred_count <- predict(count_model, data = pred_grid_eff, type = \"response\")\npred_count <- pred_count$predictions\n\n# add estimates to prediction grid\npredictions <- pred_grid_eff %>% \n  select(srd_id, latitude, longitude) %>% \n  bind_cols(in_range = pred_binary,\n            encounter_rate = pred_er_cal,\n            count = pred_count) %>% \n  mutate(encounter_rate = pmin(pmax(encounter_rate, 0), 1),\n         abundance = pred_er_cal * pred_count)\n\nNext, we convert these estimates to raster format using the raster template.\n\nr_pred <- predictions %>% \n  # convert to spatial features\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 4326) %>% \n  st_transform(crs = crs(raster_template)) %>% \n  # rasterize\n  rasterize(raster_template, \n            field = c(\"in_range\", \"encounter_rate\", \"count\", \"abundance\")) %>% \n  setNames(c(\"in_range\", \"encounter_rate\", \"count\", \"abundance\"))\n# trim global raster to study region\nr_pred <- trim(r_pred)\n\nPrior to mapping these predictions, let’s load some contextual GIS data and project everything to a more suitable coordinate reference system.\n\n# load and project gis data\nmap_proj <- \"+proj=laea +lat_0=-40 +lon_0=-72\"\nne_land <- read_sf(\"data/gis-data.gpkg\", \"ne_land\") %>% \n  st_transform(crs = map_proj) %>% \n  st_geometry()\nne_country_lines <- read_sf(\"data/gis-data.gpkg\", \"ne_country_lines\") %>% \n  st_transform(crs = map_proj) %>% \n  st_geometry()\nne_state_lines <- read_sf(\"data/gis-data.gpkg\", \"ne_state_lines\") %>% \n  st_transform(crs = map_proj) %>% \n  st_geometry()\nstudy_region_proj <- st_transform(study_region, crs = map_proj) %>% \n  st_geometry()\n\n# project the raster data\nr_pred_proj <- crop(r_pred, st_transform(study_region, crs(r_pred))) %>% \n  project(map_proj, method = \"near\")\n\nFinally we’ll produce a map of relative abundance. The values shown on this map are the expected number of Chucao Tapaculo seen by an average eBirder conducting a 2 hour, 1 km checklist on January 31, 2021 at the optimal time of day for detecting the species. Prior to mapping the relative abundance, we’ll multiple by the in_range layer, which will produce a map showing zero relative abundance where the model predicts that Chucao Tapaculo does not occur.\n\n# in range abundance\nr_plot <- r_pred_proj[[\"abundance\"]] * r_pred_proj[[\"in_range\"]]\n\npar(mar = c(0.25, 0.25, 0.25, 0.25))\n# set up plot area\nplot(study_region_proj, col = NA, border = NA)\nplot(ne_land, col = \"#cfcfcf\", border = \"#888888\", lwd = 0.5, add = TRUE)\n\n# define quantile breaks, excluding zeros\nbrks <- ifel(r_plot > 0, r_plot, NA) %>% \n  global(fun = quantile, \n         probs = seq(0, 1, 0.1), na.rm = TRUE) %>% \n  as.numeric() %>% \n  unique()\n# label the bottom, middle, and top value\nlbls <- round(c(min(brks), median(brks), max(brks)), 2)\n# ebird status and trends color palette\npal <- abundance_palette(length(brks) - 1)\nplot(r_plot, \n     col = c(\"#e6e6e6\", pal), breaks = c(0, brks), \n     maxpixels = ncell(r_plot),\n     legend = FALSE, axes = FALSE, bty = \"n\",\n     add = TRUE)\n\n# borders\nplot(ne_state_lines, col = \"#ffffff\", lwd = 0.75, add = TRUE)\nplot(ne_country_lines, col = \"#ffffff\", lwd = 1.5, add = TRUE)\nplot(study_region_proj, border = \"#000000\", col = NA, lwd = 1, add = TRUE)\nbox()\n\n# legend\nimage.plot(zlim = c(0, 1), legend.only = TRUE,\n           col = pal, breaks = seq(0, 1, length.out = length(brks)),\n           smallplot = c(0.88, 0.90, 0.2, 0.8),\n           horizontal = FALSE,\n           axis.args = list(at = c(0, 0.5, 1), labels = lbls,\n                            fg = \"black\", col.axis = \"black\",\n                            cex.axis = 0.75, lwd.ticks = 0.5),\n           legend.args = list(text = \"Chucao Tapaculo Relative Abundance\",\n                              side = 2, col = \"black\",\n                              cex = 1, line = 0))"
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-access",
    "href": "ebirdst.html#sec-ebirdst-access",
    "title": "3  eBird Status Data Products",
    "section": "3.1 Data access",
    "text": "3.1 Data access\nAccess to the eBird Status Data Products is granted through an Access Request Form at: https://ebird.org/st/request. The terms of use have been desiged to be quite permissive in many cases, particularly academic and research use. After reading the eBird Status and Trends Products Terms of Use and filling out the Access Request Form you will be provided with an alphanumeric access key. To store the access key so it can be accessed by R and the ebirdst package, run the following (replacing \"XXXXXXXXX\" with your actual key):\n\nset_ebirdst_access_key(\"XXXXXXXXX\")\n\nThen immediately restart R. This will save the access key as the environment variable EBIRDST_KEY in your .Renviron file so it’s accessible within your R session.\n\n\n\n\n\n\nCheckpoint\n\n\n\nTo ensure you’re data access key is working, attempt run the following code, which will download a single small file. Speak to the instructor if this doesn’t work.\n\nebirdst_download(\"grbfir1\", pattern = \"abundance_median_lr_2021\", force = TRUE)"
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-species",
    "href": "ebirdst.html#sec-ebirdst-species",
    "title": "3  eBird Status Data Products",
    "section": "3.2 Status and Trends species",
    "text": "3.2 Status and Trends species\nThe ebirdst_runs object is a data frame listing all the available species:\n\nglimpse(ebirdst_runs)\n#> Rows: 2,282\n#> Columns: 23\n#> $ species_code                         <chr> \"grerhe1\", \"higtin1\", \"gretin1\", …\n#> $ scientific_name                      <chr> \"Rhea americana\", \"Nothocercus bo…\n#> $ common_name                          <chr> \"Greater Rhea\", \"Highland Tinamou…\n#> $ resident                             <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRU…\n#> $ breeding_quality                     <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ breeding_range_modeled               <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ breeding_start                       <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ breeding_end                         <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ nonbreeding_quality                  <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ nonbreeding_range_modeled            <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ nonbreeding_start                    <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ nonbreeding_end                      <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ postbreeding_migration_quality       <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ postbreeding_migration_range_modeled <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ postbreeding_migration_start         <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ postbreeding_migration_end           <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ prebreeding_migration_quality        <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ prebreeding_migration_range_modeled  <chr> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ prebreeding_migration_start          <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ prebreeding_migration_end            <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ resident_quality                     <chr> \"2\", \"1\", \"2\", \"3\", \"3\", \"2\", \"2\"…\n#> $ resident_start                       <date> 2021-01-04, 2021-01-04, 2021-01-…\n#> $ resident_end                         <date> 2021-12-28, 2021-12-28, 2021-12-…\n\nIf you’re working in RStudio, you can use View() to interactively explore this data frame. You can also consult the Status and Trends species page the full list of available species. On this page you can also filter by region, for example to see only those species with some portion of their range falling within Chile.\nWe’ve included a set of regional statistics for Chile and the regions of Chile in the data package provided for this workshop. For each species and season, five statistics are provided summarizing the Status and Trends data over each region. We can use these statistics to identify which of the 2,882 Status and Trends species occur in Chile.\n\nregional_stats <- read_csv(\"data/ebirdst-2021_regional-stats_chile.csv\")\n\nFor example, we could use this to see which Status and Trends species have at least 1% of population within Chile or whose range covers at least 5% of Chile for at least one season.\n\nchile_runs <- regional_stats %>% \n  filter(region_code == \"CL\",\n         percent_population > 0.01 | percent_region_occupied > 0.05) %>%\n  distinct(species_code) %>% \n  inner_join(ebirdst_runs, by = \"species_code\")\nnrow(chile_runs)\n#> [1] 110\n\nThis leaves us with 110 species.\n\n3.2.1 Expert review\nAll species go through a process of expert human review prior to being released. The ebirdst_runs data frame also contains information from this review process. Reviewers assess each of the four seasons: breeding, non-breeding, pre-breeding migration, and post-breeding migration. Resident (i.e., non-migratory) species are identified by having TRUE in the resident column of ebirdst_runs, and these species are assessed across the whole year rather than seasonally. ebirdst_runs contains two important pieces of information for each season: a quality rating and seasonal dates.\nThe seasonal dates define the weeks that fall within each season; the relative abundance estimates for these weeks get averaged to produce the seasonal relative abundance maps on the Status and Trends website. Breeding and non-breeding season dates are defined for each species as the weeks during those seasons when the species’ population does not move. For this reason, these seasons are also described as stationary periods. Migration periods are defined as the periods of movement between the stationary non-breeding and breeding seasons. Note that for many species these migratory periods include not only movement from breeding grounds to non-breeding grounds, but also post-breeding dispersal, molt migration, and other movements.\nReviewers also examine the model estimates for each season to assess the amount of extrapolation or omission present in the model, and assign an associated quality rating ranging from 0 (lowest quality) to 3 (highest quality). Extrapolation refers to cases where the model predicts occurrence where the species is known to be absent, while omission refers to the model failing to predict occurrence where a species is known to be present.\nA rating of 0 implies this season failed review and model results should not be used at all for this period. Ratings of 1-3 correspond to a gradient of more to less extrapolation and/or omission, and we often use a traffic light analogy when referring to them:\n\nRed light (1): low quality, extensive extrapolation and/or omission and noise, but at least some regions have estimates that are accurate; can be used with caution in certain regions.\nYellow light (2): medium quality, some extrapolation and/or omission; use with caution.\nGreen light (3): high quality, very little or no extrapolation and/or omission; these seasons can be safely used.\n\n\n\n\n\n\n\nExercise\n\n\n\nLook up a species of interest to you. Identify the seasonal dates and the review quality ratings.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGreen-backed Firecrown is coded as a migrant with all four seasons receiving quality ratings of 2 suggesting that there may be some extrapolation or omission.\n\nchile_runs %>% \n  filter(common_name == \"Green-backed Firecrown\") %>% \n  glimpse()\n#> Rows: 1\n#> Columns: 23\n#> $ species_code                         <chr> \"grbfir1\"\n#> $ scientific_name                      <chr> \"Sephanoides sephaniodes\"\n#> $ common_name                          <chr> \"Green-backed Firecrown\"\n#> $ resident                             <lgl> FALSE\n#> $ breeding_quality                     <chr> \"2\"\n#> $ breeding_range_modeled               <chr> \"TRUE\"\n#> $ breeding_start                       <date> 2021-11-23\n#> $ breeding_end                         <date> 2021-04-26\n#> $ nonbreeding_quality                  <chr> \"2\"\n#> $ nonbreeding_range_modeled            <chr> \"TRUE\"\n#> $ nonbreeding_start                    <date> 2021-06-14\n#> $ nonbreeding_end                      <date> 2021-08-31\n#> $ postbreeding_migration_quality       <chr> \"2\"\n#> $ postbreeding_migration_range_modeled <chr> \"TRUE\"\n#> $ postbreeding_migration_start         <date> 2021-05-03\n#> $ postbreeding_migration_end           <date> 2021-06-07\n#> $ prebreeding_migration_quality        <chr> \"2\"\n#> $ prebreeding_migration_range_modeled  <chr> \"TRUE\"\n#> $ prebreeding_migration_start          <date> 2021-09-07\n#> $ prebreeding_migration_end            <date> 2021-11-16\n#> $ resident_quality                     <chr> NA\n#> $ resident_start                       <date> NA\n#> $ resident_end                         <date> NA"
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-download",
    "href": "ebirdst.html#sec-ebirdst-download",
    "title": "3  eBird Status Data Products",
    "section": "3.3 Downloading data",
    "text": "3.3 Downloading data\nThe function ebirdst_download() downloads data for a single species given a species name (common name, scientific name, or species code). For example, to download the data for Green-backed Firecrown use:\n\npath <- ebirdst_download(species = \"Green-backed Firecrown\")\npath\n\n\n#> [1] \"/Users/mes335/data/ebirdst/2021/grbfir1\"\n\nThe function will automatically identify a suitable location to store the downloaded data and return that path, which we captured in the variable path. We can see which files were downloaded with:\n\nlist.files(path, recursive = TRUE)\n#>  [1] \"config.json\"                                                   \n#>  [2] \"ranges/grbfir1_range_raw_lr_2021.gpkg\"                         \n#>  [3] \"ranges/grbfir1_range_raw_mr_2021.gpkg\"                         \n#>  [4] \"ranges/grbfir1_range_smooth_lr_2021.gpkg\"                      \n#>  [5] \"ranges/grbfir1_range_smooth_mr_2021.gpkg\"                      \n#>  [6] \"regional_stats.csv\"                                            \n#>  [7] \"seasonal/band-seasons.csv\"                                     \n#>  [8] \"seasonal/grbfir1_abundance_full-year_max_hr_2021.tif\"          \n#>  [9] \"seasonal/grbfir1_abundance_full-year_max_lr_2021.tif\"          \n#> [10] \"seasonal/grbfir1_abundance_full-year_max_mr_2021.tif\"          \n#> [11] \"seasonal/grbfir1_abundance_full-year_mean_hr_2021.tif\"         \n#> [12] \"seasonal/grbfir1_abundance_full-year_mean_lr_2021.tif\"         \n#> [13] \"seasonal/grbfir1_abundance_full-year_mean_mr_2021.tif\"         \n#> [14] \"seasonal/grbfir1_abundance_seasonal_max_hr_2021.tif\"           \n#> [15] \"seasonal/grbfir1_abundance_seasonal_max_lr_2021.tif\"           \n#> [16] \"seasonal/grbfir1_abundance_seasonal_max_mr_2021.tif\"           \n#> [17] \"seasonal/grbfir1_abundance_seasonal_mean_hr_2021.tif\"          \n#> [18] \"seasonal/grbfir1_abundance_seasonal_mean_lr_2021.tif\"          \n#> [19] \"seasonal/grbfir1_abundance_seasonal_mean_mr_2021.tif\"          \n#> [20] \"seasonal/grbfir1_count_full-year_max_hr_2021.tif\"              \n#> [21] \"seasonal/grbfir1_count_full-year_max_lr_2021.tif\"              \n#> [22] \"seasonal/grbfir1_count_full-year_max_mr_2021.tif\"              \n#> [23] \"seasonal/grbfir1_count_full-year_mean_hr_2021.tif\"             \n#> [24] \"seasonal/grbfir1_count_full-year_mean_lr_2021.tif\"             \n#> [25] \"seasonal/grbfir1_count_full-year_mean_mr_2021.tif\"             \n#> [26] \"seasonal/grbfir1_count_seasonal_max_hr_2021.tif\"               \n#> [27] \"seasonal/grbfir1_count_seasonal_max_lr_2021.tif\"               \n#> [28] \"seasonal/grbfir1_count_seasonal_max_mr_2021.tif\"               \n#> [29] \"seasonal/grbfir1_count_seasonal_mean_hr_2021.tif\"              \n#> [30] \"seasonal/grbfir1_count_seasonal_mean_lr_2021.tif\"              \n#> [31] \"seasonal/grbfir1_count_seasonal_mean_mr_2021.tif\"              \n#> [32] \"seasonal/grbfir1_occurrence_full-year_max_hr_2021.tif\"         \n#> [33] \"seasonal/grbfir1_occurrence_full-year_max_lr_2021.tif\"         \n#> [34] \"seasonal/grbfir1_occurrence_full-year_max_mr_2021.tif\"         \n#> [35] \"seasonal/grbfir1_occurrence_full-year_mean_hr_2021.tif\"        \n#> [36] \"seasonal/grbfir1_occurrence_full-year_mean_lr_2021.tif\"        \n#> [37] \"seasonal/grbfir1_occurrence_full-year_mean_mr_2021.tif\"        \n#> [38] \"seasonal/grbfir1_occurrence_seasonal_max_hr_2021.tif\"          \n#> [39] \"seasonal/grbfir1_occurrence_seasonal_max_lr_2021.tif\"          \n#> [40] \"seasonal/grbfir1_occurrence_seasonal_max_mr_2021.tif\"          \n#> [41] \"seasonal/grbfir1_occurrence_seasonal_mean_hr_2021.tif\"         \n#> [42] \"seasonal/grbfir1_occurrence_seasonal_mean_lr_2021.tif\"         \n#> [43] \"seasonal/grbfir1_occurrence_seasonal_mean_mr_2021.tif\"         \n#> [44] \"seasonal/grbfir1_percent-population_full-year_max_hr_2021.tif\" \n#> [45] \"seasonal/grbfir1_percent-population_full-year_max_lr_2021.tif\" \n#> [46] \"seasonal/grbfir1_percent-population_full-year_max_mr_2021.tif\" \n#> [47] \"seasonal/grbfir1_percent-population_full-year_mean_hr_2021.tif\"\n#> [48] \"seasonal/grbfir1_percent-population_full-year_mean_lr_2021.tif\"\n#> [49] \"seasonal/grbfir1_percent-population_full-year_mean_mr_2021.tif\"\n#> [50] \"seasonal/grbfir1_percent-population_seasonal_max_hr_2021.tif\"  \n#> [51] \"seasonal/grbfir1_percent-population_seasonal_max_lr_2021.tif\"  \n#> [52] \"seasonal/grbfir1_percent-population_seasonal_max_mr_2021.tif\"  \n#> [53] \"seasonal/grbfir1_percent-population_seasonal_mean_hr_2021.tif\" \n#> [54] \"seasonal/grbfir1_percent-population_seasonal_mean_lr_2021.tif\" \n#> [55] \"seasonal/grbfir1_percent-population_seasonal_mean_mr_2021.tif\" \n#> [56] \"weekly/band-dates.csv\"                                         \n#> [57] \"weekly/grbfir1_abundance_lower_hr_2021.tif\"                    \n#> [58] \"weekly/grbfir1_abundance_lower_lr_2021.tif\"                    \n#> [59] \"weekly/grbfir1_abundance_lower_mr_2021.tif\"                    \n#> [60] \"weekly/grbfir1_abundance_median_hr_2021.tif\"                   \n#> [61] \"weekly/grbfir1_abundance_median_lr_2021.tif\"                   \n#> [62] \"weekly/grbfir1_abundance_median_mr_2021.tif\"                   \n#> [63] \"weekly/grbfir1_abundance_upper_hr_2021.tif\"                    \n#> [64] \"weekly/grbfir1_abundance_upper_lr_2021.tif\"                    \n#> [65] \"weekly/grbfir1_abundance_upper_mr_2021.tif\"                    \n#> [66] \"weekly/grbfir1_centroids.csv\"                                  \n#> [67] \"weekly/grbfir1_count_median_hr_2021.tif\"                       \n#> [68] \"weekly/grbfir1_count_median_lr_2021.tif\"                       \n#> [69] \"weekly/grbfir1_count_median_mr_2021.tif\"                       \n#> [70] \"weekly/grbfir1_occurrence_median_hr_2021.tif\"                  \n#> [71] \"weekly/grbfir1_occurrence_median_lr_2021.tif\"                  \n#> [72] \"weekly/grbfir1_occurrence_median_mr_2021.tif\"                  \n#> [73] \"weekly/grbfir1_percent-population_median_hr_2021.tif\"          \n#> [74] \"weekly/grbfir1_percent-population_median_lr_2021.tif\"          \n#> [75] \"weekly/grbfir1_percent-population_median_mr_2021.tif\"\n\nWithin this data package directory, the files are organized according to the following structure:\n\nweekly/: a directory containing weekly estimates of occurrence, count, relative abundance, and percent of population on a regular grid in GeoTIFF format at three resolutions. See below for more details.\nseasonal/: a directory containing seasonal estimates of occurrence, count, relative abundance, and percent of population on a regular grid in GeoTIFF format at three resolutions. These are derived from the corresponding weekly raster data. Dates defining the boundary of each season are set on a species-specific basis by an expert reviewer familiar with the species. These dates are available in the ebirdst_runs data frame. Only seasons that passed the expert review process are included. See below for more details.\nranges/: a directory containing GeoPackages storing range boundary polygons. See below for more details.\nconfig.json: run-specific parameters, mostly for internal use, but also containing useful parameters for mapping the abundance data.\n\n\n\n\n\n\n\nTip\n\n\n\nSpatial data fall into two broad categories: raster data and vector data. Raster data represents spatial data as a regular grid of cells with a value or set of values assigned to each. Vector data represents spatial data as discrete points, lines, or polygons. In the eBird Status data products, raster data are distributed as GeoTIFFs, while vector data are distributed as GeoPackages.\n\n\nFor a species whose data have already been downloaded, you can use get_species_path(\"Green-backed Firecrown\") to identify the path to the data.\n\n3.3.1 Downloading specific files\nThe full data package for each species contains a large number of files, many of which may be unnecessary for your application. You can use the dry_run = TRUE argument to ebirdst_download() to list the available files without downloading them.\n\nebirdst_download(\"Green-backed Firecrown\", dry_run = TRUE)\n\nThen, once you’ve identified the files you want, you can use the pattern argument to download only those files. For example, imagine we only want the abundance files:\n\nebirdst_download(\"Green-backed Firecrown\", pattern = \"abundance\")\n\n\n\n\n\n\n\nTip\n\n\n\nTo avoid any issues resulting from all participants downloading data over a slow internet connection at the same time, for the remainder of this lesson we’ll use data included in the data package for this workshop. These data packages should be in the data/ebirst-data/ subdirectory of your RStudio project. To find the path to the data for a particular species using a non-standard download location, use\n\npath <- get_species_path(\"Green-backed Firecrown\", path = \"data/ebirdst-data/\")\npath\n#> [1] \"data/ebirdst-data//2021/grbfir1\"\n\nHowever, when working with eBird Status data products after this workshop, it’s best to use the standard download location and skip adding path = \"data/ebirdst-data/\"."
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-load",
    "href": "ebirdst.html#sec-ebirdst-load",
    "title": "3  eBird Status Data Products",
    "section": "3.4 Loading data in R",
    "text": "3.4 Loading data in R\nIn this workshop, we’ll focus on the raster data products, which can all be loaded into R using the ebirdst function load_raster(). In R, we’ll use the terra package to work with raster data. Raster data products fall into two broad categories providing weekly and seasonal estimates.\n\n3.4.1 Weekly raster estimates\nThe core raster data products are the weekly estimates of occurrence, count, relative abundance, and percent of population. All estimates are the median expected value for a 1km, 1 hour eBird Traveling Count by an expert eBird observer at the optimal time of day and for optimal weather conditions to observe the given species.\n\nOccurrence occurrence: the expected probability of encountering a species.\nCount count: the expected count of a species, conditional on its occurrence at the given location.\nRelative abundance abundance: the expected relative abundance of a species, computed as the product of the probability of occurrence and the count conditional on occurrence. In addition to the median relative abundance, upper and lower confidence intervals (CIs) are provided, defined at the 10th and 90th quantile of relative abundance, respectively.\nPercent of population precent-population: the proportion of the total relative abundance within each cell. This is a derived product calculated by dividing each cell value in the relative abundance raster by the sum of all cell values\n\nAll predictions are made on a standard 2.96km x 2.96km global grid, however, for convenience lower resolution GeoTIFFs are also provided, which are typically much faster to work with. The three resolutions are:\n\nHigh resolution (hr): the native 2.96 km resolution data\nMedium resolution (mr): the hr data aggregated by a factor of 3 in each direction resulting in a resolution of 8.89 km\nLow resolution (lr): the hr data aggregated by a factor of 9 in each direction resulting in a resolution of 26.7 km\n\nThe weekly cubes use the following naming convention:\nweekly/<species_code>_<product>_<metric>_<resolution>_<year>.tif\nwhere metric is typically median, except for the relative abundance CIs, which use lower and upper. The function load_raster() is used to load these data into R and takes arguments for product, metric and resolution. For example, to load the high resolution median relative abundance, use\n\nabd_median_hr <- load_raster(path, product = \"abundance\", resolution = \"hr\")\nprint(abd_median_hr)\n#> class       : SpatRaster \n#> dimensions  : 5630, 13511, 52  (nrow, ncol, nlyr)\n#> resolution  : 2963, 2963  (x, y)\n#> extent      : -2e+07, 2e+07, -6673060, 1e+07  (xmin, xmax, ymin, ymax)\n#> coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#> source      : grbfir1_abundance_median_hr_2021.tif \n#> names       : 2021-01-04, 2021-01-11, 2021-01-18, 2021-01-25, 2021-02-01, 2021-02-08, ... \n#> min values  :       0.00,        0.0,       0.00,       0.00,       0.00,        0.0, ... \n#> max values  :       4.19,        4.9,       4.23,       4.13,       4.84,        5.4, ...\n\nWe often refer to these raster objects as “weekly cubes” (e.g. the “weekly abundance cube”). Notice that the cubes contains 52 layers, corresponding to the weeks of the year. We can use the function parse_raster_dates() to see the dates associated with each layer.\n\nparse_raster_dates(abd_median_hr)\n#>  [1] \"2021-01-04\" \"2021-01-11\" \"2021-01-18\" \"2021-01-25\" \"2021-02-01\"\n#>  [6] \"2021-02-08\" \"2021-02-15\" \"2021-02-22\" \"2021-03-01\" \"2021-03-08\"\n#> [11] \"2021-03-15\" \"2021-03-22\" \"2021-03-29\" \"2021-04-05\" \"2021-04-12\"\n#> [16] \"2021-04-19\" \"2021-04-26\" \"2021-05-03\" \"2021-05-10\" \"2021-05-17\"\n#> [21] \"2021-05-24\" \"2021-05-31\" \"2021-06-07\" \"2021-06-14\" \"2021-06-21\"\n#> [26] \"2021-06-28\" \"2021-07-06\" \"2021-07-13\" \"2021-07-20\" \"2021-07-27\"\n#> [31] \"2021-08-03\" \"2021-08-10\" \"2021-08-17\" \"2021-08-24\" \"2021-08-31\"\n#> [36] \"2021-09-07\" \"2021-09-14\" \"2021-09-21\" \"2021-09-28\" \"2021-10-05\"\n#> [41] \"2021-10-12\" \"2021-10-19\" \"2021-10-26\" \"2021-11-02\" \"2021-11-09\"\n#> [46] \"2021-11-16\" \"2021-11-23\" \"2021-11-30\" \"2021-12-07\" \"2021-12-14\"\n#> [51] \"2021-12-21\" \"2021-12-28\"\n\nAs another example, we could load the low resolution upper and lower abundance confidence intervals.\n\nabd_lower_lr <- load_raster(path, product = \"abundance\", metric = \"lower\", \n                            resolution = \"lr\")\nabd_upper_lr <- load_raster(path, product = \"abundance\", metric = \"upper\", \n                            resolution = \"lr\")\n\n\n\n\n\n\n\nExercise\n\n\n\nTry loading the weekly median percent of population cube at medium resolution.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\npct_pop <- load_raster(path, product = \"percent-population\", metric = \"median\", \n                       resolution = \"mr\")\nprint(pct_pop)\n#> class       : SpatRaster \n#> dimensions  : 1877, 4504, 52  (nrow, ncol, nlyr)\n#> resolution  : 8888, 8888  (x, y)\n#> extent      : -2e+07, 2e+07, -6676023, 1e+07  (xmin, xmax, ymin, ymax)\n#> coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#> source      : grbfir1_percent-population_median_mr_2021.tif \n#> names       : 2021-01-04, 2021-01-11, 2021-01-18, 2021-01-25, 2021-02-01, 2021-02-08, ... \n#> min values  :    0.00000,     0.0000,    0.00000,    0.00000,    0.00000,    0.00000, ... \n#> max values  :    0.00105,     0.0011,    0.00104,    0.00133,    0.00143,    0.00151, ...\n\n\n\n\n\n\n3.4.2 Seasonal raster estimates\nThe seasonal raster estimates are provided for the same set of products and at the same three resolutions as the weekly estimates. They’re derived from the weekly data by taking the cell-wise mean or max across the weeks within each season. Recall that the seasonal boundary dates are available in the data frame ebirdst_runs; data is not provided for seasons with a quality score of 0.\nThe seasonal GeoTIFFs use the following naming convention:\nseasonal/<species_code>_<product>_seasonal_<metric>_<resolution>_<year>.tif\nwhere metric is either mean or max. The function load_raster(period = \"seasonal\") is used to load these data into R and takes arguments for product, metric and resolution. For example, to load the low resolution mean seasonal relative abundance, use\n\nabd_seasonal_mean <- load_raster(path, product = \"abundance\", \n                                 period = \"seasonal\", metric = \"mean\", \n                                 resolution = \"lr\")\nprint(abd_seasonal_mean)\n#> class       : SpatRaster \n#> dimensions  : 626, 1502, 4  (nrow, ncol, nlyr)\n#> resolution  : 26665, 26665  (x, y)\n#> extent      : -2e+07, 2e+07, -6684911, 1e+07  (xmin, xmax, ymin, ymax)\n#> coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#> source      : grbfir1_abundance_seasonal_mean_lr_2021.tif \n#> names       : breeding, nonbreeding, prebree~gration, postbre~gration \n#> min values  :     0.00,        0.00,            0.00,             0.0 \n#> max values  :     2.39,        3.04,            1.98,             3.4\n\nNotice there are four layers in this raster corresponding to the four seasons.\n\nnames(abd_seasonal_mean)\n#> [1] \"breeding\"               \"nonbreeding\"            \"prebreeding_migration\" \n#> [4] \"postbreeding_migration\"\n\nFinally, as a convenience, the data products include year-round rasters summarizing the mean or max across all weeks that fall within a season that passed the expert review process. These can be accessed similarly to the seasonal products, just with period = \"full-year\" instead. For example, these layers can be used in conservation planning to assess the most important sites across the full range and full annual cycle of a species.\n\nabd_fy_max <- load_raster(path, product = \"abundance\", \n                          period = \"full-year\", metric = \"max\", \n                          resolution = \"hr\")"
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-explore",
    "href": "ebirdst.html#sec-ebirdst-explore",
    "title": "3  eBird Status Data Products",
    "section": "3.5 Exploring the raster data",
    "text": "3.5 Exploring the raster data\nLet’s load the low resolution weekly and seasonal relative abundance cubes and use them to demonstrate some basic raster operations with the data.\n\nabd_weekly <- load_raster(path, product = \"abundance\", resolution = \"mr\")\nabd_seasonal <- load_raster(path, product = \"abundance\", period = \"seasonal\", \n                            resolution = \"mr\")\n\nThese cubes can easily be subset to a single week or season.\n\n# week of may 17\nabd_weekly[[\"2021-05-17\"]]\n#> class       : SpatRaster \n#> dimensions  : 1877, 4504, 1  (nrow, ncol, nlyr)\n#> resolution  : 8888, 8888  (x, y)\n#> extent      : -2e+07, 2e+07, -6676023, 1e+07  (xmin, xmax, ymin, ymax)\n#> coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#> source      : grbfir1_abundance_median_mr_2021.tif \n#> name        : 2021-05-17 \n#> min value   :       0.00 \n#> max value   :       4.11\n# breeding season\nabd_seasonal[[\"breeding\"]]\n#> class       : SpatRaster \n#> dimensions  : 1877, 4504, 1  (nrow, ncol, nlyr)\n#> resolution  : 8888, 8888  (x, y)\n#> extent      : -2e+07, 2e+07, -6676023, 1e+07  (xmin, xmax, ymin, ymax)\n#> coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#> source      : grbfir1_abundance_seasonal_mean_mr_2021.tif \n#> name        : breeding \n#> min value   :     0.00 \n#> max value   :     2.73\n\nWe can also subset the weekly cube to a range of weeks. For example, let’s subset to only the estimates for weeks in may, then take the average across the weeks.\n\n# determine which dates we want to include\nweek_dates <- parse_raster_dates(abd_weekly)\nstart_date <- as.Date(\"2021-05-01\")\nend_date <- as.Date(\"2021-05-31\")\nweek_in_may <- week_dates >= start_date & week_dates <= end_date\n\n# subset to weeks in may\nabd_weekly_may <- abd_weekly[[week_in_may]]\n\n# average across weeks\nmean(abd_weekly_may, na.rm = TRUE)\n#> class       : SpatRaster \n#> dimensions  : 1877, 4504, 1  (nrow, ncol, nlyr)\n#> resolution  : 8888, 8888  (x, y)\n#> extent      : -2e+07, 2e+07, -6676023, 1e+07  (xmin, xmax, ymin, ymax)\n#> coord. ref. : +proj=sinu +lon_0=0 +x_0=0 +y_0=0 +R=6371007.181 +units=m +no_defs \n#> source(s)   : memory\n#> name        : mean \n#> min value   : 0.00 \n#> max value   : 4.09\n\nMaking a simple map of the data will produce unexpected results. For example, let’s map the breeding season relative abundance for Green-backed Firecrown.\n\nplot(abd_seasonal[[\"breeding\"]])\n\n\n\n\n\n\n\n\nRecall that all eBird Status data products are provided for the entire globe regardless of the range of the species. Also, notice that some areas, such as most of the Amazon Basin, have missing values indicating that there was insufficient data to make a prediction in the region. Other areas, such as North America, had sufficient data to predict that the species is absent. Let’s try using the GIS data included in the workshop data package to crop the raster to the Chilean region of Los Lagos to make a more meaningful map.\n\n# los lagos boundary, projected to match the raster data\nlos_lagos <- read_sf(\"data/gis-data.gpkg\",  layer = \"ne_states\") %>% \n  filter(state == \"Los Lagos\") %>% \n  st_transform(crs = crs(abd_seasonal)) %>% \n  st_geometry()\n# crop raster data to chile\nabd_breeding_ll <- crop(abd_seasonal[[\"breeding\"]], los_lagos)\n# map\nplot(abd_breeding_ll)\nplot(los_lagos, add = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheckpoint\n\n\n\nLet’s take a break before proceeding onto some more realistic applications of the eBird Status data products. Make sure you’re comfortable loading the data into R and performing some of the basic operations."
  },
  {
    "objectID": "ebirdst.html#sec-ebirdst-applications",
    "href": "ebirdst.html#sec-ebirdst-applications",
    "title": "3  eBird Status Data Products",
    "section": "3.6 Applications",
    "text": "3.6 Applications\nThe remainder of the workshop will work through three example applications using the eBird Status data products:\n\nTrajectories: chart the change in relative abundance and percent of population for a single species throughout the year for a specific location.\nRegional statistics: calculate the proportion of the breeding population falling within protected areas for a set of species.\nPrioritization: use eBird Status data products to identify important sites for protection of a set of species.\n\n\n3.6.1 Trajectories\nIn this application, we’ll look at the change in Green-backed Firecrown abundance throughout the year in Los Lagos, Chile. Let’s start by loading the medium resolution weekly relative abundance cubes (median and confidence intervals) as well as a boundary polygon for Los Lagos.\n\n# relative abundance cubes, median and confidence intervals\npath <- get_species_path(\"grbfir1\", path = \"data/ebirdst-data/\")\nabd_median <- load_raster(path, metric = \"median\", resolution = \"mr\")\nabd_lower <- load_raster(path, metric = \"lower\", resolution = \"mr\")\nabd_upper <- load_raster(path, metric = \"upper\", resolution = \"mr\")\n\n# los lagos boundary, projected to match the raster data\nlos_lagos <- read_sf(\"data/gis-data.gpkg\", \"ne_states\") %>% \n  filter(state == \"Los Lagos\") %>% \n  st_transform(crs = crs(abd_seasonal)) %>% \n  st_geometry()\n\nNow, we’ll use the R package exactextractr to calculate the mean value for each layer within Los Lagos.\n\n# mean abundance within los lagos\nmedian_traj <- exact_extract(abd_median, los_lagos, fun = \"mean\")\nlower_traj <- exact_extract(abd_lower, los_lagos, fun = \"mean\")\nupper_traj <- exact_extract(abd_upper, los_lagos, fun = \"mean\")\n\n# combine median, lower, and upper together\ntrajectory <- data.frame(\n  week = parse_raster_dates(abd_median),\n  median = as.numeric(median_traj[1, ]),\n  lower = as.numeric(lower_traj[1, ]),\n  upper = as.numeric(upper_traj[1, ]))\nhead(trajectory)\n#>         week median lower upper\n#> 1 2021-01-04  0.766 0.729 0.807\n#> 2 2021-01-11  0.859 0.818 0.900\n#> 3 2021-01-18  0.946 0.907 0.989\n#> 4 2021-01-25  1.015 0.971 1.061\n#> 5 2021-02-01  1.091 1.045 1.138\n#> 6 2021-02-08  1.182 1.130 1.237\n\nNow we can plot the trajectories with confidence intervals.\n\nggplot(trajectory, aes(x = week, y = median)) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.3)+\n  geom_line() +\n  labs(x = \"Week\", \n       y = \"Mean relative abundance\",\n       title = \"Weekly Green-backed Firecrown trajectory in Las Lagos\")\n\n\n\n\n\n\n\n\n\n\n3.6.2 Regional statistics\nFor this application, we’ll identify the mean relative abundance and proportion of the population for a set of species in protected areas in Chile. For a species group we’ll use the top 10 species with the largest proportion of their population falling in Chile. We can identify these species using the regional statistics file we loaded in Section 3.2. For migratory species we’ll consider the percent of the breeding population and for resident species we’ll consider the percent of the year round population.\n\nspecies_list <- regional_stats %>%\n  filter(region_code == \"CL\") %>%\n  filter(season_code %in% c(\"breeding\", \"year_round\")) %>%\n  select(species_code, percent_population) %>% \n  arrange(desc(percent_population)) %>% \n  head(10)\n\n# add common names, migrant/resident status, and quality\nspecies_list <- species_list %>% \n  inner_join(ebirdst_runs, by = \"species_code\") %>% \n  mutate(quality = ifelse(resident, resident_quality, breeding_quality)) %>% \n  select(species_code, common_name, resident, quality, percent_population)\nprint(species_list)\n#> # A tibble: 10 × 5\n#>   species_code common_name                 resident quality percent_population\n#>   <chr>        <chr>                       <lgl>    <chr>                <dbl>\n#> 1 cthhue1      Chestnut-throated Huet-huet TRUE     3                    0.999\n#> 2 chipig2      Chilean Pigeon              TRUE     3                    0.989\n#> 3 chimoc1      Chilean Mockingbird         TRUE     1                    0.979\n#> 4 grbfir1      Green-backed Firecrown      FALSE    2                    0.963\n#> 5 chutap1      Chucao Tapaculo             TRUE     3                    0.918\n#> 6 pattyr2      Patagonian Tyrant           FALSE    2                    0.868\n#> # ℹ 4 more rows\n\nWe’re left with two migrants and 8 resident species, each with at least 75% of their populations falling within Chile. Notice that 2 of these species have quality ratings of 1 indicating that caution should be exercised when using the results. For real world use you should examine the relative abundance maps for errors prior to using them for analysis; however, for this example, we’ll use this species list as is. We’ll load and combine the breeding (for migrants) and resident (for residents) percent of population layers for this list of species. Data for all 10 of these species has been included in the workshop data package.\n\n\n\n\n\n\nTip\n\n\n\nRelative abundance estimates are impacted by detection rates, which can vary between species. As a results, when comparing eBird Status and Trends data across species, it’s critical to always use the percent of population layers, which have been standardized by dividing each cell value by the total relative abundance across all cells.\n\n\n\n# loop over the species list extracting the seasonal percent of population\npercent_population <- list()\nfor (i in seq_len(nrow(species_list))) {\n  # load the seasonal cube for this species\n  this_species <- species_list[i, ]\n  pop <- get_species_path(this_species$species_code, \n                          path = \"data/ebirdst-data/\") %>% \n    load_raster(\"percent-population\", period = \"seasonal\", resolution = \"mr\")\n  \n  # subset to the layer we need: breeding or resident\n  pop <- pop[[ifelse(this_species$resident, \"resident\", \"breeding\")]]\n  percent_population[[this_species$species_code]] <- pop\n}\n# stack the rasters into a single object\npercent_population <- rast(percent_population)\n\nThe GIS data available in the workshop data package contains polygon boundaries for public protected areas in Chile, let’s load them now and project to match the raster layers. For this example, we’ll combine all the protected area polygons together into one feature; however, this analysis could be modified to consider how the distribution of species varies between protected areas.\n\nprotected <- read_sf(\"data/gis-data.gpkg\",  layer = \"protected_areas\") %>% \n  st_combine() %>% \n  st_transform(crs = crs(percent_population))\n\nFinally, we can use exactextracr to calculate the total percent of population within protected areas for each species.\n\npercent_protected <- exact_extract(percent_population, protected, fun = \"sum\")\npercent_protected <- as.numeric(percent_protected[1, ])\npercent_protected <- data.frame(species_code = species_list$species_code,\n                                common_name = species_list$common_name,\n                                percent_population = percent_protected) %>% \n  arrange(desc(percent_population))\nprint(percent_protected)\n#>    species_code                 common_name percent_population\n#> 1       pattyr2           Patagonian Tyrant            0.25141\n#> 2       thtray1       Thorn-tailed Rayadito            0.21774\n#> 3       chutap1             Chucao Tapaculo            0.18595\n#> 4       auspar1            Austral Parakeet            0.17797\n#> 5       grbfir1      Green-backed Firecrown            0.15287\n#> 6       strwoo6          Striped Woodpecker            0.13066\n#> 7       chifli1             Chilean Flicker            0.12446\n#> 8       chipig2              Chilean Pigeon            0.07358\n#> 9       cthhue1 Chestnut-throated Huet-huet            0.03652\n#> 10      chimoc1         Chilean Mockingbird            0.00682\n\n# plot the data\nggplot(percent_protected) +\n  aes(x = fct_reorder(common_name, percent_population),\n      y = percent_population) +\n  geom_col() +\n  scale_y_continuous(labels = scales::percent) +\n  labs(x = NULL, y = \"Percent of population in protected areas\") +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n3.6.3 Prioritization\nFor the final application, we’ll perform a multi-species site prioritization exercise, identifying important sites for protecting the set of 10 near-endemic species we identified in the previous application. Let’s start by generating a multi-species importance layer by calculating the mean percent of population across all 10 species. Since we’re focused on identifying sites in Chile, we’ll also crop and mask the importance layer to a boundary of Chile.\n\n# boundary of chile\nchile <- read_sf(\"data/gis-data.gpkg\", layer = \"ne_states\") %>% \n  st_transform(crs = crs(percent_population))\n\n# importance: mean percent of population across species\n# fill missing values with zeros prior to averaging\nimportance <- ifel(is.na(percent_population), 0, percent_population) %>% \n  mean(na.rm = TRUE) %>% \n  # crop and mask importance to focus on chile\n  crop(chile) %>% \n  mask(chile)\n\n# plot the square root of importance since the data are right skewed\npar(mar = c(0.25, 0.25, 0.25, 0.25))\ncrs <- \"+proj=laea +lat_0=-40 +lon_0=-72\"\nr_plot <- sqrt(importance) %>% \n  project(crs, method = \"near\") %>% \n  trim()\nplot(r_plot, axes = FALSE)\n\n\n\n\n\n\n\n\nThe absolute numbers in this map are challenging to interpret (they’re the mean proportion of the population across the 10 species in each cell). Instead, the values should be interpreted in relative terms, giving the relative importance of each cell for this set of 10 species.\nIn the previous application, we examined existing public protected areas. For the sake of comparison, let’s imagine we want to identify the most important sites in Chile that cover the same area as the existing protected area network. What proportion of chile does the current protected area cover?\n\n# proportion of chile in existing protected area network\narea_chile <- sum(st_area(chile))\narea_protected <- st_area(protected)\nproportion_protected <- as.numeric(area_protected / area_chile)\nprint(proportion_protected)\n#> [1] 0.172\n\nSo, 17.2% of Chile is covered by the existing network of public protected areas. Let’s identify the top 17.2% most important raster cells from the multi-species importance layer.\n\n# identify the quantile corresponding to the desired protection level\nq <- global(importance, fun = quantile, \n            probs = 1 - proportion_protected, na.rm = TRUE) %>% \n  as.numeric()\n# identify the most importance cells\nselected_sites <- as.numeric(importance >= q)\n\nLet’s compare maps of the existing protected area network and the sites selected using eBird Status and Trends.\n\npar(mar = c(0.25, 0.25, 0.25, 0.25))\nr_plot <- project(selected_sites, crs, method = \"near\") %>% \n  trim()\nprotected_proj <- st_transform(protected, crs = crs) %>% \n  st_geometry()\nplot(r_plot, axes = FALSE, legend = FALSE)\nplot(st_simplify(protected_proj), add = TRUE)\n\n\n\n\n\n\n\n\nThe high importance sites we identified are shown in green, while the existing protected area network is shown outlined in black. It appears the existing protected area network is mostly in southern Chile and there is limited overlap with areas of high importance to the 10 near-endemic species we chose to focus on. This is not surprising since the location of existing protected areas was not chosen specifically to protect these 10 species. Let’s quantify what proportion of the population these two regions capture.\n\n# mask the percent of population layers by the selected sites\nselected_pp <- percent_population %>% \n  crop(selected_sites) %>% \n  mask(selected_sites, maskvalues = c(0, NA))\n# calculate total percent of population within proposed sites\npercent_selected <- global(selected_pp, fun = \"sum\", na.rm = TRUE)\npercent_selected <- data.frame(species_code = names(selected_pp),\n                               selected_percent = percent_selected[, 1])\n\n# combine with values for existing network\ncomparison <- inner_join(percent_protected, percent_selected,\n                         by = \"species_code\") %>% \n  rename(existing_network = percent_population,\n         prioritized_sites = selected_percent) %>% \n  pivot_longer(cols = c(existing_network, prioritized_sites),\n               names_to = \"network_type\",\n               values_to = \"percent_population\")\n\n# plot the data\nggplot(comparison) +\n  aes(x = fct_reorder(common_name, percent_population),\n      y = percent_population,\n      group = network_type,\n      fill = network_type) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(x = NULL, \n       y = \"Percent of population in protected areas\",\n       fill = NULL) +\n  coord_flip() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nSo, for the same total area, we can capture a much larger proportion of the populations of these species if we use eBird Status data products for these species in our site prioritization. This exampel is, of course, overly simplistic. In practices, systematic conservation planning tools like the R package prioritizr can perform much more complex prioritizations, accounting for both the spatial and temporal aspects of species distributions, taking advantage of site complementarity, allowing for more flexible conservation goals, and accounting for both conservation value and economic cost of sites. eBird Status data products are well suited for use in systematic conservation planning exercises using prioritizr."
  }
]